<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>logging.DEBUG</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://imperio-wxm.github.io/"/>
  <updated>2019-03-01T16:13:27.314Z</updated>
  <id>http://imperio-wxm.github.io/</id>
  
  <author>
    <name>wxmimperio</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Apache HTTP Server 编译与安装</title>
    <link href="http://imperio-wxm.github.io/2019/03/01/Apache-HTTP-Server-Compile-Install/"/>
    <id>http://imperio-wxm.github.io/2019/03/01/Apache-HTTP-Server-Compile-Install/</id>
    <published>2019-03-01T13:43:30.000Z</published>
    <updated>2019-03-01T16:13:27.314Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在使用ApacheBench做压力测试的时候出现<code>30s</code>request超时的情况，由于版本老旧，<code>ab -h</code>中发现并没有<code>-s timeout</code>的参数配置，Google上找了半天也没有可用的Binaries版本，于是开始自己编译httpd源码</p></blockquote><a id="more"></a><ul><li><a href="http://httpd.apache.org/docs/2.4/programs/ab.html" target="_blank" rel="noopener">ApacheBench Doc 文档</a></li></ul><blockquote><p>针对于ab timeout的问题(报错：The timeout specified has expired (70007))，加了<code>-k</code> 参数保证keepalived参数也无用，在2.4.4+版本中加入了<code>-s</code>参数控制timeout；</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-s timeout</span><br><span class="line">Maximum number of seconds to wait before the socket times out. Default is <span class="number">30</span> seconds. Available in <span class="number">2.4</span>.4 and later.</span><br></pre></td></tr></table></figure><table><thead><tr><th>SoftWare</th><th>Version</th></tr></thead><tbody><tr><td>Ubuntu Server x64</td><td>14.04</td></tr><tr><td>pcre</td><td>8.38</td></tr><tr><td>apr-util</td><td>1.6.1</td></tr><tr><td>apr</td><td>1.6.5</td></tr><tr><td>httpd</td><td>2.4.38</td></tr><tr><td>gcc &amp; gcc-c++</td><td>5.4.0</td></tr></tbody></table><blockquote><p>gcc &amp; gcc-c++ 系统自带；如果自己本机没有需要先install下</p></blockquote><h1 id="pcre-编译"><a href="#pcre-编译" class="headerlink" title="pcre 编译"></a>pcre 编译</h1><ul><li><a href="ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/" target="_blank" rel="noopener">pcre 下载</a></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">unzip pcre-<span class="number">8.38</span>.zip </span><br><span class="line">cd pcre-<span class="number">8.38</span></span><br><span class="line"></span><br><span class="line"># 指定编译目录</span><br><span class="line">./configure --prefix=/usr/local/pcre</span><br><span class="line"></span><br><span class="line"># 编译安装</span><br><span class="line">sudo make &amp; sudo make install</span><br></pre></td></tr></table></figure><blockquote><p>注意在make 失败后，一定要使用make clean命令清空环境</p></blockquote><ul><li><code>错误1</code></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xml/apr_xml.c:<span class="number">35</span>:<span class="number">19</span>: fatal error: expat.h: No such file or directory</span><br></pre></td></tr></table></figure><ul><li><code>解决</code></li></ul><p>Centos安装：yum install expat-devel</p><p>ubuntu安装：sudo apt-get install libexpat1-dev</p><h1 id="apr-amp-apr-util-编译"><a href="#apr-amp-apr-util-编译" class="headerlink" title="apr &amp; apr-util 编译"></a>apr &amp; apr-util 编译</h1><ul><li><p><a href="http://apr.apache.org/download.cgi" target="_blank" rel="noopener">apr &amp; apr-util 下载</a></p></li><li><p><a href="https://httpd.apache.org/download.cgi#apache24" target="_blank" rel="noopener">httpd 下载</a></p></li></ul><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apr-util-<span class="number">1.6</span>.1.tar.gz</span><br><span class="line">tar -zxvf apr-<span class="number">1.6</span>.5.tar.gz</span><br><span class="line">tar -zxvf httpd-<span class="number">2.4</span>.38.tar.gz</span><br><span class="line"></span><br><span class="line"># 一定要复制到httpd的srclib目录下，且目录版本号去掉</span><br><span class="line">cp -r apr-<span class="number">1.6</span>.5 httpd-<span class="number">2.4</span>.38/srclib/apr</span><br><span class="line">cp -r apr-util-<span class="number">1.6</span>.1 httpd-<span class="number">2.4</span>.38/srclib/apr-util</span><br></pre></td></tr></table></figure><h2 id="apr-编译"><a href="#apr-编译" class="headerlink" title="apr 编译"></a>apr 编译</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># apr 编译</span><br><span class="line">cd httpd-<span class="number">2.4</span>.38/srclib/apr</span><br><span class="line"></span><br><span class="line"># 指定编译目录</span><br><span class="line">./configure --prefix=/usr/local/apr</span><br><span class="line"></span><br><span class="line"># 编译安装</span><br><span class="line">sudo make &amp; sudo make install</span><br></pre></td></tr></table></figure><h2 id="apr-util-编译"><a href="#apr-util-编译" class="headerlink" title="apr-util 编译"></a>apr-util 编译</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># apr 编译</span><br><span class="line">cd httpd-<span class="number">2.4</span>.38/srclib/apr-util</span><br><span class="line"></span><br><span class="line"># 指定编译目录 并 指定apr依赖</span><br><span class="line">./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr </span><br><span class="line"></span><br><span class="line"># 编译安装</span><br><span class="line">sudo make &amp; sudo make install</span><br></pre></td></tr></table></figure><h1 id="httpd-编译"><a href="#httpd-编译" class="headerlink" title="httpd 编译"></a>httpd 编译</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cd httpd-<span class="number">2.4</span>.38</span><br><span class="line"></span><br><span class="line"># 指定编译目录 并 指定apr、apr-util、pcre依赖</span><br><span class="line">./configure --prefix=/usr/local/apache-httpd --with-apr=/usr/local/apr --with-apr-util=/usr/local/apr-util --with-pcre=/usr/local/pcre</span><br><span class="line"></span><br><span class="line"># 编译安装（这个过程比较长，耐心等待）</span><br><span class="line">sudo make &amp; sudo make install</span><br></pre></td></tr></table></figure><ul><li><code>错误2</code></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">recipe <span class="keyword">for</span> target <span class="string">'htpasswd'</span> failed</span><br></pre></td></tr></table></figure><ul><li><code>解决</code></li></ul><p>是因为<code>apr、apr-util</code>源码没有在<code>httpd-2.4.38/srclib/</code>目录下，cp过去就可以（注意：只需目录名，无需版本号）</p><h1 id="测试安装成功"><a href="#测试安装成功" class="headerlink" title="测试安装成功"></a>测试安装成功</h1><ul><li>ApacheBench 测试</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"># 发现已经有了 -s 参数</span><br><span class="line">/usr/local/apache-httpd/bin/ab -h</span><br><span class="line"></span><br><span class="line">Usage: ./ab [options] [http[s]:<span class="comment">//]hostname[:port]/path</span></span><br><span class="line">Options are:</span><br><span class="line">    -n requests     Number of requests to perform</span><br><span class="line">    -c concurrency  Number of multiple requests to make at a time</span><br><span class="line">    -t timelimit    Seconds to max. to spend on benchmarking</span><br><span class="line">                    This implies -n <span class="number">50000</span></span><br><span class="line">    -s timeout      Seconds to max. wait <span class="keyword">for</span> each response</span><br><span class="line">                    Default is <span class="number">30</span> seconds</span><br><span class="line">    -b windowsize   Size of TCP send/receive buffer, in bytes</span><br><span class="line">    -B address      Address to bind to when making outgoing connections</span><br><span class="line">    -p postfile     File containing data to POST. Remember also to set -T</span><br><span class="line">    -u putfile      File containing data to PUT. Remember also to set -T</span><br><span class="line">    -T content-type Content-type header to use <span class="keyword">for</span> POST/PUT data, eg.</span><br><span class="line">                    <span class="string">'application/x-www-form-urlencoded'</span></span><br><span class="line">                    Default is <span class="string">'text/plain'</span></span><br><span class="line">    -v verbosity    How much troubleshooting info to print</span><br><span class="line">    -w              Print out results in HTML tables</span><br><span class="line">    -i              Use HEAD instead of GET</span><br><span class="line">    -x attributes   String to insert as table attributes</span><br><span class="line">    -y attributes   String to insert as tr attributes</span><br><span class="line">    -z attributes   String to insert as td or th attributes</span><br><span class="line">    -C attribute    Add cookie, eg. <span class="string">'Apache=1234'</span>. (repeatable)</span><br><span class="line">    -H attribute    Add Arbitrary header line, eg. <span class="string">'Accept-Encoding: gzip'</span></span><br><span class="line">                    Inserted after all normal header lines. (repeatable)</span><br><span class="line">    -A attribute    Add Basic WWW Authentication, the attributes</span><br><span class="line">                    are a colon separated username and password.</span><br><span class="line">    -P attribute    Add Basic Proxy Authentication, the attributes</span><br><span class="line">                    are a colon separated username and password.</span><br><span class="line">    -X proxy:port   Proxyserver and port number to use</span><br><span class="line">    -V              Print version number and exit</span><br><span class="line">    -k              Use HTTP KeepAlive feature</span><br><span class="line">    -d              Do not show percentiles served table.</span><br><span class="line">    -S              Do not show confidence estimators and warnings.</span><br><span class="line">    -q              Do not show progress when doing more than <span class="number">150</span> requests</span><br><span class="line">    -<span class="function">l              Accept variable document <span class="title">length</span> <span class="params">(use <span class="keyword">this</span> <span class="keyword">for</span> dynamic pages)</span></span></span><br><span class="line"><span class="function">    -g filename     Output collected data to gnuplot format file.</span></span><br><span class="line"><span class="function">    -e filename     Output CSV file with percentages served</span></span><br><span class="line"><span class="function">    -r              Don't exit on socket receive errors.</span></span><br><span class="line"><span class="function">    -m method       Method name</span></span><br><span class="line"><span class="function">    -h              Display usage <span class="title">information</span> <span class="params">(<span class="keyword">this</span> message)</span></span></span><br><span class="line"><span class="function">    -I              Disable TLS Server Name <span class="title">Indication</span> <span class="params">(SNI)</span> extension</span></span><br><span class="line"><span class="function">    -Z ciphersuite  Specify SSL/TLS cipher <span class="title">suite</span> <span class="params">(See openssl ciphers)</span></span></span><br><span class="line"><span class="function">    -f protocol     Specify SSL/TLS protocol</span></span><br><span class="line"><span class="function">                    <span class="params">(TLS1, TLS1<span class="number">.1</span>, TLS1<span class="number">.2</span> or ALL)</span></span></span><br><span class="line"><span class="function">    -E certfile     Specify optional client certificate chain and <span class="keyword">private</span> key</span></span><br></pre></td></tr></table></figure><ul><li>服务测试</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sudovim /usr/local/apache-httpd/conf/httpd.conf</span><br><span class="line"></span><br><span class="line"># 添加ServerName</span><br><span class="line">ServerName localhost:<span class="number">80</span></span><br><span class="line"></span><br><span class="line">sudo /usr/local/apache-httpd/bin/apachectl start</span><br><span class="line"></span><br><span class="line">curl localhost</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;</span><br><span class="line"></span><br><span class="line">sudo /usr/local/apache-httpd/bin/apachectl stop</span><br></pre></td></tr></table></figure><hr><blockquote><p>转载请注明出处：<a href="https://github.com/imperio-wxm" target="_blank" rel="noopener">https://github.com/imperio-wxm</a></p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在使用ApacheBench做压力测试的时候出现&lt;code&gt;30s&lt;/code&gt;request超时的情况，由于版本老旧，&lt;code&gt;ab -h&lt;/code&gt;中发现并没有&lt;code&gt;-s timeout&lt;/code&gt;的参数配置，Google上找了半天也没有可用的Binaries版本，于是开始自己编译httpd源码&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/categories/Linux/"/>
    
    
      <category term="Apache" scheme="http://imperio-wxm.github.io/tags/Apache/"/>
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Apache Phoenix RowTimestamp</title>
    <link href="http://imperio-wxm.github.io/2019/02/25/Apache-Phoenix-Row-Timestamp/"/>
    <id>http://imperio-wxm.github.io/2019/02/25/Apache-Phoenix-Row-Timestamp/</id>
    <published>2019-02-25T11:34:12.000Z</published>
    <updated>2019-02-28T14:12:10.085Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>从4.6版本起，Phoenix支持一种时间戳映射到列的方法（即HBase中 column 的RowTimestamp），以便对Phoenix在存储时序数据时查询的优化</p></blockquote><a id="more"></a><h1 id="Row-Timestamp介绍"><a href="#Row-Timestamp介绍" class="headerlink" title="Row Timestamp介绍"></a>Row Timestamp介绍</h1><blockquote><p>在建表时对特定列指定<code>ROW_TIMESTAMP</code>关键字：</p></blockquote><ul><li>只有当parimary key为以下类型时才可以使用<code>ROW_TIMESTAMP</code>：<code>TIME, DATE, TIMESTAMP, BIGINT, UNSIGNED_LONG</code></li><li>若primary key为组合主键的时候，只有一个column能指定为<code>ROW_TIMESTAMP</code></li><li>此列的值不能为null</li><li>此列的值不能为负</li></ul><p>当使用UPSERT VALUES or UPSERT SELECT语句更新数据时，可以指定<code>ROW_TIMESTAMP</code>的值，如果不指定则默认以服务器时间为此列的时间戳，同时这个时间戳也对应hbase 中row的timestamp</p><p>当查询过滤<code>ROW_TIMESTAMP</code>时，不仅可以做常规的查询优化，同时可以依靠timestamp对数据进行最大最小的范围优化，hbase服务器端可以直接跳过不在时间区间内的hfile文件从而使扫描效率提高，尤其是查询数据尾端的时候</p><p><a href="http://phoenix.apache.org/rowtimestamp.html" target="_blank" rel="noopener">Phenix RowTimestap Doc</a></p><table><thead><tr><th>SoftWare</th><th>Version</th></tr></thead><tbody><tr><td>Hbase</td><td>1.2.0-cdh5.11.1</td></tr><tr><td>Phoenix</td><td>4.13.0-cdh5.11.1</td></tr><tr><td>Java</td><td>1.8.0_121</td></tr></tbody></table><p>部署环境：4 Region Servers</p><h1 id="测试用例"><a href="#测试用例" class="headerlink" title="测试用例"></a>测试用例</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> phoenix_dev.test_ywzx_wuhan_switch (</span><br><span class="line">event_time <span class="keyword">TIMESTAMP</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="comment">/*event_time*/</span>,</span><br><span class="line"><span class="string">"_KEY"</span> <span class="built_in">BIGINT</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="comment">/*_key*/</span>,</span><br><span class="line">switch_output_multicastpkts_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_output_multicastpkts_delta*/</span>,</span><br><span class="line">switch_output_broadcastpkts_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_output_broadcastpkts_delta*/</span>,</span><br><span class="line">switch_input_errors_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_input_errors_delta*/</span>,</span><br><span class="line">switch_cpu_utilization <span class="built_in">BIGINT</span> <span class="comment">/*switch_cpu_utilization*/</span>,</span><br><span class="line">switch_sysobjectid <span class="built_in">VARCHAR</span> <span class="comment">/*switch_sysobjectid*/</span>,</span><br><span class="line">switch_memory_utilization <span class="built_in">FLOAT</span> <span class="comment">/*switch_memory_utilization*/</span>,</span><br><span class="line">switch_input_multicastpkts_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_input_multicastpkts_delta*/</span>,</span><br><span class="line">switch_input_bytes_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_input_bytes_delta*/</span>,</span><br><span class="line">switch_output_errors_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_output_errors_delta*/</span>,</span><br><span class="line">switch_output_bytes_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_output_bytes_delta*/</span>,</span><br><span class="line">switch_port_status <span class="built_in">VARCHAR</span> <span class="comment">/*switch_port_status*/</span>,</span><br><span class="line">switch_output_ucastpkts_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_output_ucastpkts_delta*/</span>,</span><br><span class="line">switch_portname <span class="built_in">VARCHAR</span> <span class="comment">/*switch_portname*/</span>,</span><br><span class="line">switch_fan_status <span class="built_in">VARCHAR</span> <span class="comment">/*switch_fan_status*/</span>,</span><br><span class="line">switch_index <span class="built_in">VARCHAR</span> <span class="comment">/*switch_index*/</span>,</span><br><span class="line">switch_host <span class="built_in">VARCHAR</span> <span class="comment">/*switch_host*/</span>,</span><br><span class="line">switch_gims_measurement <span class="built_in">VARCHAR</span> <span class="comment">/*switch_gims_measurement*/</span>,</span><br><span class="line">switch_power_status <span class="built_in">VARCHAR</span> <span class="comment">/*switch_power_status*/</span>,</span><br><span class="line">switch_input_broadcastpkts_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_input_broadcastpkts_delta*/</span>,</span><br><span class="line">switch_input_ucastpkts_delta <span class="built_in">BIGINT</span> <span class="comment">/*switch_input_ucastpkts_delta*/</span>,</span><br><span class="line">switch_errorstatus <span class="built_in">INTEGER</span> <span class="comment">/*switch_errorstatus*/</span>,</span><br><span class="line"><span class="keyword">CONSTRAINT</span> pk PRIMARY <span class="keyword">KEY</span> (event_time <span class="keyword">ASC</span>, <span class="string">"_KEY"</span> <span class="keyword">ASC</span>)</span><br><span class="line">) COMPRESSION = SNAPPY,</span><br><span class="line"> SALT_BUCKETS = <span class="number">4</span>,</span><br><span class="line"> <span class="keyword">VERSIONS</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">UPSERT INTO PHOENIX_DEV.test_ywzx_wuhan_switch (</span><br><span class="line">event_time,</span><br><span class="line">_KEY,</span><br><span class="line">switch_output_multicastpkts_delta,</span><br><span class="line">switch_output_broadcastpkts_delta,</span><br><span class="line">switch_input_errors_delta,</span><br><span class="line">switch_cpu_utilization,</span><br><span class="line">switch_sysobjectid,</span><br><span class="line">switch_memory_utilization,</span><br><span class="line">switch_input_multicastpkts_delta,</span><br><span class="line">switch_input_bytes_delta,</span><br><span class="line">switch_output_errors_delta,</span><br><span class="line">switch_output_bytes_delta,</span><br><span class="line">switch_port_status,</span><br><span class="line">switch_output_ucastpkts_delta,</span><br><span class="line">switch_portname,</span><br><span class="line">switch_fan_status,</span><br><span class="line">switch_index,</span><br><span class="line">switch_host,</span><br><span class="line">switch_gims_measurement,</span><br><span class="line">switch_power_status,</span><br><span class="line">switch_input_broadcastpkts_delta,</span><br><span class="line">switch_input_ucastpkts_delta,</span><br><span class="line">switch_errorstatus</span><br><span class="line">)</span><br><span class="line">VALUES</span><br><span class="line">(</span><br><span class="line">?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?</span><br><span class="line">)</span><br></pre></td></tr></table></figure><ul><li>primary key 组成：CONSTRAINT pk PRIMARY KEY (event_time ASC, “_KEY” ASC)</li></ul><p><code>建立一张表结构完全一样的表test_ywzx_wuhan_switch_rowtimestap，给event_time字段添加ROW_TIMESTAMP</code></p><p><code>即给时间主键设置ROW_TIMESTAMP</code></p><ul><li>数据量及大小</li></ul><p>2000w条数据<br>压缩后size：<br>3.5 G  10.4 G  /hbase/data/PHOENIX_DEV/TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP</p><p>event_time时间范围： 2018-10-21 14:03:34.503 —— 2018-12-06 21:10:14.303</p><p>自动split一次，由于salt = 4，所以写入始终向4 Region Servers，查询旧数据则扫描前4个RS，查询新数据扫描后4个RS，全表查询则使用8个RS</p><p><code>select count(*) from PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH where event_time &gt;= to_timestamp(&#39;2018-10-21 00:00:00&#39;) AND event_time &lt;= to_timestamp(&#39;2018-12-05 00:00:00&#39;)</code><br><code>size = 1900w+</code></p><h2 id="测试语句一"><a href="#测试语句一" class="headerlink" title="测试语句一"></a>测试语句一</h2><blockquote><p>无ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH;</span><br><span class="line"></span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| COUNT(1)  |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| 20000000  |</span><br><span class="line">+<span class="comment">-----------+</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span></span><br><span class="line">+<span class="comment">-------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                       PLAN                                                        | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">-------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">72</span>-<span class="keyword">CHUNK</span> <span class="number">18453404</span> <span class="keyword">ROWS</span> <span class="number">20132661420</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">4</span>-WAY <span class="keyword">FULL</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH  | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> FILTER <span class="keyword">BY</span> <span class="keyword">FIRST</span> <span class="keyword">KEY</span> <span class="keyword">ONLY</span>                                                                               | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> SINGLE <span class="keyword">ROW</span>                                                                              | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">+<span class="comment">-------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>6.159 seconds</td></tr><tr><td>2</td><td>5.537 seconds</td></tr><tr><td>3</td><td>4.686 seconds</td></tr><tr><td>4</td><td>4.429 seconds</td></tr><tr><td>5</td><td>4.943 seconds</td></tr></tbody></table><blockquote><p>有ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP;</span><br><span class="line"></span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| COUNT(1)  |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| 20000000  |</span><br><span class="line">+<span class="comment">-----------+</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span></span><br><span class="line">+<span class="comment">--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                              PLAN                                                              | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">52</span>-<span class="keyword">CHUNK</span> <span class="number">12686716</span> <span class="keyword">ROWS</span> <span class="number">13841204812</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">4</span>-WAY <span class="keyword">FULL</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP  | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">ROW</span> <span class="keyword">TIMESTAMP</span> FILTER [<span class="number">0</span>, <span class="number">9223372036854775807</span>)                                                                              | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> FILTER <span class="keyword">BY</span> <span class="keyword">FIRST</span> <span class="keyword">KEY</span> <span class="keyword">ONLY</span>                                                                                            | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> SINGLE <span class="keyword">ROW</span>                                                                                           | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">+<span class="comment">--------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>21.726 seconds</td></tr><tr><td>2</td><td>20.906 seconds</td></tr><tr><td>3</td><td>19.494 seconds</td></tr><tr><td>4</td><td>19.514 seconds</td></tr><tr><td>5</td><td>19.478 seconds</td></tr></tbody></table><h2 id="测试语句二"><a href="#测试语句二" class="headerlink" title="测试语句二"></a>测试语句二</h2><blockquote><p>无ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(SWITCH_HOST),SWITCH_HOST,<span class="keyword">count</span>(SWITCH_POWER_STATUS),SWITCH_POWER_STATUS <span class="keyword">from</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH <span class="keyword">where</span> event_time &gt;= to_timestamp(<span class="string">'2018-10-21 00:00:00'</span>) <span class="keyword">AND</span> event_time &lt;= to_timestamp(<span class="string">'2018-12-05 00:00:00'</span>) <span class="keyword">group</span> <span class="keyword">by</span> SWITCH_HOST,SWITCH_POWER_STATUS <span class="keyword">limit</span> <span class="number">5000</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span></span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                                                       PLAN                                                                                        | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">72</span>-<span class="keyword">CHUNK</span> <span class="number">18453404</span> <span class="keyword">ROWS</span> <span class="number">20132661420</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">72</span>-WAY <span class="keyword">RANGE</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH [<span class="number">0</span>,<span class="string">'2018-10-20 16:00:00.000'</span>] - [<span class="number">3</span>,<span class="string">'2018-12-04 16:00:00.000'</span>]  | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> <span class="keyword">DISTINCT</span> <span class="keyword">ROWS</span> <span class="keyword">BY</span> [SWITCH_HOST, SWITCH_POWER_STATUS]                                                                                                     | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">MERGE</span> <span class="keyword">SORT</span>                                                                                                                                                                 | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">5000</span> <span class="keyword">ROW</span> <span class="keyword">LIMIT</span>                                                                                                                                                             | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>5.714 seconds</td></tr><tr><td>2</td><td>5.355 seconds</td></tr><tr><td>3</td><td>4.98 seconds</td></tr><tr><td>4</td><td>4.922 seconds</td></tr><tr><td>5</td><td>5.02 seconds</td></tr></tbody></table><blockquote><p>有ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(SWITCH_HOST),SWITCH_HOST,<span class="keyword">count</span>(SWITCH_POWER_STATUS),SWITCH_POWER_STATUS <span class="keyword">from</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP <span class="keyword">where</span> event_time &gt;= to_timestamp(<span class="string">'2018-10-21 00:00:00'</span>) <span class="keyword">AND</span> event_time &lt;= to_timestamp(<span class="string">'2018-12-05 00:00:00'</span>) <span class="keyword">group</span> <span class="keyword">by</span> SWITCH_HOST,SWITCH_POWER_STATUS <span class="keyword">limit</span> <span class="number">5000</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span></span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                                                              PLAN                                                                                              | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">52</span>-<span class="keyword">CHUNK</span> <span class="number">12686716</span> <span class="keyword">ROWS</span> <span class="number">13841204812</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">52</span>-WAY <span class="keyword">RANGE</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP [<span class="number">0</span>,<span class="string">'2018-10-20 16:00:00.000'</span>] - [<span class="number">3</span>,<span class="string">'2018-12-04 16:00:00.000'</span>]  | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">ROW</span> <span class="keyword">TIMESTAMP</span> FILTER [<span class="number">1540051200000</span>, <span class="number">1543939200001</span>)                                                                                                                                        | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> <span class="keyword">DISTINCT</span> <span class="keyword">ROWS</span> <span class="keyword">BY</span> [SWITCH_HOST, SWITCH_POWER_STATUS]                                                                                                                  | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">MERGE</span> <span class="keyword">SORT</span>                                                                                                                                                                              | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">5000</span> <span class="keyword">ROW</span> <span class="keyword">LIMIT</span>                                                                                                                                                                          | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>19.391 seconds</td></tr><tr><td>2</td><td>18.249 seconds</td></tr><tr><td>3</td><td>18.195 seconds</td></tr><tr><td>4</td><td>18.567 seconds</td></tr><tr><td>5</td><td>18.247 seconds</td></tr></tbody></table><h2 id="测试语句三"><a href="#测试语句三" class="headerlink" title="测试语句三"></a>测试语句三</h2><blockquote><p>无ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> <span class="keyword">CAST</span>(<span class="keyword">floor</span>(event_time, <span class="string">'MINUTE'</span>, <span class="number">1</span>) <span class="keyword">AS</span> <span class="keyword">timestamp</span>) <span class="keyword">AS</span> log_time, switch_host, <span class="keyword">MAX</span>(switch_cpu_utilization) <span class="keyword">AS</span> cpu_utilization <span class="keyword">FROM</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH <span class="keyword">AS</span> ywzx_wuhan_switch <span class="keyword">WHERE</span> switch_gims_measurement = <span class="string">'ddd'</span> <span class="keyword">AND</span> switch_host = <span class="string">'fff'</span> <span class="keyword">AND</span> ywzx_wuhan_switch.event_time &gt;= to_timestamp(<span class="string">'2018-10-21 00:00:00'</span>) <span class="keyword">AND</span> ywzx_wuhan_switch.event_time &lt;= to_timestamp(<span class="string">'2018-12-05 00:00:00'</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> log_time, switch_host <span class="keyword">ORDER</span> <span class="keyword">BY</span>  switch_host,log_time <span class="keyword">desc</span>) <span class="keyword">LIMIT</span> <span class="number">5000</span> <span class="keyword">offset</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span> </span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                                                       PLAN                                                                                        | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">72</span>-<span class="keyword">CHUNK</span> <span class="number">18453404</span> <span class="keyword">ROWS</span> <span class="number">20132661420</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">72</span>-WAY <span class="keyword">RANGE</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH [<span class="number">0</span>,<span class="string">'2018-10-20 16:00:00.000'</span>] - [<span class="number">3</span>,<span class="string">'2018-12-04 16:00:00.000'</span>]  | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> FILTER <span class="keyword">BY</span> (SWITCH_GIMS_MEASUREMENT = <span class="string">'ddd'</span> <span class="keyword">AND</span> SWITCH_HOST = <span class="string">'fff'</span>)                                                                                                    | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> <span class="keyword">DISTINCT</span> <span class="keyword">ROWS</span> <span class="keyword">BY</span> [TO_TIMESTAMP(<span class="keyword">FLOOR</span>(<span class="keyword">TO_DATE</span>(EVENT_TIME))), SWITCH_HOST]                                                                                | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">MERGE</span> <span class="keyword">SORT</span>                                                                                                                                                                 | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> TOP <span class="number">5000</span> <span class="keyword">ROWS</span> SORTED <span class="keyword">BY</span> [SWITCH_HOST, TO_TIMESTAMP(<span class="keyword">FLOOR</span>(<span class="keyword">TO_DATE</span>(EVENT_TIME))) <span class="keyword">DESC</span>]                                                                                       | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>6.917 seconds</td></tr><tr><td>2</td><td>5.914 seconds</td></tr><tr><td>3</td><td>5.929 seconds</td></tr><tr><td>4</td><td>6.091 seconds</td></tr><tr><td>5</td><td>6.135 seconds</td></tr></tbody></table><blockquote><p>有ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> <span class="keyword">CAST</span>(<span class="keyword">floor</span>(event_time, <span class="string">'MINUTE'</span>, <span class="number">1</span>) <span class="keyword">AS</span> <span class="keyword">timestamp</span>) <span class="keyword">AS</span> log_time, switch_host, <span class="keyword">MAX</span>(switch_cpu_utilization) <span class="keyword">AS</span> cpu_utilization <span class="keyword">FROM</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP <span class="keyword">AS</span> ywzx_wuhan_switch <span class="keyword">WHERE</span> switch_gims_measurement = <span class="string">'ddd'</span> <span class="keyword">AND</span> switch_host = <span class="string">'fff'</span> <span class="keyword">AND</span> ywzx_wuhan_switch.event_time &gt;= to_timestamp(<span class="string">'2018-10-21 00:00:00'</span>) <span class="keyword">AND</span> ywzx_wuhan_switch.event_time &lt;= to_timestamp(<span class="string">'2018-12-05 00:00:00'</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> log_time, switch_host <span class="keyword">ORDER</span> <span class="keyword">BY</span>  switch_host,log_time <span class="keyword">desc</span>) <span class="keyword">LIMIT</span> <span class="number">5000</span> <span class="keyword">offset</span> <span class="number">0</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span> </span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                                                              PLAN                                                                                              | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">52</span>-<span class="keyword">CHUNK</span> <span class="number">12686716</span> <span class="keyword">ROWS</span> <span class="number">13841204812</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">52</span>-WAY <span class="keyword">RANGE</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP [<span class="number">0</span>,<span class="string">'2018-10-20 16:00:00.000'</span>] - [<span class="number">3</span>,<span class="string">'2018-12-04 16:00:00.000'</span>]  | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">ROW</span> <span class="keyword">TIMESTAMP</span> FILTER [<span class="number">1540051200000</span>, <span class="number">1543939200001</span>)                                                                                                                                        | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> FILTER <span class="keyword">BY</span> (SWITCH_GIMS_MEASUREMENT = <span class="string">'ddd'</span> <span class="keyword">AND</span> SWITCH_HOST = <span class="string">'fff'</span>)                                                                                                                 | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> <span class="keyword">DISTINCT</span> <span class="keyword">ROWS</span> <span class="keyword">BY</span> [TO_TIMESTAMP(<span class="keyword">FLOOR</span>(<span class="keyword">TO_DATE</span>(EVENT_TIME))), SWITCH_HOST]                                                                                             | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">MERGE</span> <span class="keyword">SORT</span>                                                                                                                                                                              | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> TOP <span class="number">5000</span> <span class="keyword">ROWS</span> SORTED <span class="keyword">BY</span> [SWITCH_HOST, TO_TIMESTAMP(<span class="keyword">FLOOR</span>(<span class="keyword">TO_DATE</span>(EVENT_TIME))) <span class="keyword">DESC</span>]                                                                                                    | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>19.875 seconds</td></tr><tr><td>2</td><td>20.301 seconds</td></tr><tr><td>3</td><td>18.88 seconds</td></tr><tr><td>4</td><td>19.706 seconds</td></tr><tr><td>5</td><td>19.302 seconds</td></tr></tbody></table><h2 id="测试语句四"><a href="#测试语句四" class="headerlink" title="测试语句四"></a>测试语句四</h2><blockquote><p>无ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">count</span>(*) <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> <span class="keyword">CAST</span>(<span class="keyword">floor</span>(event_time, <span class="string">'MINUTE'</span>, <span class="number">1</span>) <span class="keyword">AS</span> <span class="keyword">timestamp</span>) <span class="keyword">AS</span> log_time, switch_host, <span class="keyword">MAX</span>(switch_cpu_utilization) <span class="keyword">AS</span> cpu_utilization <span class="keyword">FROM</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH <span class="keyword">AS</span> TEST_YWZX_WUHAN_SWITCH <span class="keyword">WHERE</span> switch_gims_measurement = <span class="string">'ddd'</span> <span class="keyword">AND</span> switch_host = <span class="string">'fff'</span> <span class="keyword">AND</span> TEST_YWZX_WUHAN_SWITCH.event_time &gt;= to_timestamp(<span class="string">'2018-10-21 00:00:00'</span>) <span class="keyword">AND</span> TEST_YWZX_WUHAN_SWITCH.event_time &lt;= to_timestamp(<span class="string">'2018-12-05 00:00:00'</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">CAST</span>(<span class="keyword">floor</span>(event_time, <span class="string">'MINUTE'</span>, <span class="number">1</span>) <span class="keyword">AS</span> <span class="keyword">timestamp</span>), switch_host);</span><br><span class="line"></span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| COUNT(1)  |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| 60357     |</span><br><span class="line">+<span class="comment">-----------+</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span> </span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                                                       PLAN                                                                                        | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">72</span>-<span class="keyword">CHUNK</span> <span class="number">18453404</span> <span class="keyword">ROWS</span> <span class="number">20132661420</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">72</span>-WAY <span class="keyword">RANGE</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH [<span class="number">0</span>,<span class="string">'2018-10-20 16:00:00.000'</span>] - [<span class="number">3</span>,<span class="string">'2018-12-04 16:00:00.000'</span>]  | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> FILTER <span class="keyword">BY</span> (SWITCH_GIMS_MEASUREMENT = <span class="string">'ddd'</span> <span class="keyword">AND</span> SWITCH_HOST = <span class="string">'fff'</span>)                                                                                                    | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> <span class="keyword">DISTINCT</span> <span class="keyword">ROWS</span> <span class="keyword">BY</span> [TO_TIMESTAMP(<span class="keyword">FLOOR</span>(<span class="keyword">TO_DATE</span>(EVENT_TIME))), SWITCH_HOST]                                                                                | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">MERGE</span> <span class="keyword">SORT</span>                                                                                                                                                                 | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> SINGLE <span class="keyword">ROW</span>                                                                                                                                                  | <span class="number">20132661420</span>     | <span class="number">18453404</span>       | <span class="number">1550646317452</span>  |</span><br><span class="line">+<span class="comment">-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>6.888 seconds</td></tr><tr><td>2</td><td>5.896 seconds</td></tr><tr><td>3</td><td>5.263 seconds</td></tr><tr><td>4</td><td>5.576 seconds</td></tr><tr><td>5</td><td>5.665 seconds</td></tr></tbody></table><blockquote><p>有ROW_TIMESTAMP</p></blockquote><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">SELECT</span> <span class="keyword">count</span>(*) <span class="keyword">FROM</span> (<span class="keyword">SELECT</span> <span class="keyword">CAST</span>(<span class="keyword">floor</span>(event_time, <span class="string">'MINUTE'</span>, <span class="number">1</span>) <span class="keyword">AS</span> <span class="keyword">timestamp</span>) <span class="keyword">AS</span> log_time, switch_host, <span class="keyword">MAX</span>(switch_cpu_utilization) <span class="keyword">AS</span> cpu_utilization <span class="keyword">FROM</span> PHOENIX_DEV.TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP <span class="keyword">AS</span> TEST_YWZX_WUHAN_SWITCH <span class="keyword">WHERE</span> switch_gims_measurement = <span class="string">'ddd'</span> <span class="keyword">AND</span> switch_host = <span class="string">'fff'</span> <span class="keyword">AND</span> TEST_YWZX_WUHAN_SWITCH.event_time &gt;= to_timestamp(<span class="string">'2018-10-21 00:00:00'</span>) <span class="keyword">AND</span> TEST_YWZX_WUHAN_SWITCH.event_time &lt;= to_timestamp(<span class="string">'2018-12-05 00:00:00'</span>) <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">CAST</span>(<span class="keyword">floor</span>(event_time, <span class="string">'MINUTE'</span>, <span class="number">1</span>) <span class="keyword">AS</span> <span class="keyword">timestamp</span>), switch_host);</span><br><span class="line"> </span><br><span class="line"> +<span class="comment">-----------+</span></span><br><span class="line">| COUNT(1)  |</span><br><span class="line">+<span class="comment">-----------+</span></span><br><span class="line">| 60332     |</span><br><span class="line">+<span class="comment">-----------+</span></span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// <span class="keyword">explain</span> </span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">|                                                                                              PLAN                                                                                              | EST_BYTES_READ  | EST_ROWS_READ  |  EST_INFO_TS   |</span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="number">52</span>-<span class="keyword">CHUNK</span> <span class="number">12686716</span> <span class="keyword">ROWS</span> <span class="number">13841204812</span> <span class="keyword">BYTES</span> <span class="keyword">PARALLEL</span> <span class="number">52</span>-WAY <span class="keyword">RANGE</span> <span class="keyword">SCAN</span> <span class="keyword">OVER</span> PHOENIX_DEV:TEST_YWZX_WUHAN_SWITCH_ROWTIMESTAMP [<span class="number">0</span>,<span class="string">'2018-10-20 16:00:00.000'</span>] - [<span class="number">3</span>,<span class="string">'2018-12-04 16:00:00.000'</span>]  | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">ROW</span> <span class="keyword">TIMESTAMP</span> FILTER [<span class="number">1540051200000</span>, <span class="number">1543939200001</span>)                                                                                                                                        | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> FILTER <span class="keyword">BY</span> (SWITCH_GIMS_MEASUREMENT = <span class="string">'ddd'</span> <span class="keyword">AND</span> SWITCH_HOST = <span class="string">'fff'</span>)                                                                                                                 | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">|     <span class="keyword">SERVER</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> <span class="keyword">DISTINCT</span> <span class="keyword">ROWS</span> <span class="keyword">BY</span> [TO_TIMESTAMP(<span class="keyword">FLOOR</span>(<span class="keyword">TO_DATE</span>(EVENT_TIME))), SWITCH_HOST]                                                                                             | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">MERGE</span> <span class="keyword">SORT</span>                                                                                                                                                                              | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">| <span class="keyword">CLIENT</span> <span class="keyword">AGGREGATE</span> <span class="keyword">INTO</span> SINGLE <span class="keyword">ROW</span>                                                                                                                                                               | <span class="number">13841204812</span>     | <span class="number">12686716</span>       | <span class="number">1550647235912</span>  |</span><br><span class="line">+<span class="comment">------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+----------------+----------------+</span></span><br></pre></td></tr></table></figure><table><thead><tr><th>第N次执行</th><th>耗时</th></tr></thead><tbody><tr><td>1</td><td>19.967 seconds</td></tr><tr><td>2</td><td>18.854 seconds</td></tr><tr><td>3</td><td>19.637 seconds</td></tr><tr><td>4</td><td>18.701 seconds</td></tr><tr><td>5</td><td>18.986 seconds</td></tr></tbody></table><p><code>[JIRA 问题追踪](https://issues.apache.org/jira/browse/PHOENIX-5157)</code></p><hr><blockquote><p>转载请注明出处：<a href="https://github.com/imperio-wxm" target="_blank" rel="noopener">https://github.com/imperio-wxm</a></p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;从4.6版本起，Phoenix支持一种时间戳映射到列的方法（即HBase中 column 的RowTimestamp），以便对Phoenix在存储时序数据时查询的优化&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Phoenix" scheme="http://imperio-wxm.github.io/categories/Phoenix/"/>
    
      <category term="HBase" scheme="http://imperio-wxm.github.io/categories/Phoenix/HBase/"/>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/Phoenix/HBase/BigData/"/>
    
    
      <category term="Phoenix" scheme="http://imperio-wxm.github.io/tags/Phoenix/"/>
    
      <category term="HBase" scheme="http://imperio-wxm.github.io/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>Hive 优雅的统计表（分区）Size and RowCount</title>
    <link href="http://imperio-wxm.github.io/2019/02/21/Hive-Table-Statistics/"/>
    <id>http://imperio-wxm.github.io/2019/02/21/Hive-Table-Statistics/</id>
    <published>2019-02-21T14:07:43.000Z</published>
    <updated>2019-02-21T15:32:32.637Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在Hadoop平台运维监控中，Hive表的统计信息通常是作为集群数据质量的关键依据；通常以Hive表的大小、行数、分区数等信息来衡量集群数据量的增减趋势；本文以Hive表Size大小和数据行数作为重点，对于超大表统计时避免过多的资源消耗</p></blockquote><a id="more"></a><h2 id="两种常规方式统计："><a href="#两种常规方式统计：" class="headerlink" title="两种常规方式统计："></a>两种常规方式统计：</h2><ul><li>方式一：</li></ul><p>size 统计：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> size = FileSystem.getContentSummary(<span class="keyword">new</span> Path(tablePath)).getLength();</span><br></pre></td></tr></table></figure></p><p>rowCount统计：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">select <span class="title">count</span><span class="params">(*)</span> from tableName</span>;</span><br></pre></td></tr></table></figure><ul><li>方式二：</li></ul><p>size统计：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -du -s tablePath</span><br></pre></td></tr></table></figure><p>rowCount统计（非Orc、Parquet）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -text tablePath | wc -l</span><br></pre></td></tr></table></figure><blockquote><p>常规方式在获取rowCount时都有局限性（例如OrcFile无法用hadoop fs -text），并且效率不高</p></blockquote><h2 id="ANALYZE-方式统计"><a href="#ANALYZE-方式统计" class="headerlink" title="ANALYZE 方式统计"></a>ANALYZE 方式统计</h2><blockquote><p>ANALYZE TABLE tablename [PARTITION(partcol1[=val1], partcol2[=val2], …)] COMPUTE STATISTICS [noscan];</p></blockquote><p><code>考虑到表的统计值通常是要通过计算后记录到某个地方，执行ANALYZE的时候才会快速显示；为此探究什么情况下导入Hive数据，ANALYZE的结果准确</code></p><p><code>下文会以TextFile、SequenceFile、OrcFile、ParquetFile，四种常见的Hive表文件格式来做测试</code></p><blockquote><p>Hive数据导入途径：</p></blockquote><p><strong><em>1. Load file to hive table</em></strong></p><p><strong><em>2. Add partition and mv file to partition path</em></strong></p><p><strong><em>3. Insert into</em></strong></p><blockquote><p>测试数据文件</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 数据文件 count = 20</span></span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br><span class="line"><span class="number">1</span>wxmimperio1</span><br><span class="line"><span class="number">2</span>wxmimperio2</span><br></pre></td></tr></table></figure><h3 id="TextFile"><a href="#TextFile" class="headerlink" title="TextFile"></a>TextFile</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create table </span></span><br><span class="line">CREATE TABLE `analyze_text` (`id` string, `name` string) COMMENT <span class="string">'test'</span> <span class="function">PARTITIONED <span class="title">BY</span> <span class="params">(`part_date` string)</span> </span></span><br><span class="line"><span class="function">ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' WITH <span class="title">SERDEPROPERTIES</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">'field.delim'</span> = <span class="string">'\t'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">'serialization.format'</span> = <span class="string">'\t'</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span> STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.TextInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'</span>;</span><br></pre></td></tr></table></figure><ul><li><ol><li>Load file to table</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; LOAD DATA LOCAL INPATH <span class="string">'/home/hadoop/wxm/test.txt'</span> <span class="function">OVERWRITE INTO TABLE analyze_text <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">Loading data to table dw.<span class="function">analyze_text <span class="title">partition</span> <span class="params">(part_date=<span class="number">2019</span><span class="number">-02</span><span class="number">-21</span>)</span></span></span><br><span class="line"><span class="function">Partition dw.analyze_text</span>&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">298</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">1.035</span> seconds</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_text <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_text&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">298</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.463</span> seconds</span><br></pre></td></tr></table></figure><p><code>Load 操作实际上是执行了 mv 操作，将文件移动到表目录下面；ANALYZE 只能查看到numFiles（文件数）和totalSize（分区总大小）</code></p><ul><li><ol><li>Add partition and mv file to partition path</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// add partition</span></span><br><span class="line"><span class="function">alter table analyze_text add <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// cp files</span></span><br><span class="line">hadoop fs -cp hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_text/part_date=2019-02-21/* hdfs://sdg/user/hive/warehouse/dw.db/analyze_text/part_date=2019-02-20/</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_text <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_text&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">20</span>&#125; stats: [numFiles=<span class="number">1</span>, totalSize=<span class="number">298</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.202</span> seconds</span><br></pre></td></tr></table></figure><p><code>和Load操作一样，ANALYZE 只能查看到numFiles（文件数）和totalSize（分区总大小）</code></p><ul><li><ol><li>Insert into</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">insert into table analyze_text <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> select `id`,`name` from analyze_text_copy where part_date</span>=<span class="string">'2019-02-21'</span>;</span><br><span class="line"></span><br><span class="line">Query ID = hadoop_20190221143232_fbc19f00-d0af-<span class="number">4278</span>-a644-<span class="number">924</span>c92994a75</span><br><span class="line">Total jobs = <span class="number">3</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">3</span></span><br><span class="line">Number of reduce tasks is set to <span class="number">0</span> since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1535945194143_1278, Tracking URL = http://wh-8-211:8088/proxy/application_1535945194143_1278/</span></span><br><span class="line"><span class="string">Kill Command = /app/opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/lib/hadoop/bin/hadoop job  -kill job_1535945194143_1278</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2019-02-21 14:32:54,087 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2019-02-21 14:33:01,381 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.3 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 3 seconds 300 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1535945194143_1278</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to: hdfs://sdg/user/hive/warehouse/dw.db/analyze_text/part_date=2019-02-19/.hive-staging_hive_2019-02-21_14-32-46_291_8677282162206970479-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table dw.analyze_text partition (part_date=2019-02-19)</span></span><br><span class="line"><span class="string">Partition dw.analyze_text&#123;part_date=2019-02-19&#125; stats: [numFiles=1, numRows=20, totalSize=280, rawDataSize=260]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1   Cumulative CPU: 3.3 sec   HDFS Read: 3699 HDFS Write: 373 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 3 seconds 300 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 20.567 seconds</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_text <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_text&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">19</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">20</span>, totalSize=<span class="number">280</span>, rawDataSize=<span class="number">260</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.197</span> seconds</span><br></pre></td></tr></table></figure><p><code>由于insert into 用了 MapReduce，在计算的过程中就已经将表的统计信息记录了下来，所以numRows、rawDataSize都有</code></p><h3 id="SequenceFile"><a href="#SequenceFile" class="headerlink" title="SequenceFile"></a>SequenceFile</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create table </span></span><br><span class="line">CREATE TABLE `analyze_sequence_test` (`id` string, `name` string) <span class="function">PARTITIONED <span class="title">BY</span> <span class="params">(`part_date` string)</span> </span></span><br><span class="line"><span class="function">ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' WITH <span class="title">SERDEPROPERTIES</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">'field.delim'</span> = <span class="string">'\t'</span>,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="string">'serialization.format'</span> = <span class="string">'\t'</span></span></span></span><br><span class="line"><span class="function"><span class="params">)</span> STORED AS INPUTFORMAT 'org.apache.hadoop.mapred.SequenceFileInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat'</span>;</span><br></pre></td></tr></table></figure><ul><li><ol><li>Load file to table</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; LOAD DATA LOCAL INPATH <span class="string">'/home/hadoop/wxm/analyze_sequence_test_file'</span> <span class="function">OVERWRITE INTO TABLE analyze_sequence_test <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">Loading data to table dw.<span class="function">analyze_sequence_test <span class="title">partition</span> <span class="params">(part_date=<span class="number">2019</span><span class="number">-02</span><span class="number">-21</span>)</span></span></span><br><span class="line"><span class="function">Partition dw.analyze_sequence_test</span>&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">607</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">1.525</span> seconds</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_sequence_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_sequence_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">607</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.547</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, numRows=0, totalSize=607, rawDataSize=0]</code></p><ul><li><ol><li>Add partition and mv file to partition path</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// add partition</span></span><br><span class="line"><span class="function">alter table analyze_sequence_test add <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// cp files</span></span><br><span class="line">hadoop fs -cp hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_sequence_test/part_date=2019-02-19/* hdfs://sdg/user/hive/warehouse/dw.db/analyze_sequence_test/part_date=2019-02-20/</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ANALYZE TABLE analyze_sequence_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_sequence_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">20</span>&#125; stats: [numFiles=<span class="number">1</span>, totalSize=<span class="number">607</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.875</span> seconds</span><br></pre></td></tr></table></figure><p><code>由于sequenceFile文件的head中没有存储row的相关信息，所以获取不到</code></p><ul><li><ol><li>Insert into</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;  <span class="function">insert into table analyze_sequence_test <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> select `id`,`name` from analyze_text_copy where part_date</span>=<span class="string">'2019-02-21'</span>;</span><br><span class="line"></span><br><span class="line">Query ID = hadoop_20190221144141_f9ffbdc3-<span class="number">9e68</span>-<span class="number">43</span>d4-af7c-b8f883e84d3a</span><br><span class="line">Total jobs = <span class="number">3</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">3</span></span><br><span class="line">Number of reduce tasks is set to <span class="number">0</span> since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1535945194143_1279, Tracking URL = http://wh-8-211:8088/proxy/application_1535945194143_1279/</span></span><br><span class="line"><span class="string">Kill Command = /app/opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/lib/hadoop/bin/hadoop job  -kill job_1535945194143_1279</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2019-02-21 14:41:12,146 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2019-02-21 14:41:18,387 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.94 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 2 seconds 940 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1535945194143_1279</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to: hdfs://sdg/user/hive/warehouse/dw.db/analyze_sequence_test/part_date=2019-02-19/.hive-staging_hive_2019-02-21_14-41-04_329_3570329183914133571-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table dw.analyze_sequence_test partition (part_date=2019-02-19)</span></span><br><span class="line"><span class="string">Partition dw.analyze_sequence_test&#123;part_date=2019-02-19&#125; stats: [numFiles=1, numRows=20, totalSize=607, rawDataSize=260]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1   Cumulative CPU: 2.94 sec   HDFS Read: 3954 HDFS Write: 709 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 2 seconds 940 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 20.673 seconds</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_sequence_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_sequence_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">19</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">20</span>, totalSize=<span class="number">607</span>, rawDataSize=<span class="number">260</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.191</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, numRows=20, totalSize=607, rawDataSize=260]</code></p><h3 id="OrcFile"><a href="#OrcFile" class="headerlink" title="OrcFile"></a>OrcFile</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create table</span></span><br><span class="line">CREATE TABLE `analyze_orc_test` (`id` string, `name` string) <span class="function">PARTITIONED <span class="title">BY</span> <span class="params">(`part_date` string)</span> </span></span><br><span class="line"><span class="function">ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.orc.OrcSerde' </span></span><br><span class="line"><span class="function">STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat'</span>;</span><br></pre></td></tr></table></figure><ul><li><ol><li>Load file to table</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; LOAD DATA LOCAL INPATH <span class="string">'/home/hadoop/wxm/analyze_orc_test_file'</span> <span class="function">OVERWRITE INTO TABLE analyze_orc_test <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">Loading data to table dw.<span class="function">analyze_orc_test <span class="title">partition</span> <span class="params">(part_date=<span class="number">2019</span><span class="number">-02</span><span class="number">-21</span>)</span></span></span><br><span class="line"><span class="function">Partition dw.analyze_orc_test</span>&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">365</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.991</span> seconds</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_orc_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_orc_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">20</span>, totalSize=<span class="number">365</span>, rawDataSize=<span class="number">3600</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.661</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, numRows=20, totalSize=365, rawDataSize=3600]</code></p><ul><li><ol><li>Add partition and mv file to partition path</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// add partition</span></span><br><span class="line"><span class="function">alter table analyze_orc_test add <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// cp files</span></span><br><span class="line">hadoop fs -cp hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_orc_test/part_date=2019-02-19/* hdfs://sdg/user/hive/warehouse/dw.db/analyze_orc_test/part_date=2019-02-20/</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_orc_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_orc_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">20</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">20</span>, totalSize=<span class="number">365</span>, rawDataSize=<span class="number">3600</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.469</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, numRows=20, totalSize=365, rawDataSize=3600]</code></p><ul><li><ol><li>Insert into</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">insert into table analyze_orc_test <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> select `id`,`name` from analyze_text_copy where part_date</span>=<span class="string">'2019-02-21'</span>;</span><br><span class="line"></span><br><span class="line">Query ID = hadoop_20190221145353_70e75ca0-<span class="number">210f</span>-<span class="number">48</span>d1-bbd0-b4b0ed01c0cf</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks is set to <span class="number">0</span> since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1535945194143_1281, Tracking URL = http://wh-8-211:8088/proxy/application_1535945194143_1281/</span></span><br><span class="line"><span class="string">Kill Command = /app/opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/lib/hadoop/bin/hadoop job  -kill job_1535945194143_1281</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2019-02-21 14:53:53,124 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2019-02-21 14:54:00,420 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.6 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 3 seconds 600 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1535945194143_1281</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to: hdfs://sdg/user/hive/warehouse/dw.db/analyze_orc_test/part_date=2019-02-19/.hive-staging_hive_2019-02-21_14-53-45_113_8780230061527813380-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table dw.analyze_orc_test partition (part_date=2019-02-19)</span></span><br><span class="line"><span class="string">Partition dw.analyze_orc_test&#123;part_date=2019-02-19&#125; stats: [numFiles=1, numRows=20, totalSize=365, rawDataSize=3600]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1   Cumulative CPU: 3.6 sec   HDFS Read: 3947 HDFS Write: 463 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 3 seconds 600 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 18.592 seconds</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_orc_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_orc_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">19</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">20</span>, totalSize=<span class="number">365</span>, rawDataSize=<span class="number">3600</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.274</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, numRows=20, totalSize=365, rawDataSize=3600]</code></p><h3 id="Parquet"><a href="#Parquet" class="headerlink" title="Parquet"></a>Parquet</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// create table</span></span><br><span class="line">CREATE TABLE `analyze_parquet_test` (`id` string, `name` string) <span class="function">PARTITIONED <span class="title">BY</span> <span class="params">(`part_date` string)</span> </span></span><br><span class="line"><span class="function">ROW FORMAT SERDE 'org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe' </span></span><br><span class="line"><span class="function">STORED AS INPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat' OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat'</span>;</span><br></pre></td></tr></table></figure><ul><li><ol><li>Load file to table</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;  LOAD DATA LOCAL INPATH <span class="string">'/home/hadoop/wxm/analyze_parquet_test_file'</span> <span class="function">OVERWRITE INTO TABLE analyze_parquet_test <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">Loading data to table dw.<span class="function">analyze_parquet_test <span class="title">partition</span> <span class="params">(part_date=<span class="number">2019</span><span class="number">-02</span><span class="number">-21</span>)</span></span></span><br><span class="line"><span class="function">Partition dw.analyze_parquet_test</span>&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">390</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.972</span> seconds</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_parquet_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_parquet_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">0</span>, totalSize=<span class="number">390</span>, rawDataSize=<span class="number">0</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.576</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, numRows=0, totalSize=390, rawDataSize=0]</code></p><ul><li><ol><li>Add partition and mv file to partition path</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// add partition</span></span><br><span class="line"><span class="function">alter table analyze_parquet_test add <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// cp files</span></span><br><span class="line">hadoop fs -cp hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_parquet_test/part_date=2019-02-19/* hdfs://sdg/user/hive/warehouse/dw.db/analyze_parquet_test/part_date=2019-02-20/</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_parquet_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-20'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_parquet_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">20</span>&#125; stats: [numFiles=<span class="number">1</span>, totalSize=<span class="number">390</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.799</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, totalSize=390]</code></p><ul><li><ol><li>Insert into</li></ol></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">insert into table analyze_parquet_test <span class="title">partition</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> select `id`,`name` from analyze_text_copy where part_date</span>=<span class="string">'2019-02-21'</span>;</span><br><span class="line"></span><br><span class="line">Query ID = hadoop_20190221150303_86874b16-b4c6-<span class="number">4e6</span>d-a2e6-c1a02aaae3b8</span><br><span class="line">Total jobs = <span class="number">3</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">3</span></span><br><span class="line">Number of reduce tasks is set to <span class="number">0</span> since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1535945194143_1282, Tracking URL = http://wh-8-211:8088/proxy/application_1535945194143_1282/</span></span><br><span class="line"><span class="string">Kill Command = /app/opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/lib/hadoop/bin/hadoop job  -kill job_1535945194143_1282</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2019-02-21 15:03:27,069 Stage-1 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2019-02-21 15:03:35,527 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 4.98 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 4 seconds 980 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1535945194143_1282</span></span><br><span class="line"><span class="string">Stage-4 is selected by condition resolver.</span></span><br><span class="line"><span class="string">Stage-3 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Stage-5 is filtered out by condition resolver.</span></span><br><span class="line"><span class="string">Moving data to: hdfs://sdg/user/hive/warehouse/dw.db/analyze_parquet_test/part_date=2019-02-19/.hive-staging_hive_2019-02-21_15-03-17_975_7489031492557604858-1/-ext-10000</span></span><br><span class="line"><span class="string">Loading data to table dw.analyze_parquet_test partition (part_date=2019-02-19)</span></span><br><span class="line"><span class="string">Partition dw.analyze_parquet_test&#123;part_date=2019-02-19&#125; stats: [numFiles=1, numRows=20, totalSize=390, rawDataSize=40]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-1: Map: 1   Cumulative CPU: 4.98 sec   HDFS Read: 4039 HDFS Write: 490 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 4 seconds 980 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 22.794 seconds</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_parquet_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-19'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_parquet_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">19</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">20</span>, totalSize=<span class="number">390</span>, rawDataSize=<span class="number">40</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.226</span> seconds</span><br></pre></td></tr></table></figure><p><code>stats: [numFiles=1, numRows=20, totalSize=390, rawDataSize=40]</code></p><h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p>通过上述测试可以看出,OrcFile文件的三种数据导入方式可以直接通过ANALYZE获取完整信息，其他文件格式默认只能获取到Size，除非<code>insert into</code>触发了<code>MapReduce</code>时才能获取RowCount</p><p>ANALYZE耗时非常短，文件的统计数据一定是存储在某个地方不需要RunTime去计算<code>（查询了Hive MetaStore，并没有发现表Row的统计存储）</code>，猜想原因在于OrcFile的自描述Header里存储了对Row的统计信息，ANALYZE会直接获取自描述文件中的统计信息，可以看下文件的Dump</p><h2 id="Hive-Orc-File-Dump"><a href="#Hive-Orc-File-Dump" class="headerlink" title="Hive Orc File Dump"></a>Hive Orc File Dump</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC" target="_blank" rel="noopener">Hive Orc Doc</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Orc Dump</span></span><br><span class="line"></span><br><span class="line">hive --orcfiledump hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_orc_test/part_date=2019-02-19/000000_0</span></span><br><span class="line"></span><br><span class="line"><span class="function">Java <span class="title">HotSpot</span><span class="params">(TM)</span> 64-Bit Server VM warning: ignoring option MaxPermSize</span>=<span class="number">512</span>M; support was removed in <span class="number">8.0</span></span><br><span class="line"><span class="function">Java <span class="title">HotSpot</span><span class="params">(TM)</span> 64-Bit Server VM warning: ignoring option MaxPermSize</span>=<span class="number">512</span>M; support was removed in <span class="number">8.0</span></span><br><span class="line">Structure <span class="keyword">for</span> hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_orc_test/part_date=2019-02-19/000000_0</span></span><br><span class="line">File Version: <span class="number">0.12</span> with HIVE_8732</span><br><span class="line"><span class="number">19</span>/<span class="number">02</span>/<span class="number">21</span> <span class="number">15</span>:<span class="number">54</span>:<span class="number">02</span> INFO orc.ReaderImpl: Reading ORC rows from hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_orc_test/part_date=2019-02-19/000000_0 with &#123;include: null, offset: 0, length: 9223372036854775807&#125;</span></span><br><span class="line">Rows: <span class="number">20</span></span><br><span class="line">Compression: ZLIB</span><br><span class="line">Compression size: <span class="number">262144</span></span><br><span class="line">Type: struct&lt;_col0:string,_col1:string&gt;</span><br><span class="line"></span><br><span class="line">Stripe Statistics:</span><br><span class="line">  Stripe <span class="number">1</span>:</span><br><span class="line">    Column <span class="number">0</span>: count: <span class="number">20</span> hasNull: <span class="keyword">false</span></span><br><span class="line">    Column <span class="number">1</span>: count: <span class="number">20</span> hasNull: <span class="keyword">false</span> min: <span class="number">1</span> max: <span class="number">2</span> sum: <span class="number">20</span></span><br><span class="line">    Column <span class="number">2</span>: count: <span class="number">20</span> hasNull: <span class="keyword">false</span> min: wxmimperio1 max: wxmimperio2 sum: <span class="number">220</span></span><br><span class="line"></span><br><span class="line">File Statistics:</span><br><span class="line">  Column <span class="number">0</span>: count: <span class="number">20</span> hasNull: <span class="keyword">false</span></span><br><span class="line">  Column <span class="number">1</span>: count: <span class="number">20</span> hasNull: <span class="keyword">false</span> min: <span class="number">1</span> max: <span class="number">2</span> sum: <span class="number">20</span></span><br><span class="line">  Column <span class="number">2</span>: count: <span class="number">20</span> hasNull: <span class="keyword">false</span> min: wxmimperio1 max: wxmimperio2 sum: <span class="number">220</span></span><br><span class="line"></span><br><span class="line">Stripes:</span><br><span class="line">  Stripe: offset: <span class="number">3</span> data: <span class="number">52</span> rows: <span class="number">20</span> tail: <span class="number">57</span> index: <span class="number">77</span></span><br><span class="line">    Stream: column <span class="number">0</span> section ROW_INDEX start: <span class="number">3</span> length <span class="number">11</span></span><br><span class="line">    Stream: column <span class="number">1</span> section ROW_INDEX start: <span class="number">14</span> length <span class="number">26</span></span><br><span class="line">    Stream: column <span class="number">2</span> section ROW_INDEX start: <span class="number">40</span> length <span class="number">40</span></span><br><span class="line">    Stream: column <span class="number">1</span> section DATA start: <span class="number">80</span> length <span class="number">8</span></span><br><span class="line">    Stream: column <span class="number">1</span> section LENGTH start: <span class="number">88</span> length <span class="number">6</span></span><br><span class="line">    Stream: column <span class="number">1</span> section DICTIONARY_DATA start: <span class="number">94</span> length <span class="number">5</span></span><br><span class="line">    Stream: column <span class="number">2</span> section DATA start: <span class="number">99</span> length <span class="number">8</span></span><br><span class="line">    Stream: column <span class="number">2</span> section LENGTH start: <span class="number">107</span> length <span class="number">6</span></span><br><span class="line">    Stream: column <span class="number">2</span> section DICTIONARY_DATA start: <span class="number">113</span> length <span class="number">19</span></span><br><span class="line">    Encoding column <span class="number">0</span>: DIRECT</span><br><span class="line">    Encoding column <span class="number">1</span>: DICTIONARY_V2[<span class="number">2</span>]</span><br><span class="line">    Encoding column <span class="number">2</span>: DICTIONARY_V2[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">File length: <span class="number">365</span> bytes</span><br><span class="line">Padding length: <span class="number">0</span> bytes</span><br><span class="line">Padding ratio: <span class="number">0</span>%</span><br></pre></td></tr></table></figure><p><code>可以看到Dump信息里面有Rows: 20的信息，所以可以确定ANALYZE 命令是分析了file的meta</code></p><h2 id="Parquet-File-Dump"><a href="#Parquet-File-Dump" class="headerlink" title="Parquet File Dump"></a>Parquet File Dump</h2><p><a href="https://github.com/apache/parquet-mr/tree/master/parquet-tools" target="_blank" rel="noopener">Parquet Tools</a></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar parquet-tools-<span class="number">1.5</span>.0.jar dump hdfs:<span class="comment">//sdg/user/hive/warehouse/dw.db/analyze_parquet_test/part_date=2019-02-19/000000_0</span></span><br><span class="line"></span><br><span class="line">row group <span class="number">0</span> </span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">id:    BINARY UNCOMPRESSED DO:<span class="number">0</span> FPO:<span class="number">4</span> SZ:<span class="number">61</span>/<span class="number">61</span>/<span class="number">1.00</span> VC:<span class="number">20</span> ENC:BIT_PACK [more]...</span><br><span class="line">name:  BINARY UNCOMPRESSED DO:<span class="number">0</span> FPO:<span class="number">65</span> SZ:<span class="number">101</span>/<span class="number">101</span>/<span class="number">1.00</span> VC:<span class="number">20</span> ENC:BIT_P [more]...</span><br><span class="line"></span><br><span class="line">    id TV=<span class="number">20</span> RL=<span class="number">0</span> DL=<span class="number">1</span> DS:   <span class="number">2</span> DE:PLAIN_DICTIONARY</span><br><span class="line">    ----------------------------------------------------------------------------</span><br><span class="line">    page <span class="number">0</span>:                   DLE:RLE RLE:BIT_PACKED VLE:PLAIN_DICTIONARY SZ:<span class="number">11</span> [more]...</span><br><span class="line"></span><br><span class="line">    name TV=<span class="number">20</span> RL=<span class="number">0</span> DL=<span class="number">1</span> DS: <span class="number">2</span> DE:PLAIN_DICTIONARY</span><br><span class="line">    ----------------------------------------------------------------------------</span><br><span class="line">    page <span class="number">0</span>:                   DLE:RLE RLE:BIT_PACKED VLE:PLAIN_DICTIONARY SZ:<span class="number">11</span> [more]...</span><br><span class="line"></span><br><span class="line">BINARY id </span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">*** row group <span class="number">1</span> of <span class="number">1</span>, values <span class="number">1</span> to <span class="number">20</span> *** </span><br><span class="line">value <span class="number">1</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">2</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">3</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">4</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">5</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">6</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">7</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">8</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">9</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">10</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">11</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">12</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">13</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">14</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">15</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">16</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">17</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">18</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line">value <span class="number">19</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">1</span></span><br><span class="line">value <span class="number">20</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:<span class="number">2</span></span><br><span class="line"></span><br><span class="line">BINARY name </span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">*** row group <span class="number">1</span> of <span class="number">1</span>, values <span class="number">1</span> to <span class="number">20</span> *** </span><br><span class="line">value <span class="number">1</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">2</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">3</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">4</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">5</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">6</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">7</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">8</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">9</span>:  R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">10</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">11</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">12</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">13</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">14</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">15</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">16</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">17</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">18</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br><span class="line">value <span class="number">19</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio1</span><br><span class="line">value <span class="number">20</span>: R:<span class="number">0</span> D:<span class="number">1</span> V:wxmimperio2</span><br></pre></td></tr></table></figure><p><code>虽然看到Dump文件中有TV=20，但是不像ORC File 有完整的Row信息，meta还是基于列的，所以读取不到</code></p><h2 id="MapReduce-统计"><a href="#MapReduce-统计" class="headerlink" title="MapReduce 统计"></a>MapReduce 统计</h2><blockquote><p>我们想要获取完整的表统计信息，可以将<code>ANALYZE</code>命令的<code>noscan</code>去掉执行，则会触发一个MapReduce，这个MR会对表文件做一个统计，并将结果存储到Hive MetaStore中，后续在用<code>ANALYZE</code>分析就会直接得到结果</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_parquet_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span> COMPUTE STATISTICS</span>;</span><br><span class="line"></span><br><span class="line">Query ID = hadoop_20190221173030_d9cc4e9c-<span class="number">73f</span>6-<span class="number">403</span>e-bfbc-c3cf381b373d</span><br><span class="line">Total jobs = <span class="number">1</span></span><br><span class="line">Launching Job <span class="number">1</span> out of <span class="number">1</span></span><br><span class="line">Number of reduce tasks is set to <span class="number">0</span> since there<span class="string">'s no reduce operator</span></span><br><span class="line"><span class="string">Starting Job = job_1535945194143_1284, Tracking URL = http://wh-8-211:8088/proxy/application_1535945194143_1284/</span></span><br><span class="line"><span class="string">Kill Command = /app/opt/cloudera/parcels/CDH-5.11.1-1.cdh5.11.1.p0.4/lib/hadoop/bin/hadoop job  -kill job_1535945194143_1284</span></span><br><span class="line"><span class="string">Hadoop job information for Stage-0: number of mappers: 1; number of reducers: 0</span></span><br><span class="line"><span class="string">2019-02-21 17:30:54,865 Stage-0 map = 0%,  reduce = 0%</span></span><br><span class="line"><span class="string">2019-02-21 17:31:02,248 Stage-0 map = 100%,  reduce = 0%, Cumulative CPU 4.21 sec</span></span><br><span class="line"><span class="string">MapReduce Total cumulative CPU time: 4 seconds 210 msec</span></span><br><span class="line"><span class="string">Ended Job = job_1535945194143_1284</span></span><br><span class="line"><span class="string">Partition dw.analyze_parquet_test&#123;part_date=2019-02-21&#125; stats: [numFiles=1, numRows=20, totalSize=390, rawDataSize=60]</span></span><br><span class="line"><span class="string">MapReduce Jobs Launched: </span></span><br><span class="line"><span class="string">Stage-Stage-0: Map: 1   Cumulative CPU: 4.21 sec   HDFS Read: 2931 HDFS Write: 100 SUCCESS</span></span><br><span class="line"><span class="string">Total MapReduce CPU Time Spent: 4 seconds 210 msec</span></span><br><span class="line"><span class="string">OK</span></span><br><span class="line"><span class="string">Time taken: 21.214 seconds</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; <span class="function">ANALYZE TABLE analyze_parquet_test <span class="title">PARTITION</span><span class="params">(part_date=<span class="string">'2019-02-21'</span>)</span> COMPUTE STATISTICS noscan</span>;</span><br><span class="line"></span><br><span class="line">Partition dw.analyze_parquet_test&#123;part_date=<span class="number">2019</span>-<span class="number">02</span>-<span class="number">21</span>&#125; stats: [numFiles=<span class="number">1</span>, numRows=<span class="number">20</span>, totalSize=<span class="number">390</span>, rawDataSize=<span class="number">60</span>]</span><br><span class="line">OK</span><br><span class="line">Time taken: <span class="number">0.219</span> seconds</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们可以看到利用<code>ANALYZE</code>命令可以快速帮助我们分析一张表的基本统计信息，但也有缺点：<code>如果是分区表，写分区则会列出这个分区的统计，不写分区会列出所有分区的数据列表；并没有一个队整张表进行的汇总统计</code>，所以通常需要配合最开始提到的两种常用方法</p><p>对于OrcFile则直接可以用<code>ANALYZE</code>命令分析，如果是TextFile、SequenceFile、ParquetFile，则需要确保Hive 表的数据加载方式是通过MapReduce，其他方式Load数据的则需要执行<code>noscan 的ANALYZE（可以准备离线任务，每天对非MR Load的数据表执行一次）；也可以在执行ETL的时候，将统计作为一个回调自动完成</code></p><ul><li>Size</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> size = FileSystem.getContentSummary(<span class="keyword">new</span> Path(tablePath)).getLength();</span><br></pre></td></tr></table></figure><p><code>此方法可以获取一个表路径、分区路径以及具体文件的Size大小；Size是压缩后的值</code></p><p><code>全表的统计可以将tablePath截止到tableName就可以，获取某个分区的统计，则tablePath精确到分区目录</code></p><ul><li>RowCount</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ANALYZE TABLE tablName [PARTITION(part)] COMPUTE STATISTICS noscan;</span><br></pre></td></tr></table></figure><p><code>此方法会列出所有表的分区统计，解析这些统计并将numRows加总就是全表的RowCount；如果是非分区表或只想获取当前分区的统计，则只解析一条记录</code></p><hr><blockquote><p>转载请注明出处：<a href="https://github.com/imperio-wxm" target="_blank" rel="noopener">https://github.com/imperio-wxm</a></p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在Hadoop平台运维监控中，Hive表的统计信息通常是作为集群数据质量的关键依据；通常以Hive表的大小、行数、分区数等信息来衡量集群数据量的增减趋势；本文以Hive表Size大小和数据行数作为重点，对于超大表统计时避免过多的资源消耗&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="Hive" scheme="http://imperio-wxm.github.io/categories/BigData/Hive/"/>
    
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Hive" scheme="http://imperio-wxm.github.io/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot-Java8Date</title>
    <link href="http://imperio-wxm.github.io/2019/02/19/SpringBoot-Java8Date/"/>
    <id>http://imperio-wxm.github.io/2019/02/19/SpringBoot-Java8Date/</id>
    <published>2019-02-19T12:52:12.000Z</published>
    <updated>2019-02-19T16:09:37.358Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在SpringBoot和Feign使用Java8的Date类型，如LocalDate、LocalDateTime，会出现Format不符合常规的情况</p></blockquote><a id="more"></a><table><thead><tr><th>Software</th><th>Version</th></tr></thead><tbody><tr><td>SpringBoot</td><td>1.5.13.RELEASE</td></tr><tr><td>Java</td><td>1.8.0_201</td></tr></tbody></table><h1 id="默认时间格式显示"><a href="#默认时间格式显示" class="headerlink" title="默认时间格式显示"></a>默认时间格式显示</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DefaultTimeBean</span></span><br><span class="line"><span class="keyword">private</span> LocalDate localDate;</span><br><span class="line"><span class="keyword">private</span> LocalDateTime localDateTime;</span><br><span class="line"><span class="keyword">private</span> LocalTime localTime;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">DefaultTimeBean</span><span class="params">(LocalDate localDate, LocalDateTime localDateTime, LocalTime localTime)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.localDate = localDate;</span><br><span class="line">    <span class="keyword">this</span>.localDateTime = localDateTime;</span><br><span class="line">    <span class="keyword">this</span>.localTime = localTime;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// getter and setter</span></span><br></pre></td></tr></table></figure><ul><li>通过Rest获取</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/getDefaultJava8Time"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> DefaultTimeBean <span class="title">getDefaultJava8Time</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> DefaultTimeBean(LocalDate.now(), LocalDateTime.now(), LocalTime.now());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>结果</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 全部是以数组的形式返回，这不符合我们的开发规范，要在序列化/反序列化的时候就进行formart</span></span><br><span class="line">&#123;</span><br><span class="line">localDate: [<span class="number">2019</span>, <span class="number">2</span>, <span class="number">19</span>],</span><br><span class="line">localDateTime: [<span class="number">2019</span>, <span class="number">2</span>, <span class="number">19</span>, <span class="number">15</span>, <span class="number">49</span>, <span class="number">10</span>, <span class="number">964000000</span>],</span><br><span class="line">localTime: [<span class="number">15</span>, <span class="number">49</span>, <span class="number">10</span>, <span class="number">964000000</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="格式化时间显示"><a href="#格式化时间显示" class="headerlink" title="格式化时间显示"></a>格式化时间显示</h1><ul><li>Maven</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 不需要写version</span></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.fasterxml.jackson.datatype&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jackson-datatype-jsr310&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><ul><li>application.yml</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  jackson:</span><br><span class="line">    serialization:</span><br><span class="line">      WRITE_DATES_AS_TIMESTAMPS: <span class="keyword">false</span></span><br></pre></td></tr></table></figure><ul><li>注解配置format规则</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// TimeBean</span></span><br><span class="line"><span class="meta">@DateTimeFormat</span>(iso = DateTimeFormat.ISO.DATE)</span><br><span class="line"><span class="keyword">private</span> LocalDate localDate;</span><br><span class="line"></span><br><span class="line"><span class="meta">@DateTimeFormat</span>(pattern = <span class="string">"yyyy-MM-dd HH:mm:ss"</span>)</span><br><span class="line"><span class="meta">@JsonFormat</span>(pattern = <span class="string">"yyyy-MM-dd HH:mm:ss"</span>)</span><br><span class="line"><span class="keyword">private</span> LocalDateTime localDateTime;</span><br><span class="line"></span><br><span class="line"><span class="meta">@JsonFormat</span>(pattern = <span class="string">"HH:mm:ss"</span>)</span><br><span class="line"><span class="meta">@DateTimeFormat</span>(iso = DateTimeFormat.ISO.TIME)</span><br><span class="line"><span class="keyword">private</span> LocalTime localTime;</span><br></pre></td></tr></table></figure><ul><li>通过Rest获取</li></ul><blockquote><p>Get</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/getFormatJava8Time"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> TimeBean <span class="title">getFormatJava8Time</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> TimeBean(LocalDate.now(), LocalDateTime.now(), LocalTime.now());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>结果</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    localDate: <span class="string">"2019-02-19"</span>,</span><br><span class="line">    localDateTime: <span class="string">"2019-02-19 15:57:08"</span>,</span><br><span class="line">    localTime: <span class="string">"15:57:08"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Post</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@PostMapping</span>(<span class="string">"/formatJava8Time"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> TimeBean <span class="title">postDateTime</span><span class="params">(@RequestBody TimeBean timeBean)</span> </span>&#123;</span><br><span class="line">System.out.println(timeBean.getLocalDate());</span><br><span class="line">System.out.println(timeBean.getLocalDateTime());</span><br><span class="line">System.out.println(timeBean.getLocalTime());</span><br><span class="line"><span class="keyword">return</span> timeBean;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>结果</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"localDate"</span>: <span class="string">"2019-05-02"</span>,</span><br><span class="line">    <span class="string">"localDateTime"</span>: <span class="string">"2019-06-15 12:23:59"</span>,</span><br><span class="line">    <span class="string">"localTime"</span>: <span class="string">"15:12:23"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><blockquote><p>转载请注明出处</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在SpringBoot和Feign使用Java8的Date类型，如LocalDate、LocalDateTime，会出现Format不符合常规的情况&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="SpringBoot" scheme="http://imperio-wxm.github.io/categories/SpringBoot/"/>
    
      <category term="Java" scheme="http://imperio-wxm.github.io/categories/SpringBoot/Java/"/>
    
    
      <category term="Java" scheme="http://imperio-wxm.github.io/tags/Java/"/>
    
      <category term="SpringBoot" scheme="http://imperio-wxm.github.io/tags/SpringBoot/"/>
    
  </entry>
  
  <entry>
    <title>Cassandra集群运维[Add &amp; Remove Nodes]</title>
    <link href="http://imperio-wxm.github.io/2018/10/20/Cassandra-Cluster-Operation/"/>
    <id>http://imperio-wxm.github.io/2018/10/20/Cassandra-Cluster-Operation/</id>
    <published>2018-10-20T14:47:36.000Z</published>
    <updated>2018-10-20T15:09:15.940Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在对Cassandra进行维护的时候，通常需要扩集群或者迁移数据，涉及到添加、移除节点。</p></blockquote><a id="more"></a><blockquote><p>Cassandra Version: Apache Cassandra 3.0.6</p></blockquote><h1 id="Add-Nodes"><a href="#Add-Nodes" class="headerlink" title="Add Nodes"></a>Add Nodes</h1><p>Virtual nodes (vnodes) greatly simplify adding nodes to an existing cluster:<br>Calculating tokens and assigning them to each node is no longer required.<br>Rebalancing a cluster is no longer necessary because a node joining the cluster assumes responsibility for an even portion of the data.</p><blockquote><p style="color:red">确保新加节点和现有集群的Cassandra 版本一致</p></blockquote><hr><h2 id="【操作步骤】"><a href="#【操作步骤】" class="headerlink" title="【操作步骤】"></a>【操作步骤】</h2><h3 id="在新的机器上部署cassandra，但不要启动"><a href="#在新的机器上部署cassandra，但不要启动" class="headerlink" title="在新的机器上部署cassandra，但不要启动"></a>在新的机器上部署cassandra，但不要启动</h3><p>通常都是从现有集群的一台机器上scp cassandra目录到新机器</p><h3 id="基于现有集群所用的snitch算法修改配置文件"><a href="#基于现有集群所用的snitch算法修改配置文件" class="headerlink" title="基于现有集群所用的snitch算法修改配置文件"></a>基于现有集群所用的<code>snitch</code>算法修改配置文件</h3><blockquote><p style="color:blue">cassandra-topology.properties or the cassandra-rackdc.properties</p></blockquote><ul><li>使用<code>PropertyFileSnitch</code>算法配置：cassandra-topology.properties</li><li>使用<code>GossipingPropertyFileSnitch</code>, <code>Ec2Snitch</code>, <code>Ec2MultiRegionSnitch</code>, and <code>GoogleCloudSnitch</code>算法配置：cassandra-rackdc.properties</li></ul><blockquote><p>ps: 这两个配置与机架和多数据中心有关，如果是同机架单数据中心则不用配置</p></blockquote><h3 id="修改配置cassandra-yaml文件"><a href="#修改配置cassandra-yaml文件" class="headerlink" title="修改配置cassandra.yaml文件"></a>修改配置<code>cassandra.yaml</code>文件</h3><table><thead><tr><th style="text-align:left">name</th><th>desc</th></tr></thead><tbody><tr><td style="text-align:left">auto_bootstrap</td><td>默认文件中是没有这个参数的，如果没有默认为true；如果有且为false修改为true</td></tr><tr><td style="text-align:left">cluster_name</td><td>需要加入的集群名称</td></tr><tr><td style="text-align:left">listen_address/broadcast_address</td><td>用来与集群内其他节点通信的ip，通常为本机真实ip，不要填写127.0.0.1或localhost</td></tr><tr><td style="text-align:left">endpoint_snitch</td><td>用于定位节点和路由请求的算法，与现有集群保持一致</td></tr><tr><td style="text-align:left">num_tokens</td><td>节点中vnodes的数量，与现有集群配置保持一致，如果当前机器配置更高可以按比例增加这个值，可以有更好的性能</td></tr><tr><td style="text-align:left">seed_provider</td><td>种子节点，至少保证有一个现有集群的节点，-seeds列表表示了新节点与现有集群通过哪些节点通信（种子节点无法引导，所以不要仅仅把要加入的新节点配置进去，也不要将集群所有节点配置成种子节点）</td></tr></tbody></table><h3 id="启动新节点Cassandra"><a href="#启动新节点Cassandra" class="headerlink" title="启动新节点Cassandra"></a>启动新节点Cassandra</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/cassandra</span><br></pre></td></tr></table></figure><ul><li>初始化system相关信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">INFO  06:14:41 Initializing system.IndexInfo</span><br><span class="line">INFO  06:14:42 Initializing system.batches</span><br><span class="line">INFO  06:14:42 Initializing system.paxos</span><br><span class="line">INFO  06:14:42 Initializing system.local</span><br><span class="line">INFO  06:14:42 Initializing system.peers</span><br><span class="line">INFO  06:14:42 Initializing system.peer_events</span><br><span class="line">INFO  06:14:42 Initializing system.range_xfers</span><br><span class="line">INFO  06:14:42 Initializing system.compaction_history</span><br><span class="line">INFO  06:14:42 Initializing system.sstable_activity</span><br><span class="line">INFO  06:14:42 Initializing system.size_estimates</span><br><span class="line">INFO  06:14:42 Initializing system.available_ranges</span><br><span class="line">INFO  06:14:42 Initializing system.views_builds_in_progress</span><br><span class="line">INFO  06:14:42 Initializing system.built_views</span><br><span class="line">INFO  06:14:42 Initializing system.hints</span><br><span class="line">INFO  06:14:42 Initializing system.batchlog</span><br><span class="line">......</span><br></pre></td></tr></table></figure><ul><li>寻找现有集群节点</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">INFO  06:14:44 Node /xx.xxx.xx.xx is now part of the cluster</span><br><span class="line">INFO  06:14:44 Node /xx.xxx.xx.xx is now part of the cluster</span><br><span class="line">INFO  06:14:44 Node /xx.xxx.xx.xx is now part of the cluster</span><br><span class="line">INFO  06:14:44 Handshaking version with /xx.xxx.xx.xx</span><br><span class="line">INFO  06:14:44 Handshaking version with /xx.xxx.xx.xx</span><br><span class="line">INFO  06:14:44 InetAddress /xx.xxx.xx.xx is now UP</span><br><span class="line">INFO  06:14:44 InetAddress /xx.xxx.xx.xx is now UP</span><br><span class="line">INFO  06:14:44 InetAddress /xx.xxx.xx.xx is now UP</span><br></pre></td></tr></table></figure><ul><li>新节点加入集群</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INFO  06:14:45 JOINING: waiting for ring information</span><br><span class="line">INFO  06:14:45 Updating topology for all endpoints that have changed</span><br></pre></td></tr></table></figure><ul><li>同步schema</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INFO  06:14:49 Initializing system_traces.events</span><br><span class="line">INFO  06:14:49 Initializing system_traces.sessions</span><br><span class="line">INFO  06:14:49 Initializing system_distributed.parent_repair_history</span><br><span class="line">INFO  06:14:49 Initializing system_distributed.repair_history</span><br><span class="line">INFO  06:14:49 Initializing system_auth.resource_role_permissons_index</span><br><span class="line">INFO  06:14:49 Initializing system_auth.role_members</span><br><span class="line">INFO  06:14:49 Initializing system_auth.role_permissions</span><br><span class="line">INFO  06:14:49 Initializing system_auth.roles</span><br><span class="line">INFO  06:14:49 JOINING: waiting for schema information to complete</span><br></pre></td></tr></table></figure><ul><li>Copy Schema数据</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] Executing streaming plan for Bootstrap</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] Starting streaming to /xx.xxx.xx.xx</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] Starting streaming to /xx.xxx.xx.xx</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] Starting streaming to /xx.xxx.xx.xx</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4, ID#0] Beginning stream session with /xx.xxx.xx.xx</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4, ID#0] Beginning stream session with /xx.xxx.xx.xx</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4, ID#0] Beginning stream session with /xx.xxx.xx.xx</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4 ID#0] Prepare completed. Receiving 48 files(358160851 bytes), sending 0 files(0 bytes)</span><br><span class="line">INFO  06:15:22 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4 ID#0] Prepare completed. Receiving 35 files(132483825 bytes), sending 0 files(0 bytes)</span><br><span class="line">INFO  06:15:23 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4 ID#0] Prepare completed. Receiving 46 files(174538642 bytes), sending 0 files(0 bytes)</span><br><span class="line">INFO  06:16:54 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] Session with /xx.xxx.xx.xx is complete</span><br><span class="line">INFO  06:17:38 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] Session with /xx.xxx.xx.xx is complete</span><br><span class="line">INFO  06:20:28 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] Session with /xx.xxx.xx.xx is complete</span><br><span class="line">INFO  06:20:28 [Stream #317a30b0-d29d-11e8-aa92-e9ebc9b827d4] All sessions completed</span><br></pre></td></tr></table></figure><ul><li>节点切换成NORMAL</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">INFO  06:20:29 Node /xx.xxx.xx.xx state jump to NORMAL</span><br><span class="line">INFO  06:20:29 Waiting for gossip to settle before accepting client requests...</span><br></pre></td></tr></table></figure><h3 id="查看节点同步状态"><a href="#查看节点同步状态" class="headerlink" title="查看节点同步状态"></a>查看节点同步状态</h3><blockquote><p>./bin/nodetool status</p></blockquote><ul><li>数据同步期间节点的状态：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Datacenter: dc1</span><br><span class="line">===============</span><br><span class="line">Status=Up/Down</span><br><span class="line">|/ State=Normal/Leaving/Joining/Moving</span><br><span class="line">--  Address       Load       Tokens       Owns (effective)  Host ID                               Rack</span><br><span class="line">UN  xx.xxx.xx.xx  1.53 GB    256          100.0%            30ed942d-6827-469b-aab9-7fb649c6c3d7  rack1</span><br><span class="line">UN  xx.xxx.xx.xx  1.38 GB    256          100.0%            96736106-e95d-4c54-aabf-41666071bc59  rack1</span><br><span class="line">UN  xx.xxx.xx.xx  1.07 GB    256          100.0%            4351af17-2e68-4b46-a78f-fad900e44d13  rack1</span><br><span class="line">UJ  新加节点      57.87 MB   256          ?                 f3f590ac-9835-47bb-b4d8-6e17ea2916ac  rack1</span><br></pre></td></tr></table></figure><ul><li>数据同步结束后的状态：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Datacenter: dc1</span><br><span class="line">===============</span><br><span class="line">Status=Up/Down</span><br><span class="line">|/ State=Normal/Leaving/Joining/Moving</span><br><span class="line">--  Address       Load       Tokens       Owns (effective)  Host ID                               Rack</span><br><span class="line">UN  xx.xxx.xx.xx  1.53 GB    256          69.2%             30ed942d-6827-469b-aab9-7fb649c6c3d7  rack1</span><br><span class="line">UN  xx.xxx.xx.xx  1.38 GB    256          79.3%             96736106-e95d-4c54-aabf-41666071bc59  rack1</span><br><span class="line">UN  xx.xxx.xx.xx  1.07 GB    256          78.0%             4351af17-2e68-4b46-a78f-fad900e44d13  rack1</span><br><span class="line">UN  xx.xxx.xx.xx  581.43 MB  256          73.5%             f3f590ac-9835-47bb-b4d8-6e17ea2916ac  rack1</span><br></pre></td></tr></table></figure><h3 id="运行nodetool-cleanup"><a href="#运行nodetool-cleanup" class="headerlink" title="运行nodetool cleanup"></a>运行nodetool cleanup</h3><blockquote><p>nodetool options cleanup [keyspace_name [table_name] […] ]</p></blockquote><p>在所有新节点都加入集群并且数据同步完成后，在之前旧的每一个节点上运行nodetool cleanup操作删除keys。<br>在做操作时保证一个节点结束后再运行下一个节点，不要并发执行，这样可以安全地推迟清理</p><hr><h1 id="Reomve-Nodes"><a href="#Reomve-Nodes" class="headerlink" title="Reomve Nodes"></a>Reomve Nodes</h1><h2 id="UN状态的节点下线"><a href="#UN状态的节点下线" class="headerlink" title="UN状态的节点下线"></a>UN状态的节点下线</h2><p>在要下线的节点运行<code>nodetool decommission</code>命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nodetool &lt;options&gt; decommission</span><br></pre></td></tr></table></figure><p>该命令会将当前节点的range和请求交给其他节点管理，并且将数据同步给其他节点</p><h2 id="DN状态的节点下线"><a href="#DN状态的节点下线" class="headerlink" title="DN状态的节点下线"></a>DN状态的节点下线</h2><p>在任何存活的节点运行<code>nodetool removenode</code>命令</p><p>该命令会将当前集群下线的节点移除，并且将数据同步给其他节点</p><ul><li>查看节点状态：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Datacenter: DC1</span><br><span class="line">===============</span><br><span class="line">Status=Up/Down</span><br><span class="line">|/ State=Normal/Leaving/Joining/Moving</span><br><span class="line">--  <span class="function">Address        Load       Tokens  <span class="title">Owns</span> <span class="params">(effective)</span>  Host ID                               Rack</span></span><br><span class="line"><span class="function">UN  192.168.2.101  112.82 KB  256     31.7%             420129fc-0d84-42b0-be41-ef7dd3a8ad06  RAC1</span></span><br><span class="line"><span class="function">DN  192.168.2.103  91.11 KB   256     33.9%             d0844a21-3698-4883-ab66-9e2fd5150edd  RAC1</span></span><br><span class="line"><span class="function">UN  192.168.2.102  124.42 KB  256     32.6%             8d5ed9f4-7764-4dbd-bad8-43fddce94b7c  RAC1</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> nodetool &lt;options&gt; removenode -- &lt;status&gt; | &lt;force&gt; | &lt;ID&gt;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span> nodetool removenode d0844a21-3698-4883-ab66-9e2fd5150edd</span><br></pre></td></tr></table></figure><h2 id="节点下线失败"><a href="#节点下线失败" class="headerlink" title="节点下线失败"></a>节点下线失败</h2><blockquote><p> nodetool assassinate</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nodetool [options] assassinate &lt;ip_address&gt;</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nodetool -u cassandra -pw cassandra assassinate 192.168.100.2</span><br></pre></td></tr></table></figure><hr><blockquote><p>转载请注明出处</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在对Cassandra进行维护的时候，通常需要扩集群或者迁移数据，涉及到添加、移除节点。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="Cassandra" scheme="http://imperio-wxm.github.io/categories/BigData/Cassandra/"/>
    
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/tags/Linux/"/>
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Cassandra" scheme="http://imperio-wxm.github.io/tags/Cassandra/"/>
    
  </entry>
  
  <entry>
    <title>记一次HBase Drop的错误</title>
    <link href="http://imperio-wxm.github.io/2018/09/24/HBase-DropTable-Error/"/>
    <id>http://imperio-wxm.github.io/2018/09/24/HBase-DropTable-Error/</id>
    <published>2018-09-24T04:14:56.000Z</published>
    <updated>2018-09-24T04:26:06.988Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>hbsae表进行数据清洗，在清空数据的时候发生错误，引发后续问题</p></blockquote><a id="more"></a><p><code>HBase version: 1.2.0-cdh5.11.1</code></p><ul><li>HBase 清空数据</li></ul><ol><li>truncate ‘TableName’（清除数据，并且清除了分区）</li><li>truncate_preserve ‘TableName’（清除数据，不清除分区)</li></ol><p>由于我想保留分区，所以选择了 <code>truncate_preserve</code></p><h2 id="问题发生："><a href="#问题发生：" class="headerlink" title="问题发生："></a>问题发生：</h2><p>用hbase shell 执行truncate_preserve ‘TableName’，中途网络问题ssh突然断开连接</p><ul><li>shell显示：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Truncating <span class="string">'TableName'</span> table (it may take a <span class="keyword">while</span>):</span><br><span class="line"> - Disabling table...</span><br><span class="line"> - Truncating table...</span><br></pre></td></tr></table></figure><p>后重新连接ssh hbase shell，list 发现表名存在，但是scan、disable、drop命令都报Table not found</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ERROR: Table TableName does not exist.</span><br><span class="line"></span><br><span class="line">Start disable of named table:</span><br><span class="line">  hbase&gt; disable <span class="string">'t1'</span></span><br><span class="line">  hbase&gt; disable <span class="string">'ns1:t1'</span></span><br></pre></td></tr></table></figure><p>HBase Web UI 上也存在这张表，但是点进去有报错信息：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">org.apache.hadoop.hbase.client.HBaseAdmin.checkTableExistence(HBaseAdmin.java:<span class="number">1499</span>)</span><br><span class="line">org.apache.hadoop.hbase.client.HBaseAdmin.isTableEnabled(HBaseAdmin.java:<span class="number">1510</span>)</span><br><span class="line">org.apache.hadoop.hbase.generated.master.table_jsp._jspService(table_jsp.java:<span class="number">192</span>)</span><br><span class="line">org.apache.jasper.runtime.HttpJspBase.service(HttpJspBase.java:<span class="number">98</span>)</span><br><span class="line">javax.servlet.http.HttpServlet.service(HttpServlet.java:<span class="number">820</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:<span class="number">511</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:<span class="number">1221</span>)</span><br><span class="line">org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter.doFilter(StaticUserWebFilter.java:<span class="number">113</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:<span class="number">1212</span>)</span><br><span class="line">org.apache.hadoop.hbase.http.ClickjackingPreventionFilter.doFilter(ClickjackingPreventionFilter.java:<span class="number">48</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:<span class="number">1212</span>)</span><br><span class="line">org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter.doFilter(HttpServer.java:<span class="number">1354</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:<span class="number">1212</span>)</span><br><span class="line">org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:<span class="number">49</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:<span class="number">1212</span>)</span><br><span class="line">org.apache.hadoop.hbase.http.NoCacheFilter.doFilter(NoCacheFilter.java:<span class="number">49</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:<span class="number">1212</span>)</span><br><span class="line">org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:<span class="number">399</span>)</span><br><span class="line">org.mortbay.jetty.security.SecurityHandler.handle(SecurityHandler.java:<span class="number">216</span>)</span><br><span class="line">org.mortbay.jetty.servlet.SessionHandler.handle(SessionHandler.java:<span class="number">182</span>)</span><br><span class="line">org.mortbay.jetty.handler.ContextHandler.handle(ContextHandler.java:<span class="number">767</span>)</span><br><span class="line">org.mortbay.jetty.webapp.WebAppContext.handle(WebAppContext.java:<span class="number">450</span>)</span><br><span class="line">org.mortbay.jetty.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:<span class="number">230</span>)</span><br><span class="line">org.mortbay.jetty.handler.HandlerWrapper.handle(HandlerWrapper.java:<span class="number">152</span>)</span><br><span class="line">org.mortbay.jetty.Server.handle(Server.java:<span class="number">326</span>)</span><br><span class="line">org.mortbay.jetty.HttpConnection.handleRequest(HttpConnection.java:<span class="number">542</span>)</span><br><span class="line">org.mortbay.jetty.HttpConnection$RequestHandler.headerComplete(HttpConnection.java:<span class="number">928</span>)</span><br><span class="line">org.mortbay.jetty.HttpParser.parseNext(HttpParser.java:<span class="number">549</span>)</span><br><span class="line">org.mortbay.jetty.HttpParser.parseAvailable(HttpParser.java:<span class="number">212</span>)</span><br><span class="line">org.mortbay.jetty.HttpConnection.handle(HttpConnection.java:<span class="number">404</span>)</span><br><span class="line">org.mortbay.io.nio.SelectChannelEndPoint.run(SelectChannelEndPoint.java:<span class="number">410</span>)</span><br><span class="line">org.mortbay.thread.QueuedThreadPool$PoolThread.run(QueuedThreadPool.java:<span class="number">582</span>)</span><br></pre></td></tr></table></figure><h2 id="问题推断"><a href="#问题推断" class="headerlink" title="问题推断"></a>问题推断</h2><p>第一反应是这张表到底存不存在？</p><p>到HDFS上查看文件：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /hbase/data/<span class="keyword">default</span>/TableName</span><br></pre></td></tr></table></figure><blockquote><p>发现文件目录存在，但是里面没有任何文件，是空目录。推断可能是文件已经删掉了，但是缓存中或者zk中还是有这张表的信息，因为突然中止导致table meta没有生成</p></blockquote><h2 id="尝试恢复"><a href="#尝试恢复" class="headerlink" title="尝试恢复"></a>尝试恢复</h2><ul><li>snapshot 恢复（失败）</li></ul><p>因为这张表之前做过snapshot备份，想从snapshot恢复</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">clone_snapshot <span class="string">'TableName_Bak'</span>, <span class="string">'TableName'</span></span><br><span class="line">restore_snapshot <span class="string">'TableName_Bak'</span></span><br></pre></td></tr></table></figure><p>发现一只会卡在<code>restore_snapshot &#39;TableName_Bak&#39;</code>，应该是找不到这张表的meta</p><ul><li><p>hbck修复（失败）</p></li><li><p>想着通过meta修复，可以自动生成desc文件</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#修复 meta</span><br><span class="line">hbase hbck -fixMeta</span><br><span class="line"></span><br><span class="line">#重新分配rs</span><br><span class="line">hbase hbck -fixAssignments</span><br></pre></td></tr></table></figure><p>执行这两条语句后发现日志中均没有该表名，也没有任何异常，问题依旧</p><ul><li>zookeeper删除信息（成功）</li></ul><p>登录hbase zk：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">zkCli.sh</span><br><span class="line"></span><br><span class="line">ls /hbase/table</span><br><span class="line">rmr  /hbase/table/TableName 相关信息</span><br><span class="line"></span><br><span class="line">ls /hbase/table-lock</span><br><span class="line">rmr /hbase/table-lock/TableName 相关信息</span><br></pre></td></tr></table></figure><p>重启hbase 集群后这张表已经不存在，重新建表后正常</p><hr><blockquote><p>转载请注明出处</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;hbsae表进行数据清洗，在清空数据的时候发生错误，引发后续问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="HBase" scheme="http://imperio-wxm.github.io/categories/BigData/HBase/"/>
    
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/tags/Linux/"/>
    
      <category term="HBase" scheme="http://imperio-wxm.github.io/tags/HBase/"/>
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Struts2-Upgrade</title>
    <link href="http://imperio-wxm.github.io/2018/08/27/Struts2-Upgrade/"/>
    <id>http://imperio-wxm.github.io/2018/08/27/Struts2-Upgrade/</id>
    <published>2018-08-27T15:12:08.000Z</published>
    <updated>2018-08-27T15:57:23.675Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>遇到总结一下项目中有关Struts2升级中遇到的坑。项目大概开始于09年左右，维护近10年，由于Struts2安全漏洞问题决定升级版本，由于版本跨度比较大，一些方法已经弃用或配置变更等</p></blockquote><a id="more"></a><h2 id="Main-Maven-Dependency"><a href="#Main-Maven-Dependency" class="headerlink" title="Main Maven Dependency"></a>Main Maven Dependency</h2><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// old</span></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.struts&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;struts2-core&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.1.8.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">// new</span></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.struts&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;struts2-core&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.5.17&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="Struts2-xml"><a href="#Struts2-xml" class="headerlink" title="Struts2.xml"></a>Struts2.xml</h2><ul><li>old</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;filter&gt;</span><br><span class="line">    &lt;filter-name&gt;ActionContextCleanUp&lt;/filter-name&gt;</span><br><span class="line">    &lt;filter-<span class="class"><span class="keyword">class</span>&gt;<span class="title">org</span>.<span class="title">apache</span>.<span class="title">struts2</span>.<span class="title">dispatcher</span>.<span class="title">ActionContextCleanUp</span>&lt;/<span class="title">filter</span>-<span class="title">class</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">filter</span>&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&lt;<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">filter</span>-<span class="title">name</span>&gt;<span class="title">ActionContextCleanUp</span>&lt;/<span class="title">filter</span>-<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">url</span>-<span class="title">pattern</span>&gt;/*&lt;/<span class="title">url</span>-<span class="title">pattern</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&lt;<span class="title">filter</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">filter</span>-<span class="title">name</span>&gt;<span class="title">struts</span>&lt;/<span class="title">filter</span>-<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">filter</span>-<span class="title">class</span>&gt;<span class="title">org</span>.<span class="title">apache</span>.<span class="title">struts2</span>.<span class="title">dispatcher</span>.<span class="title">FilterDispatcher</span>&lt;/<span class="title">filter</span>-<span class="title">class</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">init</span>-<span class="title">param</span>&gt;</span></span><br><span class="line"><span class="class">        &lt;<span class="title">param</span>-<span class="title">name</span>&gt;<span class="title">struts</span>.<span class="title">i18n</span>.<span class="title">encoding</span>&lt;/<span class="title">param</span>-<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">        &lt;<span class="title">param</span>-<span class="title">value</span>&gt;<span class="title">UTF</span>-8&lt;/<span class="title">param</span>-<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;/<span class="title">init</span>-<span class="title">param</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">filter</span>&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&lt;<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">filter</span>-<span class="title">name</span>&gt;<span class="title">struts</span>&lt;/<span class="title">filter</span>-<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">url</span>-<span class="title">pattern</span>&gt;*.<span class="title">action</span>&lt;/<span class="title">url</span>-<span class="title">pattern</span>&gt; </span></span><br><span class="line"><span class="class">&lt;/<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>new </li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;filter&gt;</span><br><span class="line">    &lt;filter-name&gt;struts2&lt;/filter-name&gt;</span><br><span class="line">    &lt;filter-<span class="class"><span class="keyword">class</span>&gt;<span class="title">org</span>.<span class="title">apache</span>.<span class="title">struts2</span>.<span class="title">dispatcher</span>.<span class="title">filter</span>.<span class="title">StrutsPrepareAndExecuteFilter</span>&lt;/<span class="title">filter</span>-<span class="title">class</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">init</span>-<span class="title">param</span>&gt;</span></span><br><span class="line"><span class="class">        &lt;<span class="title">param</span>-<span class="title">name</span>&gt;<span class="title">struts</span>.<span class="title">i18n</span>.<span class="title">encoding</span>&lt;/<span class="title">param</span>-<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">        &lt;<span class="title">param</span>-<span class="title">value</span>&gt;<span class="title">UTF</span>-8&lt;/<span class="title">param</span>-<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;/<span class="title">init</span>-<span class="title">param</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">filter</span>&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&lt;<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">filter</span>-<span class="title">name</span>&gt;<span class="title">struts2</span>&lt;/<span class="title">filter</span>-<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">url</span>-<span class="title">pattern</span>&gt;*.<span class="title">action</span>&lt;/<span class="title">url</span>-<span class="title">pattern</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&lt;<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">filter</span>-<span class="title">name</span>&gt;<span class="title">struts2</span>&lt;/<span class="title">filter</span>-<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">url</span>-<span class="title">pattern</span>&gt;/<span class="title">project</span>/*&lt;/<span class="title">url</span>-<span class="title">pattern</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">filter</span>-<span class="title">mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><blockquote><p>在Struts2 2.5.17中<code>org.apache.struts2.dispatcher.FilterDispatcher</code> 和 <code>org.apache.struts2.dispatcher.ActionContextCleanUp</code> 被废除，用 <code>org.apache.struts2.dispatcher.filter.StrutsPrepareAndExecuteFilter</code> 替换</p></blockquote><h2 id="升级过程中遇到的报错："><a href="#升级过程中遇到的报错：" class="headerlink" title="升级过程中遇到的报错："></a>升级过程中遇到的报错：</h2><blockquote><p>java.lang.NoSuchMethodError: ognl.SimpleNode.isEvalChain(Lognl/OgnlContext;)Z</p></blockquote><ul><li>问题：<code>ognl</code> 的jar包冲突</li></ul><p>需要查询项目中Jar依赖关系，排除无用Jar包。Ognl版本至少在<code>3.0.6</code>以上</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 我遇到的是xwork中有低版本的ognl包，故排除</span></span><br><span class="line">&lt;exclusion&gt;</span><br><span class="line">    &lt;artifactId&gt;ognl&lt;/artifactId&gt;</span><br><span class="line">    &lt;groupId&gt;opensymphony&lt;/groupId&gt;</span><br><span class="line">&lt;/exclusion&gt;</span><br></pre></td></tr></table></figure><blockquote><p>There is no Action mapped for namespace [/] and action name [user!add] associated with context path</p></blockquote><ul><li>问题：由于2.5.17安全机制，过滤器必须指定mapped规则</li></ul><ol><li>粗粒度—动态方法调用</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// struts.xml配置添加</span></span><br><span class="line"> &lt;struts&gt;</span><br><span class="line">    &lt;constant name=<span class="string">"struts.enable.DynamicMethodInvocation"</span> value=<span class="string">"true"</span>/&gt;</span><br><span class="line">    ......</span><br><span class="line">    &lt;<span class="keyword">package</span> name=<span class="string">"default"</span> extends=<span class="string">"struts-default"</span>&gt;</span><br><span class="line">        ......</span><br><span class="line">        &lt;global-allowed-methods&gt;regex:.*&lt;/global-allowed-methods&gt;</span><br><span class="line">        ......</span><br><span class="line">    &lt;/package&gt;</span><br><span class="line">&lt;/struts&gt;</span><br></pre></td></tr></table></figure><ol><li>细粒度-动态方法调用</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// action配置</span></span><br><span class="line"></span><br><span class="line"> &lt;action name=<span class="string">"login_*"</span> method=<span class="string">"&#123;2&#125;"</span>  <span class="class"><span class="keyword">class</span></span>=<span class="string">"com.wxmimperio.struts.&#123;1&#125;Action"</span>&gt; </span><br><span class="line">    .......</span><br><span class="line">    &lt;result name="success"&gt;/pages/success.jsp&lt;/result&gt; </span><br><span class="line">    &lt;result name="error"&gt;/pages/error.jsp&lt;/result&gt; </span><br><span class="line">    ......</span><br><span class="line">    &lt;allowed-methods&gt;regex:.*&lt;/allowed-methods&gt;</span><br><span class="line">    ......</span><br><span class="line">&lt;/action&gt;</span><br></pre></td></tr></table></figure><p>这里在action的name中通配了一个login_*，它对应映射的是method属性。如果在客户端发生一个这样的请 求：login_init.action、login_show.action等，这时服务器就会自动调用这个action中的init()方法或 show()方法。这里的method=”{1}”代表是第一个星号，如果有多个星号，就要根据顺序来通配{1},{2},{3}….</p><p><code>allowed-methods</code>中可以用逗号分隔指定方法名，也可以用正则匹配。</p><blockquote><p>错误： Struts2 与 Servlet 冲突</p></blockquote><p>表现在当struts.xml如下配置：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;filter-mapping&gt;</span><br><span class="line">    &lt;filter-name&gt;struts&lt;/filter-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;<span class="comment">/*&lt;/url-pattern&gt;</span></span><br><span class="line"><span class="comment">&lt;/filter-mapping&gt;</span></span><br></pre></td></tr></table></figure><p>struts拦截器会拦截/*下所有路径，所以自定义的servlet无法被mapped到，导致请求根本无法响应</p><p>解决方案如下：</p><ol><li>修改servlet的相关配置，统一在servlet后面加上.servlet</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;servlet&gt;  </span><br><span class="line">    &lt;servlet-name&gt;jqueryAjaxServlet&lt;/servlet-name&gt;  </span><br><span class="line">    &lt;servlet-<span class="class"><span class="keyword">class</span>&gt;<span class="title">com</span>.<span class="title">clzhang</span>.<span class="title">sample</span>.<span class="title">struts2</span>.<span class="title">servlet</span>.<span class="title">jQueryAjaxServlet</span>&lt;/<span class="title">servlet</span>-<span class="title">class</span>&gt;  </span></span><br><span class="line"><span class="class">&lt;/<span class="title">servlet</span>&gt; </span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">&lt;<span class="title">servlet</span>-<span class="title">mapping</span>&gt;  </span></span><br><span class="line"><span class="class">    &lt;<span class="title">servlet</span>-<span class="title">name</span>&gt;<span class="title">jqueryAjaxServlet</span>&lt;/<span class="title">servlet</span>-<span class="title">name</span>&gt;  </span></span><br><span class="line"><span class="class">    &lt;<span class="title">url</span>-<span class="title">pattern</span>&gt;/<span class="title">servlet</span>/<span class="title">jqueryAjax</span>.<span class="title">servlet</span>&lt;/<span class="title">url</span>-<span class="title">pattern</span>&gt;  </span></span><br><span class="line"><span class="class">&lt;/<span class="title">servlet</span>-<span class="title">mapping</span>&gt;</span></span><br></pre></td></tr></table></figure><ol><li>修改拦截页面配置，就是将struts的相关拦截配置一下</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;filter-mapping&gt;</span><br><span class="line">    &lt;filter-name&gt;struts2&lt;/filter-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;*.action&lt;/url-pattern&gt;</span><br><span class="line">&lt;/filter-mapping&gt;</span><br><span class="line">&lt;filter-mapping&gt;</span><br><span class="line">    &lt;filter-name&gt;struts2&lt;/filter-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;</span><br><span class="line">&lt;/filter-mapping&gt;</span><br><span class="line">&lt;filter-mapping&gt;</span><br><span class="line">    &lt;filter-name&gt;struts2&lt;/filter-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;*.jsp&lt;/url-pattern&gt;</span><br><span class="line">&lt;/filter-mapping&gt;</span><br><span class="line">&lt;filter-mapping&gt;</span><br><span class="line">    &lt;filter-name&gt;struts2&lt;/filter-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;/user<span class="comment">/*&lt;/url-pattern&gt;</span></span><br><span class="line"><span class="comment">&lt;/filter-mapping&gt;</span></span><br></pre></td></tr></table></figure><ol><li>修改struts.xml文件中的后缀映射</li></ol><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;constant name="struts.action.extension" value="action"&gt;&lt;/constant&gt;</span><br></pre></td></tr></table></figure><hr><blockquote><p>转载请注明出处</p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;遇到总结一下项目中有关Struts2升级中遇到的坑。项目大概开始于09年左右，维护近10年，由于Struts2安全漏洞问题决定升级版本，由于版本跨度比较大，一些方法已经弃用或配置变更等&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Java" scheme="http://imperio-wxm.github.io/categories/Java/"/>
    
      <category term="Struts2" scheme="http://imperio-wxm.github.io/categories/Java/Struts2/"/>
    
    
      <category term="Java" scheme="http://imperio-wxm.github.io/tags/Java/"/>
    
      <category term="Web" scheme="http://imperio-wxm.github.io/tags/Web/"/>
    
      <category term="Struts2" scheme="http://imperio-wxm.github.io/tags/Struts2/"/>
    
  </entry>
  
  <entry>
    <title>pinpoint-plugin[插件开发指南]</title>
    <link href="http://imperio-wxm.github.io/2018/07/08/pinpoint-plugin-developer-guide/"/>
    <id>http://imperio-wxm.github.io/2018/07/08/pinpoint-plugin-developer-guide/</id>
    <published>2018-07-08T07:09:48.000Z</published>
    <updated>2018-07-18T14:09:18.870Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>You can write Pinpoint profiler plugins to extend profiling target coverage. It is highly advisable to look into the trace data recorded by pinpoint plugins before jumping into plugin development.</p></blockquote><a id="more"></a><h1 id="Trace-Data"><a href="#Trace-Data" class="headerlink" title="Trace Data"></a>Trace Data</h1><p>在Pinpoint中，一个 transaction 由一组 Spans 组成，每个Span表示transaction在单个逻辑节点的足迹</p><p>When a request arrives at the FrontEnd server, Pinpoint Agent generates a new transaction id and creates a Span with it.</p><p>当一个新的请求到达，Pinpoint Agent将会生成一个新的transaction id，并且创建一个Span</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;You can write Pinpoint profiler plugins to extend profiling target coverage. It is highly advisable to look into the trace data recorded by pinpoint plugins before jumping into plugin development.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="MicroService" scheme="http://imperio-wxm.github.io/categories/BigData/MicroService/"/>
    
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="监控" scheme="http://imperio-wxm.github.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="微服务" scheme="http://imperio-wxm.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>PinPoint-Deploy[部署]</title>
    <link href="http://imperio-wxm.github.io/2018/06/30/pinpoint-deploy/"/>
    <id>http://imperio-wxm.github.io/2018/06/30/pinpoint-deploy/</id>
    <published>2018-06-30T12:54:58.000Z</published>
    <updated>2018-07-04T16:24:07.736Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Pinpoint is an APM (Application Performance Management) tool for large-scale distributed systems written in Java.</p></blockquote><a id="more"></a><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><ul><li>架构图</li></ul><p><img src="http://naver.github.io/pinpoint/images/pinpoint-architecture.png" alt="架构图"></p><p>组件：</p><ul><li><p>pinpoint-collector-1.7.3.war （数据收集）</p></li><li><p>pinpoint-web-1.7.3.war （页面展示）</p></li><li><p>pinpoint-agent-1.7.3.tar.gz （数据采集）</p></li></ul><p>所需环境</p><p><a href="http://naver.github.io/pinpoint/installation.html#quick-overview-of-installation" target="_blank" rel="noopener">版本适配信息</a></p><ul><li>Tomcat-8.5.32（web container）</li><li>Hbase-1.2.6 （for storage）</li></ul><h2 id="部署步骤"><a href="#部署步骤" class="headerlink" title="部署步骤"></a>部署步骤</h2><ol><li><p>安装HBase</p><ul><li>创建监控所需的HBase 表</li></ul></li><li><p>下载最新PinPoint执行文件（或自行git clone —&gt; maven build）</p><ul><li>The current stable version is v1.7.3.</li><li><a href="https://github.com/naver/pinpoint/releases/tag/1.7.3" target="_blank" rel="noopener">DownLoad</a></li></ul></li><li><p>部署 Pinpoint Collector</p><ul><li>解压 <code>pinpoint-collector-$VERSION.war</code> 到 <code>Tomcat</code> 容器</li><li>修改 <code>pinpoint-collector.properties</code>, <code>hbase.properties</code> 文件</li></ul></li><li><p>部署 Pinpoint Web </p><ul><li>解压 <code>pinpoint-web-$VERSION.war</code> 到 <code>Tomcat</code> 容器</li><li>修改 <code>pinpoint-web</code>, <code>hbase.properties</code> 文件</li></ul></li><li><p>启动Tomcat</p></li><li><p>部署 Pinpoint Agent</p><ul><li>解压 pinpoint-agent 压缩包</li><li>设置 <code>-javaagent:$AGENT_PATH/pinpoint-bootstrap-$VERSION.jar</code> JVM参数到 App Jar 启动参数</li><li>设置 <code>-Dpinpoint.agentId</code> and <code>-Dpinpoint.applicationName</code> 到 App Jar 启动参数</li><li>启动Java App</li></ul></li></ol><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><ul><li>Tomcat 两个webapp实例</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">&lt;Service name="Catalina1"&gt;</span><br><span class="line">    &lt;Connector port="8081" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt;</span><br><span class="line">    &lt;Engine name="Catalina1" defaultHost="localhost"&gt;</span><br><span class="line">      &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt;</span><br><span class="line">        &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt;</span><br><span class="line">      &lt;/Realm&gt;</span><br><span class="line">      &lt;Host name="localhost"  appBase="/home/wxmimperio/software/apache-tomcat-8.5.32/pinpoint-web" unpackWARs="true" autoDeploy="true"&gt;</span><br><span class="line">        &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;</span><br><span class="line">      &lt;/Host&gt;</span><br><span class="line">    &lt;/Engine&gt;</span><br><span class="line">  &lt;/Service&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;Service name="Catalina2"&gt;</span><br><span class="line">    &lt;Connector port="8082" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt;  </span><br><span class="line">    &lt;Engine name="Catalina2" defaultHost="localhost"&gt;</span><br><span class="line">      &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt;</span><br><span class="line">        &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt;</span><br><span class="line">      &lt;/Realm&gt;</span><br><span class="line">      &lt;Host name="localhost"  appBase="/home/wxmimperio/software/apache-tomcat-8.5.32/pinpoint-collector" unpackWARs="true" autoDeploy="true"&gt;</span><br><span class="line">        &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt;</span><br><span class="line">      &lt;/Host&gt;</span><br><span class="line">    &lt;/Engine&gt;</span><br><span class="line">  &lt;/Service&gt;</span><br><span class="line">......</span><br></pre></td></tr></table></figure><ul><li>初始化Hbase 监控表</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> https://github.com/naver/pinpoint/blob/master/hbase/scripts/hbase-create.hbase</span><br><span class="line"></span><br><span class="line">vim hbase-create.hbase</span><br><span class="line"></span><br><span class="line">hbase shell hbase-create.hbase</span><br></pre></td></tr></table></figure><ul><li>pinpoint-web</li></ul><p>解压war，修改配置文件：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> unzip pinpoint-web-1.7.3.war -d pinpoint-web-1.7.3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> /apache-tomcat-8.5.32/pinpoint-web/pinpoint-web-1.7.3/WEB-INF/classes</span><br><span class="line"></span><br><span class="line">vim hbase.properties</span><br><span class="line"><span class="meta">#</span> 设置hbase地址</span><br><span class="line">hbase.client.host=192.168.1.110</span><br><span class="line">hbase.client.port=2181</span><br><span class="line"></span><br><span class="line">vim pinpoint-web.properties</span><br><span class="line"><span class="meta">#</span> 关闭集群模式</span><br><span class="line">cluster.enable=false</span><br></pre></td></tr></table></figure><ul><li>pinpoint-collector</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> unzip pinpoint-collector-1.7.3.war -d pinpoint-collector-1.7.3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> /apache-tomcat-8.5.32/pinpoint-collector/pinpoint-collector-1.7.3/WEB-INF/classes</span><br><span class="line"></span><br><span class="line">vim hbase.properties</span><br><span class="line"><span class="meta">#</span> 设置hbase地址</span><br><span class="line">hbase.client.host=192.168.1.110</span><br><span class="line">hbase.client.port=2181</span><br><span class="line"></span><br><span class="line">vim pinpoint-collector.properties</span><br><span class="line"><span class="meta">#</span> 关闭集群模式</span><br><span class="line">cluster.enable=false</span><br></pre></td></tr></table></figure><ul><li>重启Tomcat</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./startup.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> http://192.168.1.110:8081/pinpoint-web-1.7.3/#/main</span><br></pre></td></tr></table></figure><ul><li>部署应用</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -javaagent:/home/wxmimperio/software/pinpoint/pinpoint-agent-1.7.3/pinpoint-bootstrap-1.7.3.jar -Dpinpoint.agentId=wxm-consumer -Dpinpoint.applicationName=wxm-consumer -jar spring-boot-test-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><p><img src="http://naver.github.io/pinpoint/images/ss_server-map.png" alt="应用拓扑"></p><p><img src="http://naver.github.io/pinpoint/images/ss_call-stack.png" alt="应用Trace"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Pinpoint is an APM (Application Performance Management) tool for large-scale distributed systems written in Java.&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="MicroService" scheme="http://imperio-wxm.github.io/categories/BigData/MicroService/"/>
    
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="监控" scheme="http://imperio-wxm.github.io/tags/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="微服务" scheme="http://imperio-wxm.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>Avro-介绍</title>
    <link href="http://imperio-wxm.github.io/2018/05/27/agamotto-avro-overview/"/>
    <id>http://imperio-wxm.github.io/2018/05/27/agamotto-avro-overview/</id>
    <published>2018-05-27T03:27:02.000Z</published>
    <updated>2018-06-30T13:01:49.684Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Apache Avro 是一个与语言无关的序列化工具，由Hadoop之父Doug Cutting开发。通过Avro读写数据文件无需生成代码，也不需要使用或实现RPC协议,使用JSON格式来自描述数据结构。支持Java、C、C++、C＃、Python和Ruby等语言。</p></blockquote><a id="more"></a><h1 id="Avro-Schema"><a href="#Avro-Schema" class="headerlink" title="Avro Schema"></a>Avro Schema</h1><ul><li><p>Avro依赖于Schema，使得序列化速度很快，并且生成的序列化数据较小。当写入数据的时候，Schema结构与Avro数据一起存储在数据文件中以供进一步处理。</p></li><li><p>在RPC中使用Avro，client和server连接时进行Schema交换，无论是client端还是server端都有完整的schema定义，这样使得命名相同的字段、缺失的字段、额外的字段等之间的对应关系可以进行同步及处理。</p></li><li><p>Avro模式使用Json定义，这有助于在已经有Json库的语言中实现。与Avro一样，Hadoop中还有其他序列化机制，例如Sequence Files、Protocol Buffers和Thrift.</p></li><li><p>Avro是一种可压缩和可拆分的二进制结构化格式，用来支持数据密集型应用，适合于远程或本地大规模数据的存储和交换，可以进行纯数据的发送和接收</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Schema样例</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"type"</span>: <span class="string">"record"</span>,</span><br><span class="line">    <span class="string">"name"</span>: <span class="string">"Employee"</span>,</span><br><span class="line">    <span class="string">"fields"</span>: [</span><br><span class="line">        &#123;<span class="string">"name"</span>: <span class="string">"name"</span>, <span class="string">"type"</span>: <span class="string">"string"</span>&#125;,</span><br><span class="line">        &#123;<span class="string">"name"</span>: <span class="string">"age"</span>, <span class="string">"type"</span>: <span class="string">"int"</span>&#125;,</span><br><span class="line">        &#123;<span class="string">"name"</span>: <span class="string">"emails"</span>, <span class="string">"type"</span>: &#123;<span class="string">"type"</span>: <span class="string">"array"</span>, <span class="string">"items"</span>: <span class="string">"string"</span>&#125;&#125;,</span><br><span class="line">        &#123;<span class="string">"name"</span>: <span class="string">"boss"</span>, <span class="string">"type"</span>: [<span class="string">"Employee"</span>,<span class="string">"null"</span>]&#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Thrift-amp-Protocol-Buffers-对比-Avro"><a href="#Thrift-amp-Protocol-Buffers-对比-Avro" class="headerlink" title="Thrift &amp; Protocol Buffers 对比 Avro"></a>Thrift &amp; Protocol Buffers 对比 Avro</h1><ul><li><p>Avro同时支持动态和静态类型，而Protocol Buffers和Thrift使用接口定义语言（IDL）来指定数据结构及其类型，同时还需要使用定义好的数据机构和类型来序列化和反序列化代码。</p></li><li><p>Avro以Hadoop生态环境为基础，建立在Hadoop中，可以很好的与MapReduce Job进行结合；而Protocol Buffers和Thrift脱离Hadoop生态。</p></li></ul><h1 id="Avro使用步骤"><a href="#Avro使用步骤" class="headerlink" title="Avro使用步骤"></a>Avro使用步骤</h1><ol><li><p>创建Schema——根据数据格式要求创建符合Json规范的Schema文件</p></li><li><p>读取Schema文件——在程序中读取Schema文件，进行初始化（两种方式）</p><ul><li>Avro编译模式，使用Avro-Tools生成带有Schema的实体类</li><li>Avro解析器模式，可以引入Avro的相关以来，通过代码解析的方式解析Schema文件</li></ul></li><li><p>使用Avro提供的序列化API对数据进行序列化</p></li><li><p>使用Avro提供的反序列化API对数据进行反序列化</p></li></ol><hr><blockquote><p>转载请注明出处：<a href="https://github.com/imperio-wxm" target="_blank" rel="noopener">https://github.com/imperio-wxm</a></p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Apache Avro 是一个与语言无关的序列化工具，由Hadoop之父Doug Cutting开发。通过Avro读写数据文件无需生成代码，也不需要使用或实现RPC协议,使用JSON格式来自描述数据结构。支持Java、C、C++、C＃、Python和Ruby等语言。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="Avro" scheme="http://imperio-wxm.github.io/categories/BigData/Avro/"/>
    
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/tags/Linux/"/>
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Avro" scheme="http://imperio-wxm.github.io/tags/Avro/"/>
    
  </entry>
  
  <entry>
    <title>Java自定义线程池ThreadPoolExecutor</title>
    <link href="http://imperio-wxm.github.io/2018/01/28/Custom-ThreadPool/"/>
    <id>http://imperio-wxm.github.io/2018/01/28/Custom-ThreadPool/</id>
    <published>2018-01-28T07:32:50.000Z</published>
    <updated>2018-06-30T13:01:49.646Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>为了提高性能和充分利用系统资源，通常会选择使用多线程技术。然而线程的启动、销毁成本是比较高的，线程之间的切换也会消耗大量的JVM资源，所以线程池的出现是为了更好管理和调度线程的一种方式，和连接池和对象池的初衷一样，在有空闲资源的前提下，让现有资源充分重复利用，避免不必要的开销。</p></blockquote><p>线程池的好处：</p><ul><li><p>降低资源消耗</p></li><li><p>提高响应速度</p></li><li><p>增强线程的管理</p></li></ul><a id="more"></a><hr><h1 id="自带线程池概述"><a href="#自带线程池概述" class="headerlink" title="自带线程池概述"></a>自带线程池概述</h1><blockquote><p>JDK已经实现了4个经典线程池</p></blockquote><h2 id="Executors-newCacheThreadPool"><a href="#Executors-newCacheThreadPool" class="headerlink" title="Executors.newCacheThreadPool()"></a>Executors.newCacheThreadPool()</h2><blockquote><p>可缓存线程池——先检查线程池中是否有已经创建且空闲的线程，如果有直接使用，否则创建一个新的线程加入线程池并启动</p></blockquote><ul><li><p>Worker线程的数据量没有限制——Interger.MAX_VALUE</p></li><li><p>Worker默认的生命周期为1min，即当线程池中线程空闲时间超过1min，此线程会被自动销毁，当有新的任务进来时重新建立线程</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a thread pool that creates new threads as needed, but</span></span><br><span class="line"><span class="comment"> * will reuse previously constructed threads when they are</span></span><br><span class="line"><span class="comment"> * available.  These pools will typically improve the performance</span></span><br><span class="line"><span class="comment"> * of programs that execute many short-lived asynchronous tasks.</span></span><br><span class="line"><span class="comment"> * Calls to &#123;<span class="doctag">@code</span> execute&#125; will reuse previously constructed</span></span><br><span class="line"><span class="comment"> * threads if available. If no existing thread is available, a new</span></span><br><span class="line"><span class="comment"> * thread will be created and added to the pool. Threads that have</span></span><br><span class="line"><span class="comment"> * not been used for sixty seconds are terminated and removed from</span></span><br><span class="line"><span class="comment"> * the cache. Thus, a pool that remains idle for long enough will</span></span><br><span class="line"><span class="comment"> * not consume any resources. Note that pools with similar</span></span><br><span class="line"><span class="comment"> * properties but different details (for example, timeout parameters)</span></span><br><span class="line"><span class="comment"> * may be created using &#123;<span class="doctag">@link</span> ThreadPoolExecutor&#125; constructors.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> the newly created thread pool</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newCachedThreadPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(</span><br><span class="line">        <span class="number">0</span>, </span><br><span class="line">        Integer.MAX_VALUE,</span><br><span class="line">        <span class="number">60L</span>, </span><br><span class="line">        TimeUnit.SECONDS,</span><br><span class="line">        <span class="keyword">new</span> SynchronousQueue&lt;Runnable&gt;()</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Executors-newFixedThreadPool"><a href="#Executors-newFixedThreadPool" class="headerlink" title="Executors.newFixedThreadPool()"></a>Executors.newFixedThreadPool()</h2><blockquote><p>可控Worker数量的线程池，此线程池中有一个<code>无界队列</code>，当提交的Worker数量大于设定值n时，提交的线程不会立刻启动，而是放到队列中；当n中某些线程执行结束，队列中的线程才得以执行</p><p>从源码中得知，<code>newFixedThreadPool</code>用的是<code>LinkedBlockingQueue</code>，此队列是一个基于<code>链表结构</code>的阻塞队列，此队列按<code>FIFO</code>原则存储元素</p><p style="color:PaleVioletRed">在线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源，即始终会保留设定值n个线程在线程池中</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a thread pool that reuses a fixed number of threads</span></span><br><span class="line"><span class="comment"> * operating off a shared unbounded queue.  At any point, at most</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@code</span> nThreads&#125; threads will be active processing tasks.</span></span><br><span class="line"><span class="comment"> * If additional tasks are submitted when all threads are active,</span></span><br><span class="line"><span class="comment"> * they will wait in the queue until a thread is available.</span></span><br><span class="line"><span class="comment"> * If any thread terminates due to a failure during execution</span></span><br><span class="line"><span class="comment"> * prior to shutdown, a new one will take its place if needed to</span></span><br><span class="line"><span class="comment"> * execute subsequent tasks.  The threads in the pool will exist</span></span><br><span class="line"><span class="comment"> * until it is explicitly &#123;<span class="doctag">@link</span> ExecutorService#shutdown shutdown&#125;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> nThreads the number of threads in the pool</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> the newly created thread pool</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IllegalArgumentException if &#123;<span class="doctag">@code</span> nThreads &lt;= 0&#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newFixedThreadPool</span><span class="params">(<span class="keyword">int</span> nThreads)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(</span><br><span class="line">        nThreads, </span><br><span class="line">        nThreads,</span><br><span class="line">        <span class="number">0L</span>, </span><br><span class="line">        TimeUnit.MILLISECONDS,</span><br><span class="line">        <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;()</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Executors-newScheduledThreadPool"><a href="#Executors-newScheduledThreadPool" class="headerlink" title="Executors.newScheduledThreadPool()"></a>Executors.newScheduledThreadPool()</h2><blockquote><p>创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行</p><p>看其源码构造方法中，有一个延迟队列<code>DelayedWorkQueue</code></p><p>JDK中定义：Delayed元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部是延迟期满后保存时间最长的Delayed元素。如果延迟都还没有期满，则队列没有头部，并且poll将返回null。当一个元素的 getDelay(TimeUnit.NANOSECONDS)方法返回一个小于等于0的值时，将发生到期。即使无法使用take或poll移除未到期的元素，也不会将这些元素作为正常元素对待。例如，size方法同时返回到期和未到期元素的计数。此队列不允许使用null元素。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a new &#123;<span class="doctag">@code</span> ScheduledThreadPoolExecutor&#125; with the</span></span><br><span class="line"><span class="comment"> * given core pool size.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> corePoolSize the number of threads to keep in the pool, even</span></span><br><span class="line"><span class="comment"> *        if they are idle, unless &#123;<span class="doctag">@code</span> allowCoreThreadTimeOut&#125; is set</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IllegalArgumentException if &#123;<span class="doctag">@code</span> corePoolSize &lt; 0&#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ScheduledThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, Integer.MAX_VALUE, <span class="number">0</span>, NANOSECONDS,<span class="keyword">new</span> DelayedWorkQueue());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这里的父类是</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates a new &#123;<span class="doctag">@code</span> ThreadPoolExecutor&#125; with the given initial</span></span><br><span class="line"><span class="comment"> * parameters and default rejected execution handler.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> corePoolSize the number of threads to keep in the pool, even</span></span><br><span class="line"><span class="comment"> *        if they are idle, unless &#123;<span class="doctag">@code</span> allowCoreThreadTimeOut&#125; is set</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> maximumPoolSize the maximum number of threads to allow in the</span></span><br><span class="line"><span class="comment"> *        pool</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> keepAliveTime when the number of threads is greater than</span></span><br><span class="line"><span class="comment"> *        the core, this is the maximum time that excess idle threads</span></span><br><span class="line"><span class="comment"> *        will wait for new tasks before terminating.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> unit the time unit for the &#123;<span class="doctag">@code</span> keepAliveTime&#125; argument</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> workQueue the queue to use for holding tasks before they are</span></span><br><span class="line"><span class="comment"> *        executed.  This queue will hold only the &#123;<span class="doctag">@code</span> Runnable&#125;</span></span><br><span class="line"><span class="comment"> *        tasks submitted by the &#123;<span class="doctag">@code</span> execute&#125; method.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> threadFactory the factory to use when the executor</span></span><br><span class="line"><span class="comment"> *        creates a new thread</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> IllegalArgumentException if one of the following holds:&lt;br&gt;</span></span><br><span class="line"><span class="comment"> *         &#123;<span class="doctag">@code</span> corePoolSize &lt; 0&#125;&lt;br&gt;</span></span><br><span class="line"><span class="comment"> *         &#123;<span class="doctag">@code</span> keepAliveTime &lt; 0&#125;&lt;br&gt;</span></span><br><span class="line"><span class="comment"> *         &#123;<span class="doctag">@code</span> maximumPoolSize &lt;= 0&#125;&lt;br&gt;</span></span><br><span class="line"><span class="comment"> *         &#123;<span class="doctag">@code</span> maximumPoolSize &lt; corePoolSize&#125;</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@throws</span> NullPointerException if &#123;<span class="doctag">@code</span> workQueue&#125;</span></span><br><span class="line"><span class="comment"> *         or &#123;<span class="doctag">@code</span> threadFactory&#125; is null</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> corePoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> maximumPoolSize,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">long</span> keepAliveTime,</span></span></span><br><span class="line"><span class="function"><span class="params">        TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">        BlockingQueue&lt;Runnable&gt; workQueue,</span></span></span><br><span class="line"><span class="function"><span class="params">        ThreadFactory threadFactory)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>(corePoolSize, maximumPoolSize, keepAliveTime,unit, workQueue,threadFactory, defaultHandler);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Executors-newSingleThreadExecutor"><a href="#Executors-newSingleThreadExecutor" class="headerlink" title="Executors.newSingleThreadExecutor()"></a>Executors.newSingleThreadExecutor()</h2><blockquote><p>单线程池，即提交到此线程池的线程只能用一个Worker线程去执行；保证所有任务按照指定顺序(FIFO, LIFO)执行；多应用于并发操作某类只能由一个线程处理的任务，例如多线程写多个不同的文件，每个线程对应于一个文件，但对于一个文件来说同一时刻只能由一个线程顺序去写。</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Creates an Executor that uses a single worker thread operating</span></span><br><span class="line"><span class="comment"> * off an unbounded queue. (Note however that if this single</span></span><br><span class="line"><span class="comment"> * thread terminates due to a failure during execution prior to</span></span><br><span class="line"><span class="comment"> * shutdown, a new one will take its place if needed to execute</span></span><br><span class="line"><span class="comment"> * subsequent tasks.)  Tasks are guaranteed to execute</span></span><br><span class="line"><span class="comment"> * sequentially, and no more than one task will be active at any</span></span><br><span class="line"><span class="comment"> * given time. Unlike the otherwise equivalent</span></span><br><span class="line"><span class="comment"> * &#123;<span class="doctag">@code</span> newFixedThreadPool(1)&#125; the returned executor is</span></span><br><span class="line"><span class="comment"> * guaranteed not to be reconfigurable to use additional threads.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> the newly created single-threaded Executor</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newSingleThreadExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> FinalizableDelegatedExecutorService(</span><br><span class="line">        <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">1</span>, <span class="number">1</span>, <span class="number">0L</span>, TimeUnit.MILLISECONDS, <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;()</span><br><span class="line">        )</span><br><span class="line">    );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="自定义线程池ThreadPoolExecutor"><a href="#自定义线程池ThreadPoolExecutor" class="headerlink" title="自定义线程池ThreadPoolExecutor"></a>自定义线程池ThreadPoolExecutor</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ThreadPoolExecutor(corePoolSize,maximumPoolSize,keepAliveTime,milliseconds,runnableTaskQueue,handler)</span><br></pre></td></tr></table></figure><p>【Params】:</p><ul><li><p><code>corePoolSize（线程池的基本大小-可运行Worker线程数量）</code>:当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads方法，线程池会提前创建并启动所有基本线程</p></li><li><p><code>runnableTaskQueue（任务队列）</code>：当线程超过corePoolSize设定的个数，会将线程先放到阻塞队列中不立刻执行<br>可以选择以下几个阻塞队列：</p></li></ul><blockquote><p>ArrayBlockingQueue：一个基于数组的有界阻塞队列，此队列按<code>FIFO</code>原则</p><p>LinkedBlockingQueue：一个基于链表的阻塞队列，此队列按<code>FIFO</code>原则，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列</p><p>SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于</p><p>LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列</p><p>PriorityBlockingQueue：一个具有优先级的无限阻塞队列</p></blockquote><ul><li><p><code>maximumPoolSize（线程池最大大小）</code>：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是如果使用了无界的任务队列这个参数就没什么效果</p></li><li><p><code>ThreadFactory</code>：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字</p></li><li><p><code>RejectedExecutionHandler（饱和策略）</code>：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。<br>这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。以下是JDK1.5提供的四种策略:</p></li></ul><blockquote><p>AbortPolicy：直接抛出异常<br>CallerRunsPolicy：只用调用者所在线程来运行任务<br>DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务<br>DiscardPolicy：不处理，丢弃掉</p></blockquote><p>当然也可以根据应用场景需要来实现RejectedExecutionHandler接口自定义策略。如记录日志或持久化不能处理的任务。<br>```</p><ul><li><p><code>keepAliveTime（线程活动保持时间）</code>：线程池的工作线程空闲后，保持存活的时间。所以如果任务很多，并且每个任务执行的时间比较短，可以调大这个时间，提高线程的利用率</p></li><li><p><code>TimeUnit（线程活动保持时间的单位）</code>：可选的单位有天（DAYS），小时（HOURS），分钟（MINUTES），毫秒(MILLISECONDS)，微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;为了提高性能和充分利用系统资源，通常会选择使用多线程技术。然而线程的启动、销毁成本是比较高的，线程之间的切换也会消耗大量的JVM资源，所以线程池的出现是为了更好管理和调度线程的一种方式，和连接池和对象池的初衷一样，在有空闲资源的前提下，让现有资源充分重复利用，避免不必要的开销。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;线程池的好处：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;降低资源消耗&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;提高响应速度&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;增强线程的管理&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Java" scheme="http://imperio-wxm.github.io/categories/Java/"/>
    
    
      <category term="Java" scheme="http://imperio-wxm.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Cassandra Install &amp; Deploy [安装部署]</title>
    <link href="http://imperio-wxm.github.io/2016/10/15/Cassandra-Install/"/>
    <id>http://imperio-wxm.github.io/2016/10/15/Cassandra-Install/</id>
    <published>2016-10-15T13:27:23.000Z</published>
    <updated>2018-06-30T13:01:49.643Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的可扩展性，被Digg、Twitter等知名Web 2.0网站所采纳，成为了一种流行的分布式结构化数据存储方案。</p></blockquote><a id="more"></a><hr><ul><li><p><a href="http://cassandra.apache.org/" target="_blank" rel="noopener">官网</a></p></li><li><p><a href="http://cassandra.apache.org/doc/latest/getting_started/index.html" target="_blank" rel="noopener">Documentation</a></p></li><li><p><a href="http://docs.datastax.com/en/landing_page/doc/landing_page/current.html" target="_blank" rel="noopener">Datastax</a></p></li><li><p><a href="https://github.com/datastax/" target="_blank" rel="noopener">Datastax Github</a></p></li></ul><hr><h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu Server 14.04 x64</span><br><span class="line">JDK 1.8+</span><br><span class="line">python 2.7.11+</span><br><span class="line">Cassandra 3.0.9</span><br><span class="line"></span><br><span class="line">server1: 192.168.1.110 seeds</span><br><span class="line">server2: 192.168.1.111 seeds</span><br><span class="line">server3: 192.168.1.112</span><br></pre></td></tr></table></figure><hr><h1 id="cassandra安装"><a href="#cassandra安装" class="headerlink" title="cassandra安装"></a>cassandra安装</h1><ul><li><a href="http://cassandra.apache.org/download/" target="_blank" rel="noopener">下载地址</a></li></ul><h2 id="修改cassandra-yaml配置文件"><a href="#修改cassandra-yaml配置文件" class="headerlink" title="修改cassandra.yaml配置文件"></a>修改cassandra.yaml配置文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每一个节点上新建数据目录</span></span><br><span class="line">mdkir cassandra-data</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改参数</span></span><br><span class="line"></span><br><span class="line">vim conf/cassandra.yaml</span><br><span class="line"></span><br><span class="line">cluster_name: <span class="string">'Cassandra Cluster'</span></span><br><span class="line"></span><br><span class="line">hints_directory: /home/wxmimperio/data/cassandra-data/hints</span><br><span class="line"></span><br><span class="line">data_file_directories:</span><br><span class="line">     - /home/wxmimperio/data/cassandra-data/data</span><br><span class="line"></span><br><span class="line">commitlog_directory: /home/wxmimperio/data/cassandra-data/commitlog</span><br><span class="line"></span><br><span class="line">saved_caches_directory: /home/wxmimperio/data/cassandra-data/saved_caches</span><br><span class="line"></span><br><span class="line">- seeds: <span class="string">"192.168.1.110,192.168.1.111"</span></span><br><span class="line"></span><br><span class="line">listen_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.110</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启thrift</span></span><br><span class="line">start_rpc: true</span><br><span class="line"></span><br><span class="line">rpc_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.110</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># batch 增加批量插入的一次插入量</span></span><br><span class="line">batch_size_warn_threshold_in_kb: <span class="number">150</span></span><br><span class="line"></span><br><span class="line">batch_size_fail_threshold_in_kb: <span class="number">1500</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点感知策略</span></span><br><span class="line">endpoint_snitch: GossipingPropertyFileSnitch</span><br></pre></td></tr></table></figure><h2 id="其他节点同步目录"><a href="#其他节点同步目录" class="headerlink" title="其他节点同步目录"></a>其他节点同步目录</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r apache-cassandra<span class="number">-3.0</span><span class="number">.9</span> wxmimperio@<span class="number">192.168</span><span class="number">.1</span><span class="number">.111</span>:/home/wxmimperio/software</span><br><span class="line"></span><br><span class="line">scp -r apache-cassandra<span class="number">-3.0</span><span class="number">.9</span> wxmimperio@<span class="number">192.168</span><span class="number">.1</span><span class="number">.112</span>:/home/wxmimperio/software</span><br></pre></td></tr></table></figure><h2 id="修改其他节点cassandra-yaml"><a href="#修改其他节点cassandra-yaml" class="headerlink" title="修改其他节点cassandra.yaml"></a>修改其他节点cassandra.yaml</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 192.168.1.111</span></span><br><span class="line">- seeds: <span class="string">"192.168.1.111,192.168.1.110"</span></span><br><span class="line">listen_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.111</span></span><br><span class="line">rpc_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.111</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 192.168.1.112</span></span><br><span class="line">- seeds: <span class="string">"192.168.1.111,192.168.1.110"</span></span><br><span class="line">listen_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.112</span></span><br><span class="line">rpc_address: <span class="number">192.168</span><span class="number">.1</span><span class="number">.112</span></span><br></pre></td></tr></table></figure><hr><h1 id="启动cassandra"><a href="#启动cassandra" class="headerlink" title="启动cassandra"></a>启动cassandra</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 每一个节点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 前台启动</span></span><br><span class="line">./bin/cassandra -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后台启动</span></span><br><span class="line">./bin/cassandra</span><br></pre></td></tr></table></figure><h2 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在任意节点运行</span></span><br><span class="line">./apache-cassandra<span class="number">-3.0</span><span class="number">.9</span>/bin/nodetool status</span><br><span class="line"></span><br><span class="line">--  Address        Load       Tokens       Owns (effective)  Host ID                               Rack</span><br><span class="line">UN  <span class="number">192.168</span><span class="number">.1</span><span class="number">.110</span>  <span class="number">91.9</span> KB    <span class="number">256</span>          <span class="number">65.5</span>%             <span class="number">7</span>ea5d945-fb2f<span class="number">-410</span>e-b03c-da8a1596d150  rack1</span><br><span class="line">UN  <span class="number">192.168</span><span class="number">.1</span><span class="number">.111</span>  <span class="number">112.05</span> KB  <span class="number">256</span>          <span class="number">67.2</span>%             da86d35a<span class="number">-9819</span><span class="number">-4</span>d33-a6df-c378c3872936  rack1</span><br><span class="line">UN  <span class="number">192.168</span><span class="number">.1</span><span class="number">.112</span>  <span class="number">150.97</span> KB  <span class="number">256</span>          <span class="number">67.3</span>%             a851446d-bb15<span class="number">-44</span>b6<span class="number">-9</span>b2e<span class="number">-33</span>fcf7076279  rack1</span><br></pre></td></tr></table></figure><hr><h1 id="CQL操作"><a href="#CQL操作" class="headerlink" title="CQL操作"></a>CQL操作</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./apache-cassandra<span class="number">-3.0</span><span class="number">.9</span>/bin/cqlsh  --request-timeout=<span class="number">500</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.110</span></span><br></pre></td></tr></table></figure><ul><li>创建Keyspace</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 多数据中心策略NetworkTopologyStrategy</span></span><br><span class="line"><span class="comment"># 副本因子2</span></span><br><span class="line">CREATE KEYSPACE IF NOT EXISTS cassandra_test WITH replication =  &#123;<span class="string">'class'</span> : <span class="string">'NetworkTopologyStrategy'</span>, <span class="string">'dc1'</span> : <span class="number">2</span>&#125;;</span><br></pre></td></tr></table></figure><ul><li>创建表</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># id、name 为组合primary key</span></span><br><span class="line"><span class="comment"># id 为 partition key</span></span><br><span class="line"><span class="comment"># name、password 为cluster key</span></span><br><span class="line">CREATE TABLE IF NOT EXISTS cassandra_test.user(id text, name text, password text,PRIMARY KEY (id,name)) WITH comment=<span class="string">'UserTable'</span>;</span><br></pre></td></tr></table></figure><ul><li>查看表结构</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">DESCRIBE TABLE cassandra_test.user;</span><br><span class="line"></span><br><span class="line">CREATE TABLE cassandra_test.user (</span><br><span class="line">    id text,</span><br><span class="line">    name text,</span><br><span class="line">    password text,</span><br><span class="line">    PRIMARY KEY (id, name)</span><br><span class="line">) WITH CLUSTERING ORDER BY (name ASC)</span><br><span class="line">    AND bloom_filter_fp_chance = <span class="number">0.01</span></span><br><span class="line">    AND caching = &#123;<span class="string">'keys'</span>: <span class="string">'ALL'</span>, <span class="string">'rows_per_partition'</span>: <span class="string">'NONE'</span>&#125;</span><br><span class="line">    AND comment = <span class="string">'UserTable'</span></span><br><span class="line">    AND compaction = &#123;<span class="string">'class'</span>: <span class="string">'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'</span>, <span class="string">'max_threshold'</span>: <span class="string">'32'</span>, <span class="string">'min_threshold'</span>: <span class="string">'4'</span>&#125;</span><br><span class="line">    AND compression = &#123;<span class="string">'chunk_length_in_kb'</span>: <span class="string">'64'</span>, <span class="string">'class'</span>: <span class="string">'org.apache.cassandra.io.compress.LZ4Compressor'</span>&#125;</span><br><span class="line">    AND crc_check_chance = <span class="number">1.0</span></span><br><span class="line">    AND dclocal_read_repair_chance = <span class="number">0.1</span></span><br><span class="line">    AND default_time_to_live = <span class="number">0</span></span><br><span class="line">    AND gc_grace_seconds = <span class="number">864000</span></span><br><span class="line">    AND max_index_interval = <span class="number">2048</span></span><br><span class="line">    AND memtable_flush_period_in_ms = <span class="number">0</span></span><br><span class="line">    AND min_index_interval = <span class="number">128</span></span><br><span class="line">    AND read_repair_chance = <span class="number">0.0</span></span><br><span class="line">    AND speculative_retry = <span class="string">'99PERCENTILE'</span>;</span><br></pre></td></tr></table></figure><ul><li>插入数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INSERT INTO cassandra_test.user(id,name,password) VALUES(<span class="string">'1'</span>,<span class="string">'wxmimperio'</span>,<span class="string">'123456'</span>);</span><br></pre></td></tr></table></figure><ul><li>查询数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM cassandra_test.user WHERE id = <span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line">id | name       | password</span><br><span class="line">----+------------+----------</span><br><span class="line"> <span class="number">1</span> | wxmimperio |   <span class="number">123456</span></span><br></pre></td></tr></table></figure><ul><li>更新数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">UPDATE cassandra_test.user SET password = <span class="string">'abcde'</span> WHERE id = <span class="string">'1'</span> AND name = <span class="string">'wxmimperio'</span>;</span><br><span class="line"></span><br><span class="line">SELECT * FROM cassandra_test.user WHERE id = <span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line">id | name       | password</span><br><span class="line">----+------------+----------</span><br><span class="line"> <span class="number">1</span> | wxmimperio |    abcde</span><br></pre></td></tr></table></figure><ul><li>删除数据</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE FROM cassandra_test.user WHERE id = <span class="string">'1'</span> AND name = <span class="string">'wxmimperio'</span>;</span><br></pre></td></tr></table></figure><h2 id="检查数据一致性"><a href="#检查数据一致性" class="headerlink" title="检查数据一致性"></a>检查数据一致性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用192.168.1.111和192.168.1.112启动CQL进行数据查询</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 192.168.1.111</span></span><br><span class="line">SELECT * FROM cassandra_test.user WHERE id = <span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line">id | name       | password</span><br><span class="line">----+------------+----------</span><br><span class="line">  <span class="number">1</span> | wxmimperio |   <span class="number">123456</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 192.168.1.112</span></span><br><span class="line">SELECT * FROM cassandra_test.user WHERE id = <span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line">id | name       | password</span><br><span class="line">----+------------+----------</span><br><span class="line">  <span class="number">1</span> | wxmimperio |   <span class="number">123456</span></span><br></pre></td></tr></table></figure><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Cassandra是一套开源分布式NoSQL数据库系统。它最初由Facebook开发，用于储存收件箱等简单格式数据，集GoogleBigTable的数据模型与Amazon Dynamo的完全分布式的架构于一身Facebook于2008将 Cassandra 开源，此后，由于Cassandra良好的可扩展性，被Digg、Twitter等知名Web 2.0网站所采纳，成为了一种流行的分布式结构化数据存储方案。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="Cassandra" scheme="http://imperio-wxm.github.io/categories/BigData/Cassandra/"/>
    
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/tags/Linux/"/>
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Cassandra" scheme="http://imperio-wxm.github.io/tags/Cassandra/"/>
    
  </entry>
  
  <entry>
    <title>Presto Install &amp; Deploy [安装部署]</title>
    <link href="http://imperio-wxm.github.io/2016/08/20/Presto-Install/"/>
    <id>http://imperio-wxm.github.io/2016/08/20/Presto-Install/</id>
    <published>2016-08-20T07:15:23.000Z</published>
    <updated>2018-06-30T13:01:49.653Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Presto是什么？<br>Presto是一个开源的分布式SQL查询引擎，适用于交互式分析查询，数据量支持GB到PB字节<br>Presto的设计和编写完全是为了解决像Facebook这样规模的商业数据仓库的交互式分析和处理速度的问题</p></blockquote><a id="more"></a><blockquote><p>Presto可以做什么？<br>Presto支持在线数据查询，包括Hive, Cassandra, 关系数据库以及专有数据存储。 一条Presto查询可以将多个数据源的数据进行合并，可以跨越整个组织进行分析<br>Presto以分析师的需求作为目标，他们期望响应时间小于1秒到几分钟。 Presto终结了数据分析的两难选择，要么使用速度快的昂贵的商业方案，要么使用消耗大量硬件的慢速的“免费”方案。</p><p>(摘自Presto中文网)</p></blockquote><hr><ul><li><p><a href="https://prestodb.io" target="_blank" rel="noopener">官网</a></p></li><li><p><a href="http://prestodb-china.com/" target="_blank" rel="noopener">中国官网</a></p></li><li><p><a href="https://github.com/prestodb/presto" target="_blank" rel="noopener">项目Github</a></p></li></ul><hr><h1 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu Server 14.04 x64</span><br><span class="line">JDK 1.8+</span><br><span class="line">Presto 0.151</span><br></pre></td></tr></table></figure><h1 id="Presto安装"><a href="#Presto安装" class="headerlink" title="Presto安装"></a>Presto安装</h1><h2 id="下载Presto"><a href="#下载Presto" class="headerlink" title="下载Presto"></a>下载Presto</h2><ul><li><a href="https://repo1.maven.org/maven2/com/facebook/presto/presto-server" target="_blank" rel="noopener">下载地址</a></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://repo1.maven.org/maven2/com/facebook/presto/presto-server/<span class="number">0.151</span>/presto-server<span class="number">-0.151</span>.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -zxvf presto-server<span class="number">-0.151</span>.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目录结构（apt-get install tree）</span></span><br><span class="line">tree -L <span class="number">2</span></span><br><span class="line">.</span><br><span class="line">├── bin</span><br><span class="line">│   ├── launcher</span><br><span class="line">│   ├── launcher.properties</span><br><span class="line">│   ├── launcher.py</span><br><span class="line">│   └── procname</span><br><span class="line">├── lib</span><br><span class="line">│   ├── aether-api<span class="number">-1.13</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── aether-connector-asynchttpclient<span class="number">-1.13</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── aether-connector-file<span class="number">-1.13</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── aether-impl<span class="number">-1.13</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── aether-spi<span class="number">-1.13</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── aether-util<span class="number">-1.13</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── annotations<span class="number">-2.0</span><span class="number">.3</span>.jar</span><br><span class="line">│   ├── antlr4-runtime<span class="number">-4.5</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── aopalliance<span class="number">-1.0</span>.jar</span><br><span class="line">│   ├── asm-all<span class="number">-5.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── <span class="keyword">async</span>-http-client<span class="number">-1.6</span><span class="number">.5</span>.jar</span><br><span class="line">│   ├── bootstrap<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── bval-core<span class="number">-0.5</span>.jar</span><br><span class="line">│   ├── bval-jsr303<span class="number">-0.5</span>.jar</span><br><span class="line">│   ├── cglib-nodep<span class="number">-2.2</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── commons-beanutils-core<span class="number">-1.8</span><span class="number">.3</span>.jar</span><br><span class="line">│   ├── commons-lang3<span class="number">-3.1</span>.jar</span><br><span class="line">│   ├── commons-math3<span class="number">-3.2</span>.jar</span><br><span class="line">│   ├── concurrent<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── configuration<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── discovery<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── discovery-server<span class="number">-1.25</span>.jar</span><br><span class="line">│   ├── event<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── fastutil<span class="number">-6.5</span><span class="number">.9</span>.jar</span><br><span class="line">│   ├── guava<span class="number">-18.0</span>.jar</span><br><span class="line">│   ├── guice<span class="number">-4.0</span>.jar</span><br><span class="line">│   ├── guice-multibindings<span class="number">-4.0</span>.jar</span><br><span class="line">│   ├── hk2-api<span class="number">-2.4</span><span class="number">.0</span>-b34.jar</span><br><span class="line">│   ├── hk2-locator<span class="number">-2.4</span><span class="number">.0</span>-b34.jar</span><br><span class="line">│   ├── hk2-utils<span class="number">-2.4</span><span class="number">.0</span>-b34.jar</span><br><span class="line">│   ├── http2-client<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── http2-common<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── http2-hpack<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── http2-http-client-transport<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── http2-server<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── http-client<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── http-server<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── jackson-annotations<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-core<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-databind<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-dataformat-smile<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-datatype-guava<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-datatype-jdk7<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-datatype-jdk8<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-datatype-joda<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── jackson-datatype-jsr310<span class="number">-2.4</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── javassist<span class="number">-3.18</span><span class="number">.1</span>-GA.jar</span><br><span class="line">│   ├── javax.annotation-api<span class="number">-1.2</span>.jar</span><br><span class="line">│   ├── javax.inject<span class="number">-1.j</span>ar</span><br><span class="line">│   ├── javax.servlet-api<span class="number">-3.1</span><span class="number">.0</span>.jar</span><br><span class="line">│   ├── javax.ws.rs-api<span class="number">-2.0</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── jaxrs<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── jcl-over-slf4j<span class="number">-1.7</span><span class="number">.12</span>.jar</span><br><span class="line">│   ├── jersey-client<span class="number">-2.22</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jersey-common<span class="number">-2.22</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jersey-container-servlet<span class="number">-2.22</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jersey-container-servlet-core<span class="number">-2.22</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jersey-guava<span class="number">-2.22</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jersey-media-jaxb<span class="number">-2.22</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jersey-server<span class="number">-2.22</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jetty-alpn-client<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-client<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-http<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-io<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-jmx<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-security<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-server<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-servlet<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jetty-util<span class="number">-9.3</span><span class="number">.11</span>.M0.jar</span><br><span class="line">│   ├── jgrapht-core<span class="number">-0.9</span><span class="number">.0</span>.jar</span><br><span class="line">│   ├── jmx<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── jmx-http<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── jmx-http-rpc<span class="number">-0.118</span>.jar</span><br><span class="line">│   ├── jmxutils<span class="number">-1.19</span>.jar</span><br><span class="line">│   ├── joda-time<span class="number">-2.8</span><span class="number">.2</span>.jar</span><br><span class="line">│   ├── jol-core<span class="number">-0.2</span>.jar</span><br><span class="line">│   ├── joni<span class="number">-2.1</span><span class="number">.5</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── json<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── leveldb<span class="number">-0.7</span>.jar</span><br><span class="line">│   ├── leveldb-api<span class="number">-0.7</span>.jar</span><br><span class="line">│   ├── log<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── log4j-over-slf4j<span class="number">-1.7</span><span class="number">.12</span>.jar</span><br><span class="line">│   ├── logback-core<span class="number">-1.0</span><span class="number">.13</span>.jar</span><br><span class="line">│   ├── log-manager<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── maven-aether-provider<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-artifact<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-compat<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-core<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-embedder<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-model<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-model-builder<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-plugin-api<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-repository-metadata<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-settings<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── maven-settings-builder<span class="number">-3.0</span><span class="number">.4</span>.jar</span><br><span class="line">│   ├── netty<span class="number">-3.7</span><span class="number">.0</span>.Final.jar</span><br><span class="line">│   ├── node<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── osgi-resource-locator<span class="number">-1.0</span><span class="number">.1</span>.jar</span><br><span class="line">│   ├── plexus-cipher<span class="number">-1.7</span>.jar</span><br><span class="line">│   ├── plexus-classworlds<span class="number">-2.4</span>.jar</span><br><span class="line">│   ├── plexus-component-annotations<span class="number">-1.5</span><span class="number">.5</span>.jar</span><br><span class="line">│   ├── plexus-container-default<span class="number">-1.5</span><span class="number">.5</span>.jar</span><br><span class="line">│   ├── plexus-interpolation<span class="number">-1.14</span>.jar</span><br><span class="line">│   ├── plexus-sec-dispatcher<span class="number">-1.3</span>.jar</span><br><span class="line">│   ├── plexus-utils<span class="number">-2.0</span><span class="number">.6</span>.jar</span><br><span class="line">│   ├── presto-bytecode<span class="number">-0.151</span>.jar</span><br><span class="line">│   ├── presto-client<span class="number">-0.151</span>.jar</span><br><span class="line">│   ├── presto-main<span class="number">-0.151</span>.jar</span><br><span class="line">│   ├── presto-parser<span class="number">-0.151</span>.jar</span><br><span class="line">│   ├── presto-spi<span class="number">-0.151</span>.jar</span><br><span class="line">│   ├── re2j-td<span class="number">-1.4</span>.jar</span><br><span class="line">│   ├── resolver<span class="number">-1.3</span>.jar</span><br><span class="line">│   ├── slf4j-api<span class="number">-1.7</span><span class="number">.12</span>.jar</span><br><span class="line">│   ├── slf4j-jdk14<span class="number">-1.7</span><span class="number">.12</span>.jar</span><br><span class="line">│   ├── slice<span class="number">-0.22</span>.jar</span><br><span class="line">│   ├── stats<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── trace-token<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── units<span class="number">-0.131</span>.jar</span><br><span class="line">│   ├── validation-api<span class="number">-1.1</span><span class="number">.0</span>.Final.jar</span><br><span class="line">│   ├── wagon-provider-api<span class="number">-2.2</span>.jar</span><br><span class="line">│   └── xbean-reflect<span class="number">-3.4</span>.jar</span><br><span class="line">├── NOTICE</span><br><span class="line">├── plugin</span><br><span class="line">│   ├── atop</span><br><span class="line">│   ├── blackhole</span><br><span class="line">│   ├── cassandra</span><br><span class="line">│   ├── example-http</span><br><span class="line">│   ├── hive-cdh4</span><br><span class="line">│   ├── hive-cdh5</span><br><span class="line">│   ├── hive-hadoop1</span><br><span class="line">│   ├── hive-hadoop2</span><br><span class="line">│   ├── jmx</span><br><span class="line">│   ├── kafka</span><br><span class="line">│   ├── localfile</span><br><span class="line">│   ├── ml</span><br><span class="line">│   ├── mongodb</span><br><span class="line">│   ├── mysql</span><br><span class="line">│   ├── postgresql</span><br><span class="line">│   ├── raptor</span><br><span class="line">│   ├── redis</span><br><span class="line">│   ├── teradata-functions</span><br><span class="line">│   └── tpch</span><br><span class="line">└── README.txt</span><br></pre></td></tr></table></figure><hr><h1 id="Presto配置"><a href="#Presto配置" class="headerlink" title="Presto配置"></a>Presto配置</h1><blockquote><p>在安装目录中创建一个etc目录。 在这个etc目录中放入以下配置信息：</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir etc</span><br></pre></td></tr></table></figure><ul><li><p>node.properties</p><ul><li>节点配置：每个节点的环境信息</li></ul></li><li><p>jvm.config</p><ul><li>JVM 配置：JVM的命令行选项</li></ul></li><li><p>config.properties</p><ul><li>参数配置：Presto server的参数信息</li></ul></li><li><p>log.properties</p><ul><li>日志信息：配置输出日志级别</li></ul></li><li><p>catalog目录：</p><ul><li>configuration forConnectors（数据源）的配置信息</li></ul></li></ul><hr><h2 id="node-properties"><a href="#node-properties" class="headerlink" title="node.properties"></a>node.properties</h2><p>包含针对于每个节点的特定的配置信息，一个节点就是在一台机器上安装的Presto实例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim etc/node.properties</span><br><span class="line"></span><br><span class="line">node.environment=production</span><br><span class="line">node.id=ffffffff-ffff-ffff-ffff-ffffffffffff</span><br><span class="line">node.data-dir=/var/presto/data</span><br></pre></td></tr></table></figure><ul><li><p>node.environment：集群名称，所有在同一个集群中的Presto节点必须拥有相同的集群名称</p></li><li><p>node.id：每个Presto节点的唯一标示。每个节点的node.id都必须是唯一的。在Presto进行重启或者升级过程中每个节点的node.id必须保持不变。如果在一个节点上安装多个Presto实例（例如：在同一台机器上安装多个Presto节点），那么每个Presto节点必须拥有唯一的node.id</p></li><li><p>node.data-dir：数据存储目录的位置（操作系统上的路径），Presto将会把日期和数据存储在这个目录下</p></li></ul><hr><h2 id="jvm-config"><a href="#jvm-config" class="headerlink" title="jvm.config"></a>jvm.config</h2><p>包含一系列在启动JVM的时候需要使用的命令行选项。这份配置文件的格式是：一系列的选项，每行配置一个单独的选项。由于这些选项不在shell命令中使用。 因此即使将每个选项通过空格或者其他的分隔符分开，java程序也不会将这些选项分开，而是作为一个命令行选项处理</p><p>Presto会将查询编译成字节码文件，因此Presto会生成很多class，因此我们我们应该增大Perm区的大小（在Perm中主要存储class）并且要允许Jvm class unloading</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim etc/jvm.config</span><br><span class="line"></span><br><span class="line">-server</span><br><span class="line">-Xmx4G</span><br><span class="line">-XX:+UseConcMarkSweepGC</span><br><span class="line">-XX:+ExplicitGCInvokesConcurrent</span><br><span class="line">-XX:+CMSClassUnloadingEnabled</span><br><span class="line">-XX:+AggressiveOpts</span><br><span class="line">-XX:+HeapDumpOnOutOfMemoryError</span><br><span class="line">-XX:OnOutOfMemoryError=kill <span class="number">-9</span> %p</span><br><span class="line">-XX:ReservedCodeCacheSize=<span class="number">150</span>M</span><br></pre></td></tr></table></figure><hr><h2 id="config-properties"><a href="#config-properties" class="headerlink" title="config.properties"></a>config.properties</h2><p>包含了Presto server的所有配置信息。 每个Presto server既是一个coordinator也是一个worker。但是在大型集群中，处于性能考虑，建议单独用一台机器作为 coordinator</p><blockquote><p>新版本中已经不使用一下配置: task.max-memory=1GB</p><p>改为:query.max-memory=1GB和query.max-memory-per-node=1GB</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim etc/config.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># coordinator最小配置</span></span><br><span class="line"></span><br><span class="line">coordinator=true</span><br><span class="line">node-scheduler.include-coordinator=false</span><br><span class="line">http-server.http.port=<span class="number">8080</span></span><br><span class="line">query.max-memory=<span class="number">2</span>GB</span><br><span class="line">query.max-memory-per-node=<span class="number">1</span>GB</span><br><span class="line">discovery-server.enabled=true</span><br><span class="line">discovery.uri=http://example.net:<span class="number">8080</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim etc/config.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># worker最小配置</span></span><br><span class="line"></span><br><span class="line">coordinator=false</span><br><span class="line">http-server.http.port=<span class="number">8080</span></span><br><span class="line">query.max-memory=<span class="number">2</span>GB</span><br><span class="line">query.max-memory-per-node=<span class="number">1</span>GB</span><br><span class="line">discovery.uri=http://example.net:<span class="number">8080</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim etc/config.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最小伪分布式，coordinator和worker在一台机</span></span><br><span class="line"></span><br><span class="line">coordinator=true</span><br><span class="line">node-scheduler.include-coordinator=true</span><br><span class="line">http-server.http.port=<span class="number">8080</span></span><br><span class="line">query.max-memory=<span class="number">2</span>GB</span><br><span class="line">query.max-memory-per-node=<span class="number">1</span>GB</span><br><span class="line">discovery-server.enabled=true</span><br><span class="line">discovery.uri=http://example.net:<span class="number">8080</span></span><br></pre></td></tr></table></figure><ul><li><p>coordinator：指定是否运维Presto实例作为一个coordinator(接收来自客户端的查询情切管理每个查询的执行过程)</p></li><li><p>node-scheduler.include-coordinator：是否允许在coordinator服务中进行调度工作。对于大型的集群，在一个节点上的Presto server即作为coordinator又作为worke将会降低查询性能。因为如果一个服务器作为worker使用，那么大部分的资源都不会被worker占用，那么就不会有足够的资源进行关键任务调度、管理和监控查询执行</p></li><li><p>http-server.http.port：指定HTTP server的端口。Presto 使用 HTTP进行内部和外部的所有通讯</p></li><li><p>query.max-memory：一个提交计划在所有worker节点上占用的内存上限</p></li><li><p>query.max-memory-per-node：一个查询在一个机器上可使用的内存上限</p></li><li><p>discovery-server.enabled：Presto 通过Discovery 服务来找到集群中所有的节点。为了能够找到集群中所有的节点，每一个Presto实例都会在启动的时候将自己注册到discovery服务。Presto为了简化部署，并且也不想再增加一个新的服务进程，Presto coordinator 可以运行一个内嵌在coordinator 里面的Discovery 服务。这个内嵌的Discovery 服务和Presto共享HTTP server并且使用同样的端口</p></li><li><p>discovery.uri：Discovery server的URI。由于启用了Presto coordinator内嵌的Discovery 服务，因此这个uri就是Presto coordinator的uri。修改example.net:8080，根据你的实际环境设置该URI。注意：这个URI一定不能以“/“结尾</p></li></ul><hr><h2 id="log-properties"><a href="#log-properties" class="headerlink" title="log.properties"></a>log.properties</h2><p>在这个配置文件中允许你根据不同的日志结构设置不同的日志级别。每个logger都有一个名字（通常是使用logger的类的全标示类名）. Loggers通过名字中的“.“来表示层级和集成关系</p><blockquote><p>默认就是INFO,四个级别 DEBUG, INFO, WARN and ERROR</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim etc/log.properties</span><br><span class="line"></span><br><span class="line">com.facebook.presto=INFO</span><br></pre></td></tr></table></figure><hr><h2 id="数据源Catalog-Properties"><a href="#数据源Catalog-Properties" class="headerlink" title="数据源Catalog Properties"></a>数据源Catalog Properties</h2><p>Presto通过connectors访问数据。这些connectors挂载在catalogs上。 connector 可以提供一个catalog中所有的schema和表</p><ul><li>创建catalog目录</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir etc/catalog</span><br></pre></td></tr></table></figure><ul><li>创建jmx连接器</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim etc/catalog/jmx.properties</span><br><span class="line"></span><br><span class="line">connector.name=jmx</span><br></pre></td></tr></table></figure><hr><h1 id="运行Presto"><a href="#运行Presto" class="headerlink" title="运行Presto"></a>运行Presto</h1><ul><li>后台进程启动</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/launcher start</span><br></pre></td></tr></table></figure><ul><li>前台运行， 日志和相关输出将会写入stdout/stderr</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/launcher run</span><br></pre></td></tr></table></figure><hr><h1 id="启动成功"><a href="#启动成功" class="headerlink" title="启动成功"></a>启动成功</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.396</span>+<span class="number">0800</span>INFOmaincom.facebook.presto.metadata.CatalogManager-- Loading catalog etc/catalog/jmx.properties --</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.675</span>+<span class="number">0800</span>INFOmainBootstrapPROPERTY         DEFAULT  RUNTIME  DESCRIPTION</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.675</span>+<span class="number">0800</span>INFOmainBootstrapjmx.dump-period  <span class="number">10.00</span>s   <span class="number">10.00</span>s</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.675</span>+<span class="number">0800</span>INFOmainBootstrapjmx.dump-tables  []       []</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.675</span>+<span class="number">0800</span>INFOmainBootstrapjmx.max-entries  <span class="number">86400</span>    <span class="number">86400</span></span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.675</span>+<span class="number">0800</span>INFOmainBootstrap</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.894</span>+<span class="number">0800</span>INFOmainio.airlift.bootstrap.LifeCycleManagerLife cycle starting...</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.895</span>+<span class="number">0800</span>INFOmainio.airlift.bootstrap.LifeCycleManagerLife cycle startup complete. System ready.</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.895</span>+<span class="number">0800</span>INFOmaincom.facebook.presto.metadata.CatalogManager-- Added catalog jmx using connector jmx --</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.897</span>+<span class="number">0800</span>INFOmaincom.facebook.presto.security.AccessControlManager-- Loading system access control --</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.897</span>+<span class="number">0800</span>INFOmaincom.facebook.presto.security.AccessControlManager-- Loaded system access control allow-all --</span><br><span class="line"><span class="number">2016</span><span class="number">-08</span><span class="number">-21</span>T21:<span class="number">56</span>:<span class="number">25.957</span>+<span class="number">0800</span>INFOmaincom.facebook.presto.server.PrestoServer======== SERVER STARTED ========</span><br></pre></td></tr></table></figure><blockquote><p>运行bin/launcher–help，Presto将会列出支持的命令和命令行选项。 另外可以通过运行bin/launcher–verbose命令，来调试安装是否正确</p></blockquote><p>启动完之后，日志将会写在data目录下，该目录下有如下文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── etc -&gt; /root/sortware/presto-server-0.151/etc</span><br><span class="line">├── plugin -&gt; /root/sortware/presto-server-0.151/plugin</span><br><span class="line">└── var</span><br><span class="line">    ├── log</span><br><span class="line">    │   └── http-request.log</span><br><span class="line">    └── run</span><br><span class="line">        └── launcher.pid</span><br></pre></td></tr></table></figure><blockquote><p>打开WEB界面：<a href="http://example.net:8080" target="_blank" rel="noopener">http://example.net:8080</a></p></blockquote><p><img src="http://7tt05h.com1.z0.glb.clouddn.com/presto-web.png" alt=""></p><hr><h1 id="常见问题汇总"><a href="#常见问题汇总" class="headerlink" title="常见问题汇总"></a><span style="color:red">常见问题汇总</span></h1><blockquote><p>1.JDK版本过低</p></blockquote><ul><li>出现以下错误通常是因为JDK版本低于1.8造成的，Presto要求JDK版本必须为1.8+</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">"main"</span> java.lang.UnsupportedClassVersionError: com/facebook/presto/server/PrestoServer : Unsupported major.minor version <span class="number">52.0</span></span><br><span class="line">    at java.lang.ClassLoader.defineClass1(Native Method)</span><br><span class="line">    at java.lang.ClassLoader.defineClass(ClassLoader.java:<span class="number">800</span>)</span><br><span class="line">    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:<span class="number">142</span>)</span><br><span class="line">    at java.net.URLClassLoader.defineClass(URLClassLoader.java:<span class="number">449</span>)</span><br><span class="line">    at java.net.URLClassLoader.access$<span class="number">100</span>(URLClassLoader.java:<span class="number">71</span>)</span><br><span class="line">    at java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">361</span>)</span><br><span class="line">    at java.net.URLClassLoader$<span class="number">1</span>.run(URLClassLoader.java:<span class="number">355</span>)</span><br><span class="line">    at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">    at java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">354</span>)</span><br><span class="line">    at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">425</span>)</span><br><span class="line">    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">308</span>)</span><br><span class="line">    at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">358</span>)</span><br><span class="line">    at sun.launcher.LauncherHelper.checkAndLoadMain(LauncherHelper.java:<span class="number">482</span>)</span><br></pre></td></tr></table></figure><blockquote><p>2.node.properties配置问题</p></blockquote><ul><li>出现以下错误通常是因为node.properties文件没有配置，或者配置错误引起的，请参照前文重新配置</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">08</span>-<span class="number">21</span>T21:<span class="number">50</span>:<span class="number">41.242</span>+<span class="number">0800</span> ERROR main com.facebook.presto.server.PrestoServer Unable to create injector, see the following errors:</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>) Error: Invalid configuration property node.environment: <span class="function">may not be <span class="title">null</span> <span class="params">(<span class="keyword">for</span> class io.airlift.node.NodeConfig.environment)</span></span></span><br><span class="line"><span class="function">  at io.airlift.node.NodeModule.<span class="title">configure</span><span class="params">(NodeModule.java:<span class="number">34</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">1 error</span></span><br><span class="line"><span class="function">com.google.inject.CreationException: Unable to create injector, see the following errors:</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">1) Error: Invalid configuration property node.environment: may not be <span class="title">null</span> <span class="params">(<span class="keyword">for</span> class io.airlift.node.NodeConfig.environment)</span></span></span><br><span class="line"><span class="function">  at io.airlift.node.NodeModule.<span class="title">configure</span><span class="params">(NodeModule.java:<span class="number">34</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">1 error</span></span><br><span class="line"><span class="function">    at com.google.inject.internal.Errors.<span class="title">throwCreationExceptionIfErrorsExist</span><span class="params">(Errors.java:<span class="number">466</span>)</span></span></span><br><span class="line"><span class="function">    at com.google.inject.internal.InternalInjectorCreator.<span class="title">initializeStatically</span><span class="params">(InternalInjectorCreator.java:<span class="number">155</span>)</span></span></span><br><span class="line"><span class="function">    at com.google.inject.internal.InternalInjectorCreator.<span class="title">build</span><span class="params">(InternalInjectorCreator.java:<span class="number">107</span>)</span></span></span><br><span class="line"><span class="function">    at com.google.inject.Guice.<span class="title">createInjector</span><span class="params">(Guice.java:<span class="number">96</span>)</span></span></span><br><span class="line"><span class="function">    at io.airlift.bootstrap.Bootstrap.<span class="title">initialize</span><span class="params">(Bootstrap.java:<span class="number">242</span>)</span></span></span><br><span class="line"><span class="function">    at com.facebook.presto.server.PrestoServer.<span class="title">run</span><span class="params">(PrestoServer.java:<span class="number">111</span>)</span></span></span><br><span class="line"><span class="function">    at com.facebook.presto.server.PrestoServer.<span class="title">main</span><span class="params">(PrestoServer.java:<span class="number">63</span>)</span></span></span><br></pre></td></tr></table></figure><hr><p>参考：<a href="http://prestodb-china.com/docs/current/index.html" target="_blank" rel="noopener">Presto 0.100 Documentation</a></p><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Presto是什么？&lt;br&gt;Presto是一个开源的分布式SQL查询引擎，适用于交互式分析查询，数据量支持GB到PB字节&lt;br&gt;Presto的设计和编写完全是为了解决像Facebook这样规模的商业数据仓库的交互式分析和处理速度的问题&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="Presto" scheme="http://imperio-wxm.github.io/categories/BigData/Presto/"/>
    
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/tags/Linux/"/>
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Presto" scheme="http://imperio-wxm.github.io/tags/Presto/"/>
    
  </entry>
  
  <entry>
    <title>Spark 编程指南 (二) [Spark Programming Guide]</title>
    <link href="http://imperio-wxm.github.io/2016/05/26/Spark-Programming-Guide-2/"/>
    <id>http://imperio-wxm.github.io/2016/05/26/Spark-Programming-Guide-2/</id>
    <published>2016-05-26T08:10:52.000Z</published>
    <updated>2018-06-30T13:01:49.669Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Python Programming Guide - Spark</p></blockquote><hr><h1 id="弹性分布式数据集-RDDs"><a href="#弹性分布式数据集-RDDs" class="headerlink" title="弹性分布式数据集 (RDDs)"></a>弹性分布式数据集 (RDDs)</h1><p>Spark的核心概念是弹性分布式数据集—<span style="background:yellow">Resilient Distributed Datasets</span>，这是一个具有容错能力并且可以进行并行计算的元素集合</p><p>对于RDD的基本概念，在 <a href="http://wxmimperio.tk/2016/01/20/Spark-Programming-Guide-1/" target="_blank" rel="noopener">Spark 编程指南 (一) [Spark Programming Guide]</a> 中有详细介绍</p><a id="more"></a><h2 id="RDD的创建"><a href="#RDD的创建" class="headerlink" title="RDD的创建"></a>RDD的创建</h2><p><strong>用户可以通过两种方式创建RDD：</strong></p><ul><li><p>并行化（Parallelizing）一个已经存在与驱动程序（Driver Program）中的集合（Collection），如set、list</p></li><li><p>引用外部存储系统上的一个数据集，比如HDFS、HBase，或者任何提供了Hadoop InputFormat的数据源</p></li></ul><h3 id="并行集合（Parallelized-Collections）"><a href="#并行集合（Parallelized-Collections）" class="headerlink" title="并行集合（Parallelized Collections）"></a>并行集合（Parallelized Collections）</h3><p>并行集合是在驱动程序中，由<span style="background:yellow">SparkContext’s parallelize</span>方法从一个已经存在的迭代器或者集合中创建，集合中的元素会被复制到一个可以进行并行操作的分布式数据集中</p><p>例如：如下代码演示如何创建一个元素为1到5的并行数据集</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line">distData = sc.parallelize(data)</span><br></pre></td></tr></table></figure><p>这个数据集一旦创建，就可以被并行的操作，例如用下代码就可以对上面列表中元素进行叠加</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distData.reduce(<span class="keyword">lambda</span> a, b: a + b)</span><br></pre></td></tr></table></figure><p>在并行集合中有一个重要的参数—分片数，表示数据集的切分片数；Spark会在集群中为每个分片启动一个任务（task），通常情况下你希望集群中的每个CPU都有2—4个分片，但Spark会根据集群情况自动分配分片数；然而，你也可以通过第二个参数手动设置分片数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.parallelize(data, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><h3 id="外部数据集（External-Datasets）"><a href="#外部数据集（External-Datasets）" class="headerlink" title="外部数据集（External Datasets）"></a>外部数据集（External Datasets）</h3><p>PySpark可以从Hadoop所支持的任何存储数据源中构建出分布式数据集，包括本地文件系统、HDFS、Cassandra、HBase、Amazon S3，Spark支持text files、SequenceFiles和任何Hadoop InputFormat</p><p>Text file RDDs可以通过<span style="background:yellow">SparkContext’s textFile</span>方法创建，这个方法接收一个URI文件地址作为参数（或者是一个本地路径、hdfs://,s3n://等），并读取文件作为行的集合，下面是一个调用实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distFile = sc.textFile(<span class="string">"data.txt"</span>)</span><br></pre></td></tr></table></figure><p>一旦创建完成，distFile就可以执行数据集的相关操作。例如：要对文件中的所有行进行求和，就可以用map和reduce操作</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distFile.map(<span class="keyword">lambda</span> s: len(s)).reduce(<span class="keyword">lambda</span> a, b: a + b)</span><br></pre></td></tr></table></figure><p><strong>Spark读取文件时的一些注意事项：</strong></p><ul><li><p>如果用本地文件系统，该文件必须在其工作节点上的相同目录下也可以访问。也可以将文件拷贝到所有的workers节点上，或者使用network-mounted共享文件系统</p></li><li><p>Spark中所有基于文件的输入方法，包括textFile，都支持在目录上运行，压缩文件和通配符。如：可以使用 textFile(“/my/directory”), textFile(“/my/directory/<em>.txt”), 和 textFile(“/my/directory/</em>.gz”)</p></li><li><p>textFile方法也带有第二个可选参数，其作用是控制文件的分片数。默认情况下，Spark会为文件的每一个block（在HDFS中，block的默认大小为64MB）创建一个分片，或者你也可以通过传入更大的值，来设置更高的分片数，但要注意，你设置的分片数不能比文件的块数小</p></li></ul><p><strong>除了text files，Spark的Python API还支持其他的数据格式：</strong></p><ul><li><p>SparkContext.wholeTextFiles 可以让你读取包含多个小text files的目录，并且对每一个文件返回这样的元祖对(filename, content)，而对于对应的textFile，文件的每一行对应着一条上述所说的返回元祖对</p></li><li><p>RDD.saveAsPickleFile 和 SparkContext.pickleFile支持将RDD保存成由pickled Python对象组成的简单格式，使用批处理的方式对pickle的对象进行序列化，默认的处理批次是10</p></li><li><p>SequenceFile 和 Hadoop Input/Output 的格式</p></li></ul><blockquote><p>注意：这个功能目前属于实验性质的，为高级用户而提供。在将来的版本中，可能会因为支持Spark SQL的读写而被取代，且Spark SQL的读写是首选方法</p></blockquote><p><strong>Writable支持</strong></p><p>PySpark的SequenceFile支持加载Java中的键值对RDD（key-value），将Writable转换为基本的Java类型，并且通过Pyrolite在结果Java对象上执行pickles序列化操作。当将一个键值对的RDD保存为SequenceFIle时，PySpark会对其进行反操作。它会unpickles Python的对象为Java对象，然后再将它们转换为Writables。</p><p>下表中的Writables会被自动地转换：</p><table><thead><tr><th>Writable Type</th><th>Python Type</th></tr></thead><tbody><tr><td>Text</td><td>unicode str</td></tr><tr><td>IntWritable</td><td>int</td></tr><tr><td>FloatWritable</td><td>float</td></tr><tr><td>DoubleWritable</td><td>float</td></tr><tr><td>BooleanWritable</td><td>bool</td></tr><tr><td>BytesWritable</td><td>bytearray</td></tr><tr><td>NullWritable</td><td>None</td></tr><tr><td>MapWritable</td><td>dict</td></tr></tbody></table><p>数组不支持开箱（out-of-the-box）操作。在读或写数组时，用户需要指定自定义的ArrayWritable子类。当写数组时，用户也需要指定自定义的转换器（converters），将数组转换为自定义的ArrayWritable子类。当读数组时，默认的转换器会将自定义的ArrayWritable子类转换为Java的Object[]，然后被pickled成Python的元组。如果要获取Python中包含基本数据类型的数组—array.array的话，用户需要为该数组指定自定义的转换器。</p><p><strong>保存和加载SequenFiles</strong></p><p>同text files类似，SequenceFiles可以被保存和加载到指定路径。可以指定key-value的类型，但对标准的Writables类型则不需要指定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rdd = sc.parallelize(range(<span class="number">1</span>,<span class="number">4</span>)).map(<span class="keyword">lambda</span> x: (x, <span class="string">"a"</span> * x ))  </span><br><span class="line">rdd.saveAsSequenceFile(<span class="string">"path/to/file"</span>)  </span><br><span class="line">sorted(sc.sequenceFile(<span class="string">"path/to/file"</span>).collect())  </span><br><span class="line"></span><br><span class="line"><span class="comment"># [(1, u'a'), (2, u'aa'), (3, u'aaa')]</span></span><br></pre></td></tr></table></figure><p><strong> 保存和加载其他的Hadoop输入/输出格式 </strong></p><p>PySpark也可以读、写任何Hadoop InputFormat，包括”新”、”旧”两种Hadoop MapReduce APIs。如果需要的话，可以将传递进来的一个Hadoop配置当成一个Python字典</p><p>以下是一个Elasticsearch ESInputFormat的样例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SPARK_CLASSPATH=/path/to/elasticsearch-hadoop.jar./bin/pyspark</span><br><span class="line"></span><br><span class="line">conf = &#123;<span class="string">"es.resource"</span> :<span class="string">"index/type"</span>&#125;   <span class="comment"># assumeElasticsearch is running on localhost defaults  </span></span><br><span class="line">rdd = sc.newAPIHadoopRDD(<span class="string">"org.elasticsearch.hadoop.mr.EsInputFormat"</span>,\  </span><br><span class="line">          <span class="string">"org.apache.hadoop.io.NullWritable"</span>,<span class="string">"org.elasticsearch.hadoop.mr.LinkedMapWritable"</span>, conf=conf)</span><br><span class="line">rdd.first()         <span class="comment"># the result is a MapWritable that isconverted to a Python dict  </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (u'Elasticsearch ID',  &#123;u'field1': True,  u'field2': u'Some Text',  'field3': 12345&#125;)</span></span><br></pre></td></tr></table></figure><blockquote><p>注意:如果这个InputFormat只是简单地依赖于Hadoop配置和输入路径，以及key-value的类型，它就可以很容易地根据上面的表格进行转换，那么这种方法应该可以很好地处理这些情况</p></blockquote><p>如果你有一个定制序列化的二进制数据（例如从Cassandra/HBase加载的数据），那么你首先要做的是用Scala/Java将数据转换为可供Pyrolite的pickler处理的数据，Converter特质提供了这一转换功能。简单地继承该特质，然后在convert方法中实现你自己的转换代码。记住要确保该类和访问InputFormat所需的依赖，都需要被打包到你的Spark作业的jar包，并且包含在PySpark的类路径中。</p><p>在Python样例和Converter样例上给出了带自定义转换器的Cassandra/HBase的InputFormat和OutputFormat使用样例。</p><hr><h2 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h2><p><strong>RDDs支持两种操作：</strong></p><ul><li><p><span style="background:yellow">转换（transformations）</span>，可以从已有的数据集创建一个新的数据集</p></li><li><p><span style="background:yellow">动作（actions）</span>，在数据集上运行计算后，会向驱动程序返回一个值</p></li></ul><p>例如，map就是一种转换，它将数据集每一个元素都传递给函数，并返回一个新RDD来表示结果。另一方面，reduce是一种动作，通过一些函数将所有的元素聚合起来，并将最终结果返回给驱动程序（不过还有一个并行的reduceByKey，能返回一个分布式数据集）。</p><p>Spark中的所有转换都是<span style="background:yellow">惰性</span>的，也就是说它们并不会马上执行得到结果。相反的，它们只是记住应用到基础数据集（例如一个文件）上的这些转换动作。<span style="background:yellow">只有当触发一个需要返回结果的动作给驱动程序时</span>，这些转换才会真正执行，这种设计让Spark更加有效率地运行。例如，我们对map操作创建的数据集进行reduce操作时，只会向驱动返回reduce操作的结果，而不是返回更大的map操作创建的数据集。</p><p>默认情况下，每一个转换过的RDD都会在你对它执行一个动作时被重新计算。而然，你也可以使用持久化或者缓存方法，把一个RDD持久化到内存中。在这种情况下，Spark会在集群中保存相关元素，以便你下次查询这个RDD时能更快速地访问。对于把RDDs持久化到磁盘上，或在集群中复制到多个节点同样是支持的。</p><p><strong>基础操作</strong></p><p>为了描述RDD的基础操作，可以考虑下面的简单程序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lines = sc.textFile(<span class="string">"data.txt"</span>)  </span><br><span class="line">lineLengths = lines.map(<span class="keyword">lambda</span> s: len(s))  </span><br><span class="line">totalLength = lineLengths.reduce(<span class="keyword">lambda</span> a, b: a+ b)</span><br></pre></td></tr></table></figure><ul><li>第一行通过一个外部文件定义了一个基本的RDD。这个数据集未被加载到内存，也未执行操作：lines仅仅指向这个文件。</li><li>第二行定义了lineLengths作为map转换结果。此外，由于惰性，不会立即计算lineLengths。</li><li>最后，我们运行reduce，这是一个动作。这时候，Spark才会将这个计算拆分成不同的task，并运行在独立的机器上，并且每台机器运行它自己的map部分和本地的reducatin，仅仅返回它的结果给驱动程序</li></ul><p>如果我们希望以后可以复用lineLengths，可以添加：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lineLengths.persist()</span><br></pre></td></tr></table></figure><p>在reduce执行之前，这将导致lineLengths在第一次被计算之后，被保存在内存中</p><p><strong>将函数传入Spark</strong></p><p>Spark的API，在很大程度上依赖于把驱动程序中的函数传递到集群上运行</p><p>有三种推荐方法可以使用：</p><ul><li><p>使用Lambda表达式来编写可以写成一个表达式的简单函数（Lambdas不支持没有返回值的多语句函数或表达式）</p></li><li><p>Spark调用的函数中的Local defs，可以用来代替更长的代码</p></li><li><p>模块中的顶级函数</p></li></ul><p>例如，如果想传递一个支持使用lambda表达式的更长的函数，可以考虑以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""MyScript.py"""</span>  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">myFunc</span><span class="params">(s)</span>:</span>  </span><br><span class="line">    words = s.split(<span class="string">" "</span>)  </span><br><span class="line">        <span class="keyword">return</span> len(words)  </span><br><span class="line">   </span><br><span class="line">    sc = SparkContext(...)  </span><br><span class="line">    sc.textFile(<span class="string">"file.txt"</span>).map(myFunc)</span><br></pre></td></tr></table></figure><blockquote><p>注意：由于可能传递的是一个类实例方法的引用（而不是一个单例对象（singleton object）），在传递方法的时候，应该同时传递包含该方法的对象。</p></blockquote><p>比如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">(object)</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(self, s)</span>:</span>  </span><br><span class="line">    <span class="keyword">return</span> s  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">doStuff</span><span class="params">(self, rdd)</span>:</span>  </span><br><span class="line">    <span class="keyword">return</span> rdd.map(self.func)</span><br></pre></td></tr></table></figure><p>这里，如果我们创建了一个类实例new MyClass，并且调用了实例的doStuff方法，该方法中的map处调用了这个MyClass实例的func方法，所以需要将整个对象传递到集群中</p><p>类似地，访问外部对象的字段时将引用整个对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span><span class="params">(object)</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span>  </span><br><span class="line">   self.field = <span class="string">"Hello"</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">doStuff</span><span class="params">(self, rdd)</span>:</span>  </span><br><span class="line">        <span class="keyword">return</span> rdd.map(<span class="keyword">lambda</span> s: self.field + x)</span><br></pre></td></tr></table></figure><p>为了避免这种问题，最简单的方式是把field拷贝到本地变量，而不是去外部访问它：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">doStuff</span><span class="params">(self, rdd)</span>:</span>  </span><br><span class="line">    field= self.field  </span><br><span class="line">    <span class="keyword">return</span> rdd.map(<span class="keyword">lambda</span> s: field + x)</span><br></pre></td></tr></table></figure><p><strong>理解闭包</strong></p><p>关于Spark的一个更困难的问题是理解当在一个集群上执行代码的时候，变量和方法的范围以及生命周期。修改范围之外变量的RDD操作经常是造成混乱的源头。在下面的实例中我们看一下使用foreach()来增加一个计数器的代码，不过同样的问题也可能有其他的操作引起。</p><p><strong>实例</strong></p><p>考虑下面的单纯的RDD元素求和，根据是否运行在同一个虚拟机上，它们表现的行为完全不同。一个简单的例子是在local模式（–master=local[n]）下运行Spark对比将Spark程序部署到一个集群上（例如通过spark-submit提交到YARN）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">counter = <span class="number">0</span></span><br><span class="line">rdd = sc.parallelize(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Wrong: Don't do this!!</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">increment_counter</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> counter</span><br><span class="line">    counter += x</span><br><span class="line">rdd.foreach(increment_counter)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Counter value: "</span>, counter)</span><br></pre></td></tr></table></figure><p><strong>本地模式 VS 集群模式</strong></p><p>上述代码的行为是未定义的,不能按照预期执行。为了执行作业，Spark将RDD操作拆分成多个task，每个任务由一个执行器操作。在执行前，Spark计算闭包。闭包是指执行器要在RDD上进行计算时必须对执行节点可见的那些变量和方法（在这里是foreach()）。这个闭包被序列化并发送到每一个执行器。</p><p>闭包中的变量被发送到每个执行器都是被拷贝的，因此，当计数器在foreach函数中引用时，它不再是驱动节点上的那个计数器了。在驱动节点的内存中仍然有一个计数器，但它对执行器来说不再是可见的了。执行器只能看到序列化闭包中的拷贝。因此，计数器最终的值仍然是0，因为所有在计数器上的操作都是引用的序列化闭包中的值。</p><p>在这种情况下要确保一个良好定义的行为，应该使用Accumulator。Spark中的累加器是一个专门用来在执行被分散到一个集群中的各个工作节点上的情况下安全更新变量的机制。本指南中的累加器部分会做详细讨论。</p><p>一般来说，闭包-构造像循环或者本地定义的方法，不应该用来改变一些全局状态。Spark没有定义或者是保证改变在闭包之外引用的对象的行为。一些这样做的代码可能会在local模式下起作用，但那仅仅是个偶然，这样的代码在分布式模式下是不会按照期望工作的。如果需要一些全局的参数，可以使用累加器。</p><p><strong>打印RDD中的元素</strong></p><p>另一个常见的用法是使用<span style="background:yellow">rdd.foreach(println)</span>方法或者<span style="background:yellow">rdd.map(println)</span>方法试图打印出RDD中的元素。</p><p>在单台机器上，这样会产生期望的输出并打印出RDD中的元素。然而，在集群模式中，被执行器调用输出到stdout的输出现在被写到了执行器的stdout，并不是在驱动上的这一个，因此驱动上的stdout不会显示这些信息。</p><p>在驱动上打印所有的元素，可以使用collect()方法首先把RDD取回到驱动节点如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.collect().foreach(println)</span><br></pre></td></tr></table></figure><p>然而，这可能导致驱动内存溢出，因为collect()将整个RDD拿到了单台机器上；如果你只需要打印很少几个RDD的元素，一个更安全的方法是使用take()方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdd.take(<span class="number">100</span>).foreach(println)</span><br></pre></td></tr></table></figure><hr><h2 id="使用键值对（key-value）"><a href="#使用键值对（key-value）" class="headerlink" title="使用键值对（key-value）"></a>使用键值对（key-value）</h2><p>虽然在包含任意类型的对象的RDDs中，可以使用大部分的Spark操作，但也有一些特殊的操作只能在键值(key-value)对的 RDDs上使用</p><p>最常见的一个就是分布式的”shuffle”操作，诸如基于key值对元素进行分组或聚合的操作</p><p>在Python中，RDDs支持的操作包含Python内置的元组(tuples)操作，比如 (1, 2)。你可以简单地创建这样的元组，然后调用期望的操作</p><p>例如，下面的代码在键值(key-value)对上使用 reduceByKey操作来计算在一个文件中每行文本出现的总次数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lines = sc.textFile(<span class="string">"data.txt"</span>)  </span><br><span class="line">pairs = lines.map(<span class="keyword">lambda</span> s: (s, <span class="number">1</span>))  </span><br><span class="line">counts = pairs.reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</span><br></pre></td></tr></table></figure><p>我们也可以使用 counts.sortByKey()，例如，按照字典序(alphabetically)排序键值对。最后调用counts.collect()转换成对象的数组形式，返回给驱动程序(driver program)</p><hr><h2 id="转换操作"><a href="#转换操作" class="headerlink" title="转换操作"></a>转换操作</h2><p>下表中列出了 Spark支持的一些常见的转换。详情请参考RDD API文档 (Scala, Java, Python)和 pair RDD函数文档 (Scala, Java)</p><table><thead><tr><th>Transformation</th><th>Meaning</th></tr></thead><tbody><tr><td>map(func)</td><td>返回一个新分布式数据集，由每一个输入元素经过func函数计算后组成</td></tr><tr><td>filter(func)</td><td>返回一个新数据集，由经过func函数计算后返回值为true的元素组成</td></tr><tr><td>flatMap(func)</td><td>类似于map，但是每一个输入元素可以被映射为0或多个输出元素(因此func应该返回一个序列(Seq)，而不是单一元素)</td></tr><tr><td>mapPartitions(func)</td><td>类似于map，但独立地在RDD的每一个分区（对应块block)上运行，当在类型为T的RDD上运行时，func的函数类型必须是Iterator<t> =&gt; Iterator<u></u></t></td></tr><tr><td>mapPartitionsWithIndex(func)</td><td>类似于mapPartitions，但func带有一个整数参数表示分区(partition)的索引值。当在类型为T的RDD上运行时， func的函数类型必须是(Int, Iterator<t>) =&gt; Iterator<u></u></t></td></tr><tr><td>sample(withReplacement, fraction, seed)</td><td>根据fraction指定的比例，对数据进行采样，可以选择是否用随机数进行替换，seed用于指定随机数生成器种子</td></tr><tr><td>union(otherDataset)</td><td>返回一个新的数据集，新数据集由源数据集和参数数据集的元素联合(union)而成</td></tr><tr><td>intersection(otherDataset)</td><td>返回一个新的数据集，新数据集由源数据集和参数数据集的元素的交集(intersection)组成}</td></tr><tr><td>distinct([numTasks]))</td><td>返回一个新的数据集，新数据集由源数据集过滤掉多余的重复元素而成</td></tr><tr><td>groupByKey([numTasks])</td><td>在一个 (K, V)对的数据集上调用，返回一个 (K, Iterable<v>)对的数据集<br><span style="color:red">注意</span>:如果你想在每个key上分组执行聚合（如总和或平均值）操作，使用reduceByKey或combineByKey会产生更好的性能<br><span style="color:red">注意</span>:默认情况下，输出的并行数依赖于父RDD(parent RDD)的分区数(number of partitions)。你可以通过传递可选的第二个参数numTasks来设置不同的任务数</v></td></tr><tr><td>reduceByKey(func, [numTasks])</td><td>在一个 (K, V)对的数据集上调用时，返回一个 (K, V)对的数据集，使用指定的reduce函数func将相同 key的值聚合到一起，该函数的类型必须是(V,V) =&gt; V。类似groupByKey，reduce的任务个数是可以通过第二个可选参数来配置的</td></tr><tr><td>aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])</td><td>在一个 (K, V)对的数据集上调用时，返回一个(K, U)对的数据集，对每个键的值使用给定的组合函数(combine functions)和一个中性的”零”值进行聚合。允许聚合后的值类型不同于输入的值类型，从而避免了不必要的内存分配。如同groupByKey，可以通过设置第二个可选参数来配置 reduce任务的个数</td></tr><tr><td>sortByKey([ascending], [numTasks])</td><td>在一个 (K, V)对的数据集上调用，其中，K必须实现Ordered，返回一个按照Key进行排序的(K, V)对数据集，升序或降序由布尔参数ascending决定</td></tr><tr><td>join(otherDataset, [numTasks])</td><td>在类型为(K, V)和(K, W)类型的数据集上调用时，返回一个相同key对应的所有元素对在一起的(K, (V, W))对的数据集。也支持外联(Outer joins)，通过使用leftOuterJoin和rightOuterJoin</td></tr><tr><td>cogroup(otherDataset, [numTasks])</td><td>在类型为(K, V)和(K, W)的数据集上调用，返回一个(K, Iterable<v>, Iterable<w>)元组(tuples的数据集。这个操作也可以称之为groupWith</w></v></td></tr><tr><td>cartesian(otherDataset)</td><td>笛卡尔积，在类型为T和U类型的数据集上调用时，返回一个(T, U)对的数据集(所有元素交互进行笛卡尔积)</td></tr><tr><td>pipe(command, [envVars])</td><td>以管道(Pipe)方式将RDD的各个分区(partition)传递到shell命令，比如一个Perl或bash脚本中。RDD的元素会被写入进程的标准输入(stdin)，并且将作为字符串的RDD(RDD of strings)，在进程的标准输出(stdout)上输出一行行数据</td></tr><tr><td>coalesce(numPartitions)</td><td>把RDD的分区数降低到指定的numPartitions。过滤掉一个大数据集之后再执行操作会更加有效</td></tr><tr><td>repartition(numPartitions)</td><td>随机地对RDD的数据重新洗牌(Reshuffle)，以便创建更多或更少的分区，对它们进行平衡。总是对网络上的所有数据进行洗牌(shuffles)</td></tr><tr><td>repartitionAndSortWithinPartitions(partitioner)</td><td>根据给定的分区器对RDD进行重新分区，在每个结果分区中，将记录按照key值进行排序。这在每个分区中比先调用repartition再排序效率更高，因为它可以推动排序到分牌机器上</td></tr></tbody></table><hr><h2 id="动作"><a href="#动作" class="headerlink" title="动作"></a>动作</h2><p>下表中列出了 Spark支持的一些常见的动作(actions)。详情请参考 RDD API文档(Scala,Java, Python) 和pair RDD函数文档(Scala, Java)</p><table><thead><tr><th>Action</th><th>Meaning</th></tr></thead><tbody><tr><td>reduce(func)</td><td>通过函数func(接受两个参数，返回一个参数)，聚集数据集中的所有元素。该函数应该是可交换和可结合的，以便它可以正确地并行计算</td></tr><tr><td>collect()</td><td>在驱动程序中，以数组的形式，返回数据集的所有元素。这通常会在使用filter或者其它操作，并返回一个足够小的数据子集后再使用会比较有用</td></tr><tr><td>count()</td><td>返回数据集的元素的个数</td></tr><tr><td>first()</td><td>返回数据集的第一个元素。 (类似于take(1))</td></tr><tr><td>take(n)</td><td>返回一个由数据集的前n个元素组成的数组。注意，这个操作目前不能并行执行，而是由驱动程序(driver program)计算所有的元素</td></tr><tr><td>takeSample(withReplacement,num, [seed])</td><td>返回一个数组，由数据集中随机采样的num个元素组成，可以选择是否用随机数替换不足的部分，可以指定可选参数seed，预先指定一个随机数生成器的种子</td></tr><tr><td>takeOrdered(n, [ordering])</td><td>返回一个由数据集的前 n个元素，并使用自然顺序或定制顺序对这些元素进行排序</td></tr><tr><td>saveAsTextFile(path)</td><td>将数据集的元素，以text file(或text file的集合)的形式，保存到本地文件系统的指定目录，Spark会对每个元素调用 toString方法，然后转换为文件中的文本行</td></tr><tr><td>saveAsSequenceFile(path)<br>(Java and Scala)</td><td>将数据集的元素，以Hadoop sequencefile的格式，保存到各种文件系统的指定路径下，包括本地系统， HDFS或者任何其它hadoop支持的文件系统。该方法只能用于键值(key-value)对的RDDs，或者实现了Hadoop的Writable接口的情况下。在 Scala中，也可以用于支持隐式转换为Writable的类型。(Spark包括了基本类型的转换，例如 Int，Double String，等等)</td></tr><tr><td>saveAsObjectFile(path)<br>(Java and Scala)</td><td>以简单地Java序列化方式将数据集的元素写入指定的路径，对应的可以用SparkContext.objectFile()加载该文件</td></tr><tr><td>countByKey()</td><td>只对(K,V)类型的RDD有效。返回一个 (K，Int)对的hashmap，其中(K,Int)对表示每一个 key对应的元素个数</td></tr><tr><td>foreach(func)</td><td>在数据集的每一个元素上，运行 func函数。这通常用于副作用(sideeffects)，例如更新一个累加器变量(accumulator variable)(参见下文)，或者和外部存储系统进行交互</td></tr></tbody></table><hr><h2 id="Shuffle操作"><a href="#Shuffle操作" class="headerlink" title="Shuffle操作"></a>Shuffle操作</h2><p><span style="background:yellow">Spark触发一个事件后进行的一些操作成为Shuffle</span>。Shuffle是Spark重新分配数据的机制，这样它就可以跨分区分组。这通常涉及在执行器和机器之间复制数据，这就使得Shuffle是一个复杂和高代价的操作。</p><p><strong>背景</strong></p><p>为了理解在洗牌的时候发生了什么，我们可以考虑reduceByKey操作的例子。reduceByKey操作产生了一个新的RDD，在这个RDD中，所有的单个的值被组合成了一个元组，key和执行一个reduce函数后的结果中与这个key有关的所有值。面临的挑战是一个key的所有的值并不都是在同一个分区上的，甚至不是一台机器上的，但是他们必须是可连接的以计算结果</p><p>在Spark中，数据一般是不会跨分区分布的，除非是在一个特殊的地方为了某种特定的目的。在计算过程中，单个任务将在单个分区上操作—因此，为了组织所有数据执行单个reduceByKey中的reduce任务，Spark需要执行一个all-to-all操作</p><p>它必须读取所有分区，找到所有key的值，并跨分区把这些值放到一起来计算每个key的最终结果—这就叫做Shuffle</p><p>尽管在每个分区中新的Shuffle的元素集合是确定性的，分区本身的顺序也同样如此，这些元素的顺序就不一定是了。如果期望在Shuffle后获得可预测的有序的数据，可以使用：</p><ul><li>mapPartitions来排序每个分区，例如使用，.sorted</li><li>repartitionAndSortWithinPartitions在重新分区的同时有效地将分区排序</li><li>sortBy来创建一个全局排序的RDD</li></ul><p>可以引起Shuffle的操作有重分区例如repartition和coalesce，‘ByKey操作（除了计数）像groupByKey和reduceByKey，还有join操作例如cogroup和join</p><p><strong>性能影响</strong></p><p>Shuffle是一个代价高昂的操作，因为它调用磁盘I/O，数据序列化和网络I/O。要组织shuffle的数据，Spark生成一个任务集合—map任务来组织数据，并使用一组reduce任务集合来聚合它。它的命名来自与MapReduce，但并不直接和Spark的map和reduce操作相关</p><p>在内部，单个的map任务的结果被保存在内存中，直到他们在内存中存不下为止。然后，他们基于目标分区进行排序，并写入到一个单个的文件中。在reduce这边，任务读取相关的已经排序的块（blocks）</p><p>某些shuffle操作会消耗大量的堆内存，因为他们用在内存中的数据结构在转换操作之前和之后都要对数据进行组织。特别的，reduceByKey和aggregateByKey在map侧创建这些结构，‘ByKey操作在reduce侧生成这些结构。当数据在内存中存不下时，Spark会将他们存储到磁盘，造成额外的磁盘开销和增加垃圾收集（GC）</p><p>Shuffle也会在磁盘上产生大量的中间文件。在Spark1.3中，这些文件直到Spark停止运行时才会从Spark的临时存储中清理掉，这意味着长时间运行Spark作业会消耗可观的磁盘空间。这些做了之后如果lineage重新计算了，那shuffle不需要重新计算了。在配置Spark上下文时，临时存储目录由spark.local.dir配置参数指定</p><p>Shuffle的行为可以通过调整各种配置参数来调整。请看Spark配置指南中的Shuffle Behavior部分</p><hr><h2 id="RDD的持久化"><a href="#RDD的持久化" class="headerlink" title="RDD的持久化"></a>RDD的持久化</h2><p>Spark最重要的一个功能，就是在不同操作间，将一个数据集持久化(persisting) (或缓存caching)到内存中。当你持久化(persist)一个 RDD，每一个节点都会把它计算的所有分区(partitions)存储在内存中，并在对数据集 (或者衍生出的数据集)执行其他动作(actioins)时重用。这将使得后续动作(actions)的执行变得更加迅速(通常快10倍)。缓存(Caching)是用 Spark 构建迭代算法和快速地交互使用的关键</p><p>你可以使用persist()或cache()方法来持久化一个RDD。在首次被一个动作(action)触发计算后，它将会被保存到节点的内存中。Spark的缓存是带有容错机制的，如果 RDD丢失任何一个分区的话，会自动地用原先构建它的转换(transformations)操作来重新进行计算</p><p>此外，每一个被持久化的RDD都可以用不同的存储级别(storage level)进行存储，比如，允许你持久化数据集到硬盘，以序列化的Java对象(节省空间)存储到内存，跨节点复制，或者以off-heap的方式存储在Tachyon</p><p>这些级别的选择，是通过将一个StorageLevel对象 (Scala, Java, Python)传递到persist()方法中进行设置的。cache()方法是使用默认存储级别的快捷方法，也就是 StorageLevel.MEMORY_ONLY (将反序列化 (deserialized)的对象存入内存）</p><p>完整的可选存储级别如下：</p><table><thead><tr><th>Storage Level</th><th>Meaning</th></tr></thead><tbody><tr><td>MEMORY_ONLY</td><td>将RDD以反序列化(deserialized)的Java对象存储到JVM。如果RDD不能被内存装下，一些分区将不会被缓存，并且在需要的时候被重新计算。这是默认的级别</td></tr><tr><td>MEMORY_AND_DISK</td><td>将RDD以反序列化(deserialized)的Java对象存储到JVM。如果RDD不能被内存装下，超出的分区将被保存在硬盘上，并且在需要时被读取</td></tr><tr><td>MEMORY_ONLY_SER</td><td>将RDD以序列化(serialized)的Java对象进行存储（每一分区占用一个字节数组）。通常来说，这比将对象反序列化(deserialized)的空间利用率更高，尤其当使用快速序列化器(fast serializer)，但在读取时会比较耗CPU</td></tr><tr><td>MEMORY_AND_DISK_SER</td><td>类似于MEMORY_ONLY_SER，但是把超出内存的分区将存储在硬盘上而不是在每次需要的时候重新计算</td></tr><tr><td>DISK_ONLY</td><td>只将RDD分区存储在硬盘上</td></tr><tr><td>MEMORY_ONLY_2, <br>MEMORY_AND_DISK_2, etc.</td><td>与上述的存储级别一样，但是将每一个分区都复制到两个集群节点上</td></tr><tr><td>OFF_HEAP (experimental)</td><td>以序列化的格式 (serialized format) 将RDD存储到Tachyon。相比于MEMORY_ONLY_SER，OFF_HEAP降低了垃圾收集(GC)的开销，并使 executors变得更小而且共享内存池，这在大堆(heaps)和多应用并行的环境下是非常吸引人的。而且，由于RDDs驻留于Tachyon中，executor的崩溃不会导致内存中的缓存丢失。在这种模式下， Tachyon中的内存是可丢弃的。因此，Tachyon不会尝试重建一个在内存中被清除的分块</td></tr></tbody></table><blockquote><p>注意:在Python中，存储对象时总是使用Pickle库来序列化(serialized),而不管你是否选择了一个序列化的级别</p></blockquote><p>Spark也会自动地持久化一些shuffle操作(比如，reduceByKey)的中间数据，即使用户没有调用persist。这么做是为了避免在一个节点上的shuffle过程失败时，重新计算整个输入。如果希望重用它的话,我们仍然建议用户在结果RDD上调用 persist</p><h2 id="如何选择存储级别？"><a href="#如何选择存储级别？" class="headerlink" title="如何选择存储级别？"></a>如何选择存储级别？</h2><p>Spark的存储级别是在满足内存使用和CPU效率权衡上的不同需求</p><p>我们建议通过以下方法进行选择：</p><ul><li><p>如果你的RDDs可以很好的与默认的存储级别(MEMORY_ONLY)契合，就不需要做任何修改了。这已经是CPU使用效率最高的选项，它使得RDDs的操作尽可能的快</p></li><li><p>如果不行，试着使用MEMORY_ONLY_SER，并且选择一个快速序列化库使对象在有比较高的空间使用率(space-efficient)的情况下，依然可以较快被访问</p></li><li><p>尽可能不要存储到硬盘上，除非计算数据集的函数的计算量特别大，或者它们过滤了大量的数据。否则，重新计算一个分区的速度，可能和从硬盘中读取差不多快</p></li><li><p>如果你想有快速的故障恢复能力，使用复制存储级别(例如：用Spark来响应web应用的请求）。所有的存储级别都有通过重新计算丢失的数据来恢复错误的容错机制，但是复制的存储级别可以让你在RDD 上持续地运行任务，而不需要等待丢失的分区被重新计算</p></li><li><p>在大量的内存或多个应用程序的环境下，试验性的OFF_HEAP模式具有以下几个优点：</p><ul><li><p>允许多个 executors共享 Tachyon中相同的内存池</p></li><li><p>极大地降低了垃圾收集器(garbage collection)的开销</p></li><li><p>即使个别的 executors崩溃了，缓存的数据也不会丢失</p></li></ul></li></ul><hr><h2 id="移除数据"><a href="#移除数据" class="headerlink" title="移除数据"></a>移除数据</h2><p>Spark会自动监控各个节点上的缓存使用情况，并使用最近最少使用算法(least-recently-used (LRU))删除老的数据分区</p><p>如果你想手动移除一个RDD，而不是等它自动从缓存中清除，可以使用RDD.unpersist()方法</p><hr><p>参考：<a href="http://spark.apache.org/docs/latest/programming-guide.html#overview" target="_blank" rel="noopener">Spark Programming  Guide 官方文档</a></p><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Python Programming Guide - Spark&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;弹性分布式数据集-RDDs&quot;&gt;&lt;a href=&quot;#弹性分布式数据集-RDDs&quot; class=&quot;headerlink&quot; title=&quot;弹性分布式数据集 (RDDs)&quot;&gt;&lt;/a&gt;弹性分布式数据集 (RDDs)&lt;/h1&gt;&lt;p&gt;Spark的核心概念是弹性分布式数据集—&lt;span style=&quot;background:yellow&quot;&gt;Resilient Distributed Datasets&lt;/span&gt;，这是一个具有容错能力并且可以进行并行计算的元素集合&lt;/p&gt;
&lt;p&gt;对于RDD的基本概念，在 &lt;a href=&quot;http://wxmimperio.tk/2016/01/20/Spark-Programming-Guide-1/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Spark 编程指南 (一) [Spark Programming Guide]&lt;/a&gt; 中有详细介绍&lt;/p&gt;
    
    </summary>
    
      <category term="BigData" scheme="http://imperio-wxm.github.io/categories/BigData/"/>
    
      <category term="Spark" scheme="http://imperio-wxm.github.io/categories/BigData/Spark/"/>
    
    
      <category term="Linux" scheme="http://imperio-wxm.github.io/tags/Linux/"/>
    
      <category term="大数据" scheme="http://imperio-wxm.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="Spark" scheme="http://imperio-wxm.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Nginx整合Apache2和Tomcat</title>
    <link href="http://imperio-wxm.github.io/2016/05/24/Nginx-Apache2-Tomcat/"/>
    <id>http://imperio-wxm.github.io/2016/05/24/Nginx-Apache2-Tomcat/</id>
    <published>2016-05-24T06:13:09.000Z</published>
    <updated>2018-06-30T13:01:49.651Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>通常情况下，如果PHP业务和Java Web业务占用资源都不是很多的情况下，为了节省服务器开销，可以放到一台服务器上。此时可以利用Nginx依旧80端口，做一个请求转发来分别访问PHP应用和Java Web应用</p></blockquote><a id="more"></a><h1 id="环境及版本"><a href="#环境及版本" class="headerlink" title="环境及版本"></a>环境及版本</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu 14.04 Server x64</span><br><span class="line">MySQL 5.5</span><br><span class="line">Apache 2.4.7</span><br><span class="line">Nginx 1.4.6</span><br><span class="line">Tomcat 7.0.69</span><br></pre></td></tr></table></figure><hr><h1 id="MySQL-PHP5-Apache2安装"><a href="#MySQL-PHP5-Apache2安装" class="headerlink" title="MySQL+PHP5+Apache2安装"></a>MySQL+PHP5+Apache2安装</h1><p>请参考：<a href="http://wxmimperio.tk/2016/05/22/Apache2-Wordpress/" target="_blank" rel="noopener">Apache2部署WordPress</a> </p><hr><h1 id="Nginx安装"><a href="#Nginx安装" class="headerlink" title="Nginx安装"></a>Nginx安装</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nginx</span><br></pre></td></tr></table></figure><hr><h1 id="Tomcat安装"><a href="#Tomcat安装" class="headerlink" title="Tomcat安装"></a>Tomcat安装</h1><p><a href="http://tomcat.apache.org/download-70.cgi" target="_blank" rel="noopener">Tomcat官方下载</a></p><ul><li>解压文件（opt下）</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf apache-tomcat<span class="number">-7.0</span><span class="number">.69</span>.tar.gz</span><br></pre></td></tr></table></figure><ul><li>开启Tomcat</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd apache-tomcat<span class="number">-7.0</span><span class="number">.69</span>/bin/</span><br><span class="line"></span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure><ul><li>浏览器输入：</li></ul><blockquote><p><a href="http://IP:8080" target="_blank" rel="noopener">http://IP:8080</a></p></blockquote><hr><h1 id="Nginx配置"><a href="#Nginx配置" class="headerlink" title="Nginx配置"></a>Nginx配置</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/nginx/nginx.conf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#user www-data;</span></span><br><span class="line">worker_processes <span class="number">4</span>;</span><br><span class="line">pid /run/nginx.pid;</span><br><span class="line"></span><br><span class="line"><span class="comment">#error_log  /home/jabo/nginx_logs/error.log;</span></span><br><span class="line"><span class="comment">#error_log  /home/jabo/nginx_logs/error.log  notice;</span></span><br><span class="line"><span class="comment">#error_log  /home/jabo/nginx_logs/error.log  info;</span></span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">        worker_connections <span class="number">768</span>;</span><br><span class="line">        <span class="comment"># multi_accept on;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line">        <span class="comment"># Basic Settings</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line"></span><br><span class="line">        sendfile on;</span><br><span class="line">        tcp_nopush on;</span><br><span class="line">        tcp_nodelay on;</span><br><span class="line">        keepalive_timeout <span class="number">65</span>;</span><br><span class="line">        types_hash_max_size <span class="number">2048</span>;</span><br><span class="line">        <span class="comment"># server_tokens off;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># server_names_hash_bucket_size 64;</span></span><br><span class="line">        <span class="comment"># server_name_in_redirect off;</span></span><br><span class="line"></span><br><span class="line">        include /etc/nginx/mime.types;</span><br><span class="line">        default_type application/octet-stream;</span><br><span class="line"></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line">        <span class="comment"># Logging Settings</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line"></span><br><span class="line">        access_log /var/log/nginx/access.log;</span><br><span class="line">        error_log /var/log/nginx/error.log;</span><br><span class="line"></span><br><span class="line">        <span class="comment">##                          </span></span><br><span class="line">        <span class="comment"># Gzip Settings</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line"></span><br><span class="line">        gzip on;</span><br><span class="line">        gzip_disable <span class="string">"msie6"</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># gzip_vary on;</span></span><br><span class="line">        <span class="comment"># gzip_proxied any;</span></span><br><span class="line">        <span class="comment"># gzip_comp_level 6;</span></span><br><span class="line">        <span class="comment"># gzip_buffers 16 8k;</span></span><br><span class="line">        <span class="comment"># gzip_http_version 1.1;</span></span><br><span class="line">        <span class="comment"># gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line">        <span class="comment"># nginx-naxsi config</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line">        <span class="comment"># Uncomment it if you installed nginx-naxsi</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#include /etc/nginx/naxsi_core.rules;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line">        <span class="comment"># nginx-passenger config</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line">        <span class="comment"># Uncomment it if you installed nginx-passenger</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#passenger_root /usr;</span></span><br><span class="line">        <span class="comment">#passenger_ruby /usr/bin/ruby;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line">        <span class="comment"># Virtual Host Configs</span></span><br><span class="line">        <span class="comment">##</span></span><br><span class="line"></span><br><span class="line">        include /etc/nginx/conf.d/*.conf;</span><br><span class="line">        include /etc/nginx/sites-enabled/*;</span><br><span class="line"></span><br><span class="line">        <span class="comment">#反向代理</span></span><br><span class="line">        upstream tomcat &#123;</span><br><span class="line">                server <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">8080</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        server &#123;</span><br><span class="line">                listen       <span class="number">80</span>;</span><br><span class="line">                server_name  www.javaapp.com;</span><br><span class="line"></span><br><span class="line">                location / &#123;</span><br><span class="line">                        proxy_pass      http://tomcat; <span class="comment">#转发到上边定义的java代理中去</span></span><br><span class="line"></span><br><span class="line">                        proxy_redirect          off;</span><br><span class="line">                        proxy_set_header        Host $host;</span><br><span class="line">                        proxy_set_header        X-Real-IP $remote_addr;</span><br><span class="line">                        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        upstream php &#123;</span><br><span class="line">                server <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">9090</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        server &#123;</span><br><span class="line">                listen       <span class="number">80</span>;</span><br><span class="line">                server_name  www.phpapp.com;</span><br><span class="line"></span><br><span class="line">                location / &#123;</span><br><span class="line">                        proxy_pass      http://php; <span class="comment">#转发到php代理</span></span><br><span class="line">                        proxy_redirect          off;</span><br><span class="line">                        proxy_set_header        Host $host;</span><br><span class="line">                        proxy_set_header        X-Real-IP $remote_addr;</span><br><span class="line">                        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#mail &#123;</span></span><br><span class="line"><span class="comment">#       # See sample authentication script at:</span></span><br><span class="line"><span class="comment">#       # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#       # auth_http localhost/auth.php;</span></span><br><span class="line"><span class="comment">#       # pop3_capabilities "TOP" "USER";</span></span><br><span class="line"><span class="comment">#       # imap_capabilities "IMAP4rev1" "UIDPLUS";</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#       server &#123;</span></span><br><span class="line"><span class="comment">#               listen     localhost:110;</span></span><br><span class="line"><span class="comment">#               protocol   pop3;</span></span><br><span class="line"><span class="comment">#               proxy      on;</span></span><br><span class="line"><span class="comment">#       &#125;</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#       server &#123;</span></span><br><span class="line"><span class="comment">#               listen     localhost:143;</span></span><br><span class="line"><span class="comment">#               protocol   imap;</span></span><br><span class="line"><span class="comment">#               proxy      on;</span></span><br><span class="line"><span class="comment">#       &#125;</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br></pre></td></tr></table></figure><hr><h1 id="修改Apache2配置"><a href="#修改Apache2配置" class="headerlink" title="修改Apache2配置"></a>修改Apache2配置</h1><ul><li>修改Apache2监听端口</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apache2/ports.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改Listen 80</span></span><br><span class="line">Listen <span class="number">9090</span></span><br></pre></td></tr></table></figure><ul><li>添加虚拟主机</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apache2/sites-available/test.local.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入以下内容</span></span><br><span class="line">&lt;VirtualHost *:<span class="number">9090</span>&gt;</span><br><span class="line">        <span class="comment"># The ServerName directive sets the request scheme, hostname and port that</span></span><br><span class="line">        <span class="comment"># the server uses to identify itself. This is used when creating</span></span><br><span class="line">        <span class="comment"># redirection URLs. In the context of virtual hosts, the ServerName</span></span><br><span class="line">        <span class="comment"># specifies what hostname must appear in the request's Host: header to</span></span><br><span class="line">        <span class="comment"># match this virtual host. For the default virtual host (this file) this</span></span><br><span class="line">        <span class="comment"># value is not decisive as it is used as a last resort host regardless.</span></span><br><span class="line">        <span class="comment"># However, you must set it for any further virtual host explicitly.</span></span><br><span class="line">        <span class="comment">#ServerName www.example.com</span></span><br><span class="line"></span><br><span class="line">        ServerAdmin webmaster@localhost</span><br><span class="line">        DocumentRoot /var/www/html/wordpress</span><br><span class="line">        ServerName www.phpapp.com</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Available loglevels: trace8, ..., trace1, debug, info, notice, warn,</span></span><br><span class="line">        <span class="comment"># error, crit, alert, emerg.</span></span><br><span class="line">        <span class="comment"># It is also possible to configure the loglevel for particular</span></span><br><span class="line">        <span class="comment"># modules, e.g.</span></span><br><span class="line">        <span class="comment">#LogLevel info ssl:warn</span></span><br><span class="line"></span><br><span class="line">        ErrorLog $&#123;APACHE_LOG_DIR&#125;/error.log</span><br><span class="line">        CustomLog $&#123;APACHE_LOG_DIR&#125;/access.log combined</span><br><span class="line"></span><br><span class="line">        <span class="comment"># For most configuration files from conf-available/, which are</span></span><br><span class="line">        <span class="comment"># enabled or disabled at a global level, it is possible to</span></span><br><span class="line">        <span class="comment"># include a line for only one particular virtual host. For example the</span></span><br><span class="line">        <span class="comment"># following line enables the CGI configuration for this host only</span></span><br><span class="line">        <span class="comment"># after it has been globally disabled with "a2disconf".</span></span><br><span class="line">        <span class="comment">#Include conf-available/serve-cgi-bin.conf</span></span><br><span class="line">&lt;/VirtualHost&gt;</span><br></pre></td></tr></table></figure><ul><li>让test.local.config生效</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo a2ensite test.local.conf</span><br></pre></td></tr></table></figure><ul><li>重启Apache2</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service apache2 restart</span><br></pre></td></tr></table></figure><p><span style="background:pink">关于WordPress的部署请看</span>： <a href="http://wxmimperio.tk/2016/05/22/Apache2-Wordpress/" target="_blank" rel="noopener">Apache2部署WordPress</a></p><hr><h1 id="Java-Web测试程序"><a href="#Java-Web测试程序" class="headerlink" title="Java Web测试程序"></a>Java Web测试程序</h1><p><a href="https://github.com/imperio-wxm/CodeSegment/tree/master/myTest" target="_blank" rel="noopener">GitHub地址</a></p><p>将程序打成war包，放入Tomcat的 <span style="background:pink">webapps</span> 目录下</p><hr><h1 id="其他工作"><a href="#其他工作" class="headerlink" title="其他工作"></a>其他工作</h1><ul><li>重启Nginx</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service nginx restart</span><br></pre></td></tr></table></figure><ul><li>修改hosts</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>       www.javaapp.com</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>       www.phpapp.com</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><ul><li>浏览器输入：</li></ul><blockquote><p>www.javaapp.com/myTest/index.jsp</p></blockquote><p>转到Java Web测试程序主页</p><ul><li>浏览器输入：</li></ul><blockquote><p>www.phpapp.com</p></blockquote><p>转到WordPress安装主页</p><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;通常情况下，如果PHP业务和Java Web业务占用资源都不是很多的情况下，为了节省服务器开销，可以放到一台服务器上。此时可以利用Nginx依旧80端口，做一个请求转发来分别访问PHP应用和Java Web应用&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="Tools" scheme="http://imperio-wxm.github.io/categories/Tools/"/>
    
    
      <category term="Apache" scheme="http://imperio-wxm.github.io/tags/Apache/"/>
    
      <category term="Nginx" scheme="http://imperio-wxm.github.io/tags/Nginx/"/>
    
      <category term="Tomcat" scheme="http://imperio-wxm.github.io/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>Apache2部署WordPress</title>
    <link href="http://imperio-wxm.github.io/2016/05/22/Apache2-Wordpress/"/>
    <id>http://imperio-wxm.github.io/2016/05/22/Apache2-Wordpress/</id>
    <published>2016-05-22T03:17:34.000Z</published>
    <updated>2018-06-30T13:01:49.640Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>WordPress是一种使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。功能强大、扩展性强，这主要得益于其插件众多，易于扩充功能，基本上一个完整网站该有的功能，通过其第三方插件都能实现所有功能。</p></blockquote><hr><a id="more"></a><h1 id="环境及版本"><a href="#环境及版本" class="headerlink" title="环境及版本"></a>环境及版本</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Ubuntu 14.04 LTS x64</span><br><span class="line">MySQL 5.5</span><br><span class="line">Apache 2.4.7</span><br><span class="line">WordPress 4.5.2-zh_CN</span><br></pre></td></tr></table></figure><hr><h1 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install mysql-server</span><br></pre></td></tr></table></figure><p>安装过程中会有几个设置选项：</p><ul><li><p>New password for the MySQL “root” user:</p></li><li><p>Repeat password for the MySQL “root” user:</p></li></ul><p>测试MySQL安装成功：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Welcome to the MySQL monitor.  Commands end <span class="keyword">with</span> ; <span class="keyword">or</span> \g.</span><br><span class="line">Your MySQL connection id <span class="keyword">is</span> <span class="number">42</span></span><br><span class="line">Server version: <span class="number">5.5</span><span class="number">.49</span><span class="number">-0</span>ubuntu0<span class="number">.14</span><span class="number">.04</span><span class="number">.1</span> (Ubuntu)</span><br><span class="line"></span><br><span class="line">Copyright (c) <span class="number">2000</span>, <span class="number">2016</span>, Oracle <span class="keyword">and</span>/<span class="keyword">or</span> its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle <span class="keyword">is</span> a registered trademark of Oracle Corporation <span class="keyword">and</span>/<span class="keyword">or</span> its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type <span class="string">'help;'</span> <span class="keyword">or</span> <span class="string">'\h'</span> <span class="keyword">for</span> help. Type <span class="string">'\c'</span> to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure><hr><h1 id="安装Apache2"><a href="#安装Apache2" class="headerlink" title="安装Apache2"></a>安装Apache2</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install apache2</span><br></pre></td></tr></table></figure><p>浏览器地址中输入：</p><blockquote><p><a href="http://localhost/" target="_blank" rel="noopener">http://localhost/</a>  或者 <a href="http://127.0.0.1" target="_blank" rel="noopener">http://127.0.0.1</a></p></blockquote><p>看到Apache2主页</p><ul><li>常见问题：</li></ul><blockquote><p>Apache2重启时遇到</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">AH00558: apache2: Could <span class="keyword">not</span> reliably determine the serve<span class="string">r's fully qualified domain name, using 127.0.1.1. Set the '</span>ServerName<span class="string">' directive globally to suppress this message</span></span><br></pre></td></tr></table></figure><blockquote><p>解决：</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apache2/apache2.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入一下内容</span></span><br><span class="line">ServerName <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启Apache2</span></span><br><span class="line">sudo service apache2 restart</span><br></pre></td></tr></table></figure><hr><h1 id="安装php5"><a href="#安装php5" class="headerlink" title="安装php5"></a>安装php5</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install php5</span><br></pre></td></tr></table></figure><blockquote><p>安装PHP其他模块</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MySQL连接</span></span><br><span class="line">sudo apt-get install php5-mysql</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装phpMyAdmin</span></span><br><span class="line">sudo apt-get install phpMyAdmin</span><br><span class="line"></span><br><span class="line"><span class="comment"># Web server to reconfigure automatically</span></span><br><span class="line"><span class="comment"># 选择Apache2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Configure database for phpmyadmin with dbconfig-common? # Yes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Password of the database's administrative user:  </span></span><br><span class="line"><span class="comment"># MySQL application password for phpmyadmin:</span></span><br><span class="line"><span class="comment"># Password confirmation:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建连接</span></span><br><span class="line">sudo ln -s /usr/share/phpmyadmin /var/www/html</span><br></pre></td></tr></table></figure><blockquote><p>测试PHP和phpMyAdmin安装成功</p></blockquote><ul><li>PHP测试</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /var/www/html</span><br><span class="line"></span><br><span class="line">sudo vim test.php</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加入Hello PHP! 保存退出</span></span><br></pre></td></tr></table></figure><p>浏览器输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://localhost/test.php</span><br></pre></td></tr></table></figure><ul><li>phpMyAdmin测试</li></ul><p>浏览器输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http://localhost/phpmyadmin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入登录页面</span></span><br></pre></td></tr></table></figure><hr><h1 id="安装WordPress"><a href="#安装WordPress" class="headerlink" title="安装WordPress"></a>安装WordPress</h1><p><a href="https://cn.wordpress.org/" target="_blank" rel="noopener">官网下载WordPress</a></p><ul><li>解压WordPress</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo tar -zxvf wordpress<span class="number">-4.5</span><span class="number">.2</span>-zh_CN.tar.gz -C /var/www/html/</span><br></pre></td></tr></table></figure><ul><li>创建数据库</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 登录MySQL</span></span><br><span class="line">mysql -u root -p</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据库</span></span><br><span class="line">create database db_wp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据库</span></span><br><span class="line"></span><br><span class="line">show databases;</span><br></pre></td></tr></table></figure><ul><li>配置WordPress</li></ul><p>浏览器输入:</p><blockquote><p><a href="http://localhost/wordpress" target="_blank" rel="noopener">http://localhost/wordpress</a></p></blockquote><ul><li>现在就开始</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">数据库名</span><br><span class="line">数据库用户名</span><br><span class="line">数据库密码</span><br><span class="line">数据库主机</span><br><span class="line">数据库表前缀</span><br></pre></td></tr></table></figure><ul><li>抱歉，我不能写入wp-config.php文件</li><li>您可以手工创建wp-config.php文件并将以下信息贴入其中</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /var/www/html/wordpress/wp-config.php</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将浏览器上的内容复制进去</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将编码格式改成utf8</span></span><br><span class="line">/** 创建数据表时默认的文字编码 */</span><br><span class="line">define(<span class="string">'DB_CHARSET'</span>, <span class="string">'utf8'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存退出，浏览器进行安装</span></span><br></pre></td></tr></table></figure><ul><li>设置WordPress基本信息</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">站点标题</span><br><span class="line">用户名</span><br><span class="line">密码</span><br><span class="line">电子邮箱</span><br></pre></td></tr></table></figure><ul><li>登录后进入后台仪表盘，安装结束！</li></ul><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;WordPress是一种使用PHP语言开发的博客平台，用户可以在支持PHP和MySQL数据库的服务器上架设属于自己的网站。功能强大、扩展性强，这主要得益于其插件众多，易于扩充功能，基本上一个完整网站该有的功能，通过其第三方插件都能实现所有功能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="Tools" scheme="http://imperio-wxm.github.io/categories/Tools/"/>
    
    
      <category term="Apache" scheme="http://imperio-wxm.github.io/tags/Apache/"/>
    
      <category term="WordPress" scheme="http://imperio-wxm.github.io/tags/WordPress/"/>
    
  </entry>
  
  <entry>
    <title>Thriftpy—[RPC文件传输]</title>
    <link href="http://imperio-wxm.github.io/2016/05/14/thriftpy-rpc-file/"/>
    <id>http://imperio-wxm.github.io/2016/05/14/thriftpy-rpc-file/</id>
    <published>2016-05-14T13:24:05.000Z</published>
    <updated>2018-06-30T13:01:49.727Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ThriftPy is a pure python implementation of Apache Thrift in a pythonic way.</p></blockquote><hr><p><a href="https://github.com/Eleme/thriftpy" target="_blank" rel="noopener">Github地址</a><br><a href="http://thriftpy.readthedocs.io/en/latest/" target="_blank" rel="noopener">Documentation</a></p><a id="more"></a><hr><h1 id="环境及版本"><a href="#环境及版本" class="headerlink" title="环境及版本"></a>环境及版本</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">【Server、Client】</span><br><span class="line">Ubuntu 14.04 LTS x64</span><br><span class="line">Thriftpy 0.3.8</span><br><span class="line">Python 2.7</span><br><span class="line">Pycharm 4.5.1</span><br></pre></td></tr></table></figure><hr><h1 id="简单Server-amp-Client"><a href="#简单Server-amp-Client" class="headerlink" title="简单Server &amp; Client"></a>简单Server &amp; Client</h1><p>Thriftpy的使用和Thrift类似，用两台Ubuntu分别做Server和Client，实现跨机器通信</p><h2 id="Server"><a href="#Server" class="headerlink" title="Server"></a>Server</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> thriftpy</span><br><span class="line"><span class="keyword">from</span> thriftpy.rpc <span class="keyword">import</span> make_server</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyRPC</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 提供调用的方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">print_fun</span><span class="params">(self,name)</span>:</span></span><br><span class="line">        str = <span class="string">"Hello "</span> + name</span><br><span class="line">        <span class="keyword">return</span> str</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    file_path = os.path.abspath(<span class="string">"../conf/simple.thrift"</span>)</span><br><span class="line">    <span class="comment"># 加载注册文件</span></span><br><span class="line">    simple_thrift = thriftpy.load(file_path, module_name=<span class="string">"simple_thrift"</span>)</span><br><span class="line"></span><br><span class="line">    server = make_server(simple_thrift.RPCTest, MyRPC(), <span class="string">'192.168.1.105'</span>, <span class="number">6000</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Thriftpy listening 6000......"</span></span><br><span class="line">    server.serve()</span><br></pre></td></tr></table></figure><h2 id="Client"><a href="#Client" class="headerlink" title="Client"></a>Client</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> thriftpy</span><br><span class="line"><span class="keyword">from</span> thriftpy.rpc <span class="keyword">import</span> make_client</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    file_path = os.path.abspath(<span class="string">"../conf/simple.thrift"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载注册文件</span></span><br><span class="line">    simple_thrift = thriftpy.load(file_path, module_name=<span class="string">"simple_thrift"</span>)</span><br><span class="line"></span><br><span class="line">    client = make_client(simple_thrift.RPCTest, <span class="string">'192.168.1.105'</span>, <span class="number">6000</span>)</span><br><span class="line">    <span class="keyword">print</span> client.print_fun(<span class="string">"wxmimperio"</span>)</span><br></pre></td></tr></table></figure><h2 id="Service-Conf"><a href="#Service-Conf" class="headerlink" title="Service Conf"></a>Service Conf</h2><p>方法注册文件以.thrif为后缀，Server与Client都必须有，文件目录可以指定</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service RPCTest &#123;</span><br><span class="line">    string print_fun(<span class="number">1</span>:string name),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>Thrift支持的数据类型Thriftpy里都支持</p></blockquote><ul><li>基本数据类型（Java为准）</li></ul><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>bool（boolean）</td><td>布尔类型(TRUE or FALSE)</td></tr><tr><td>byte（byte）</td><td>8位带符号整数</td></tr><tr><td>i16（short）</td><td>16位带符号整数</td></tr><tr><td>i32（int）</td><td>32位带符号整数</td></tr><tr><td>i64（long）</td><td>64位带符号整数</td></tr><tr><td>double（double）</td><td>64位浮点数</td></tr><tr><td>string（String）</td><td>采用UTF-8编码的字符串</td></tr></tbody></table><ul><li>复合数据类型（Java为准）</li></ul><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>list（java.util.ArrayList）</td><td>列表</td></tr><tr><td>set（java.util.HashSet）</td><td>集合</td></tr><tr><td>map（java.util.HashMap）</td><td>键值对</td></tr></tbody></table><ul><li>特殊数据类型（Java为准）</li></ul><table><thead><tr><th>类型</th><th>说明</th></tr></thead><tbody><tr><td>binary（ByteBuffer）</td><td>未经过编码的字节流</td></tr><tr><td>struct（结构体）</td><td>定义了一个很普通的OOP对象，但是没有继承特性</td></tr></tbody></table><blockquote><p>复合、特殊数据、基本数据类型可以嵌套使用</p></blockquote><hr><h1 id="RPC传输文件"><a href="#RPC传输文件" class="headerlink" title="RPC传输文件"></a>RPC传输文件</h1><blockquote><p>这里我采用Base64进行编码与解码，将文件从Client传向Server</p><p>Base64是网络上最常见的用于传输8Bit字节代码的编码方式之一，大家可以查看RFC2045～RFC2049，上面有MIME的详细规范。Base64编码可用于在HTTP环境下传递较长的标识信息。例如，在Java Persistence系统Hibernate中，就采用了Base64来将一个较长的唯一标识符（一般为128-bit的UUID）编码为一个字符串，用作HTTP表单和HTTP GET URL中的参数。在其他应用程序中，也常常需要把二进制数据编码为适合放在URL（包括隐藏表单域）中的形式。此时，采用Base64编码具有不可读性，即所编码的数据不会被人用肉眼所直接看到。</p></blockquote><h2 id="Server-接收文件"><a href="#Server-接收文件" class="headerlink" title="Server 接收文件"></a>Server 接收文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line">__author__ = <span class="string">'wxmimperio'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> thriftpy</span><br><span class="line"><span class="keyword">from</span> thriftpy.rpc <span class="keyword">import</span> make_server</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyFileRPC</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_server</span><span class="params">(self, file_list)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> file_list:</span><br><span class="line">            files_path = os.path.abspath(<span class="string">"../"</span>)</span><br><span class="line">            <span class="keyword">for</span> item <span class="keyword">in</span> file_list:</span><br><span class="line">                <span class="keyword">with</span> open(files_path + <span class="string">"/"</span> + item[<span class="number">0</span>], <span class="string">"wb"</span>) <span class="keyword">as</span> file:</span><br><span class="line">                    file.write(item[<span class="number">1</span>].decode(<span class="string">"base64"</span>))</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"file create!"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"file_list is empty!"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">server_start</span><span class="params">(conf_path, server_ip, server_port)</span>:</span></span><br><span class="line">    <span class="comment"># 加载注册文件</span></span><br><span class="line">    file_thrift = thriftpy.load(conf_path, module_name=<span class="string">"file_thrift"</span>)</span><br><span class="line">    server = make_server(file_thrift.FileRPC, MyFileRPC(), server_ip, server_port)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Thriftpy listening "</span> + str(server_port) + <span class="string">"......"</span></span><br><span class="line">    server.serve()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    conf_path = os.path.abspath(<span class="string">"../conf/file.thrift"</span>)</span><br><span class="line">    server_start(conf_path, <span class="string">"192.168.1.105"</span>, <span class="number">6000</span>)</span><br></pre></td></tr></table></figure><h2 id="Client-发送文件"><a href="#Client-发送文件" class="headerlink" title="Client 发送文件"></a>Client 发送文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line">__author__ = <span class="string">'wxmimperio'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> thriftpy</span><br><span class="line"><span class="keyword">from</span> thriftpy.rpc <span class="keyword">import</span> make_client</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">client_start</span><span class="params">(conf_path, client_ip, client_port)</span>:</span></span><br><span class="line">    file_thrift = thriftpy.load(conf_path, module_name=<span class="string">"file_thrift"</span>)</span><br><span class="line">    <span class="keyword">return</span> make_client(file_thrift.FileRPC, client_ip, client_port)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">opt_files</span><span class="params">(files_path_list)</span>:</span></span><br><span class="line">    files_context_list = []</span><br><span class="line">    files_name_list = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> files_path_list:</span><br><span class="line">        <span class="keyword">with</span> open(item, <span class="string">"rb"</span>) <span class="keyword">as</span> files:</span><br><span class="line">            files_context_list.append(files.read().encode(<span class="string">"base64"</span>))</span><br><span class="line">        <span class="comment"># 获取文件名</span></span><br><span class="line">        files_name_list.append(item.split(<span class="string">'/'</span>)[<span class="number">-1</span>])</span><br><span class="line">    <span class="keyword">return</span> zip(files_name_list, files_context_list)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    conf_path = os.path.abspath(<span class="string">"../conf/file.thrift"</span>)</span><br><span class="line">    client = client_start(conf_path, <span class="string">"192.168.1.105"</span>, <span class="number">6000</span>)</span><br><span class="line"></span><br><span class="line">    files_path_list = []</span><br><span class="line">    files_path_list.append(os.path.abspath(<span class="string">"../files/markdown.md"</span>))</span><br><span class="line">    files_path_list.append(os.path.abspath(<span class="string">"../files/markdown.pdf"</span>))</span><br><span class="line">    files_path_list.append(os.path.abspath(<span class="string">"../files/photo.jpg"</span>))</span><br><span class="line"></span><br><span class="line">    files_info = opt_files(files_path_list)</span><br><span class="line">    <span class="keyword">print</span> client.file_server(files_info)</span><br></pre></td></tr></table></figure><h2 id="Service-Conf-1"><a href="#Service-Conf-1" class="headerlink" title="Service Conf"></a>Service Conf</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service FileRPC &#123;</span><br><span class="line">    string file_server(<span class="number">1</span>:list&lt;list&lt;string&gt;&gt; file_list),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p><a href="https://github.com/imperio-wxm/CodeSegment/tree/master/thriftpy" target="_blank" rel="noopener">本文Github源码</a></p><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;ThriftPy is a pure python implementation of Apache Thrift in a pythonic way.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/Eleme/thriftpy&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Github地址&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://thriftpy.readthedocs.io/en/latest/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Tools" scheme="http://imperio-wxm.github.io/categories/Tools/"/>
    
    
      <category term="Thriftpy" scheme="http://imperio-wxm.github.io/tags/Thriftpy/"/>
    
      <category term="RPC" scheme="http://imperio-wxm.github.io/tags/RPC/"/>
    
  </entry>
  
  <entry>
    <title>Python基础—文件和流操作</title>
    <link href="http://imperio-wxm.github.io/2016/03/10/python-file-stream-ops/"/>
    <id>http://imperio-wxm.github.io/2016/03/10/python-file-stream-ops/</id>
    <published>2016-03-10T06:03:28.000Z</published>
    <updated>2018-06-30T13:01:49.722Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>Python打开文件可以用open函数<br>语法：open(filename, mode[, buffering]),返回一个文件对象<br>mode为文件模式，buffering为缓冲，都是可选参数</p></blockquote><p><a href="https://github.com/imperio-wxm/learning-python/tree/master/learning-python/learning_file" target="_blank" rel="noopener">Demo Github源码</a></p><a id="more"></a><h1 id="环境及版本"><a href="#环境及版本" class="headerlink" title="环境及版本"></a>环境及版本</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Windows 10 x64</span><br><span class="line">Python 2.7</span><br><span class="line">Pycharm 4.5.1</span><br></pre></td></tr></table></figure><hr><h1 id="文件模式（mode）"><a href="#文件模式（mode）" class="headerlink" title="文件模式（mode）"></a>文件模式（mode）</h1><table><thead><tr><th>值</th><th>描述</th></tr></thead><tbody><tr><td>‘r’</td><td>只读模式</td></tr><tr><td>‘w’</td><td>只写模式（会覆盖掉已经有的内容）</td></tr><tr><td>‘a’</td><td>追加模式（向已有的内容后面进行追加）</td></tr><tr><td>‘b’</td><td>二进制模式</td></tr><tr><td>‘t’</td><td>文本模式</td></tr><tr><td>‘+’</td><td>读写模式</td></tr><tr><td>‘U’</td><td>通用匹配换行符模式</td></tr></tbody></table><hr><h2 id="文件模式组合"><a href="#文件模式组合" class="headerlink" title="文件模式组合"></a>文件模式组合</h2><table><thead><tr><th>值</th><th>描述</th><th>文件不存在</th></tr></thead><tbody><tr><td>‘r’或’rt’</td><td>只读模式（default）</td><td>报错</td></tr><tr><td>‘rb’</td><td>只读模式（针对二进制文件）</td><td>报错</td></tr><tr><td>‘w’或’wt’</td><td>只写模式（覆盖已有内容）</td><td>创建</td></tr><tr><td>‘wb’</td><td>只写模式（针对二进制文件，覆盖已有内容）</td><td>创建</td></tr><tr><td>‘a’</td><td>只写模式（向已有的内容后面进行追加）</td><td>创建</td></tr><tr><td>‘r+’</td><td>读写模式（覆盖）</td><td>报错</td></tr><tr><td>‘w+’</td><td>读写模式（覆盖）</td><td>创建</td></tr><tr><td>‘a+’</td><td>读写模式（向已有的内容后面进行追加）</td><td>创建</td></tr></tbody></table><hr><h1 id="缓冲（buffering）"><a href="#缓冲（buffering）" class="headerlink" title="缓冲（buffering）"></a>缓冲（buffering）</h1><table><thead><tr><th>值</th><th>描述</th></tr></thead><tbody><tr><td>0或False</td><td>无缓冲，读写操作直接针对磁盘</td></tr><tr><td>1或True</td><td>有缓冲，只有使用flush或者close时才会写入磁盘</td></tr><tr><td>大于1</td><td>数字表示缓冲区大小（字节）</td></tr><tr><td>任意负数</td><td>表示默认缓冲区大小</td></tr></tbody></table><hr><h1 id="读和写"><a href="#读和写" class="headerlink" title="读和写"></a>读和写</h1><table><thead><tr><th>方法名</th><th>描述</th></tr></thead><tbody><tr><td>read([size])</td><td>以字符串形式返回数据，可选参数size可以指定读取的字节数，如果未指定表示返回全部数据</td></tr><tr><td>write(str)</td><td>将字符串写入文件</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读文件</span></span><br><span class="line">file_read = open(file_path, <span class="string">'r+'</span>)</span><br><span class="line"><span class="keyword">print</span> file_read.read()</span><br><span class="line">file_read.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 写文件</span></span><br><span class="line">file_wtite = open(file_path, <span class="string">'a+'</span>)</span><br><span class="line">file_wtite.write(<span class="string">"This is a test!"</span>.decode(<span class="string">"utf-8"</span>)) <span class="comment"># 中文UTF-8</span></span><br><span class="line">file_wtite.close()</span><br></pre></td></tr></table></figure><hr><h1 id="读写行"><a href="#读写行" class="headerlink" title="读写行"></a>读写行</h1><table><thead><tr><th>方法名</th><th>描述</th></tr></thead><tbody><tr><td>readline()</td><td>以当前位置，从文件中读取一行，以字符串返回这行数据，offset指向下一行起始位置</td></tr><tr><td>readlines([size])</td><td>将文件返回行为列表（list类型），可选参数size用于指定返回的行数；如果size未指定，表示返回所有行数</td></tr><tr><td>writelines()</td><td>将一个字符串列表一次性写入到文件中，不会加换行符</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读一行数据</span></span><br><span class="line">file_readline = open(file_path, <span class="string">'r+'</span>)</span><br><span class="line"><span class="keyword">print</span> file_readline.readline().decode(<span class="string">"utf-8"</span>)</span><br><span class="line"><span class="comment"># 读指定行数</span></span><br><span class="line">lines = file_readline.readlines(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line"><span class="keyword">print</span> line</span><br><span class="line">file_readline.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 写入一个字符串列表</span></span><br><span class="line">str_list = [<span class="string">"a\n"</span>, <span class="string">"b\n"</span>, <span class="string">"c\n"</span>]</span><br><span class="line">file_writelines = open(file_path, <span class="string">'a+'</span>)</span><br><span class="line">file_writelines.writelines(str_list)</span><br><span class="line">file_writelines.close()</span><br></pre></td></tr></table></figure><hr><h1 id="随机访问"><a href="#随机访问" class="headerlink" title="随机访问"></a>随机访问</h1><table><thead><tr><th>方法名</th><th>描述</th></tr></thead><tbody><tr><td>seek(offset[, whence])</td><td>把当前位置移动到offset和whence定义的位置。offset时一个字节（字符）偏移量，whence默认0表示偏移量从文件的开头计算；whence为1表示相对于当前位置偏移；whence为2表示从文件的尾部向前偏移</td></tr><tr><td>tell()</td><td>返回当前文件的位置</td></tr></tbody></table><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># offset偏移</span></span><br><span class="line">offset_path = os.path.abspath(<span class="string">'../doc/offset_test.txt'</span>)</span><br><span class="line">file_offset = open(offset_path, <span class="string">'w'</span>)</span><br><span class="line">file_offset.write(<span class="string">"abcdefg"</span>)</span><br><span class="line">file_offset.seek(<span class="number">2</span>)</span><br><span class="line">file_offset.write(<span class="string">'12346'</span>)</span><br><span class="line">file_offset.close()</span><br><span class="line">file_offset = open(offset_path)</span><br><span class="line"><span class="keyword">print</span> file_offset.read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># tell返回当前文件位置</span></span><br><span class="line">file_tell = open(offset_path, <span class="string">'w'</span>)</span><br><span class="line">file_tell.seek(<span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> file_tell.tell()</span><br></pre></td></tr></table></figure><hr><h1 id="关闭、清空缓冲"><a href="#关闭、清空缓冲" class="headerlink" title="关闭、清空缓冲"></a>关闭、清空缓冲</h1><table><thead><tr><th>方法名</th><th>描述</th></tr></thead><tbody><tr><td>close()</td><td>关闭文件流</td></tr><tr><td>flush()</td><td>强制写入磁盘，并清空缓冲区</td></tr></tbody></table><ul><li>通常文件、流的关闭应该在try/except/finally语句中</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 此处打开文件</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line"><span class="comment"># 文件操作</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line"><span class="comment"># 捕获可能出现的异常</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line"><span class="comment"># 关闭文件</span></span><br><span class="line">file.close()</span><br></pre></td></tr></table></figure><ul><li>还可以使用with语句（上下文管理器）</li><li>文件在语句结束后会自动关闭，即使引发了异常也是这样</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">"file_path"</span>) <span class="keyword">as</span> f:</span><br><span class="line">do_something(f)</span><br></pre></td></tr></table></figure><hr><h1 id="文件迭代"><a href="#文件迭代" class="headerlink" title="文件迭代"></a>文件迭代</h1><hr><h2 id="按字节迭代"><a href="#按字节迭代" class="headerlink" title="按字节迭代"></a>按字节迭代</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">file_name = open(file_path)</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">char = file_name.read(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> char:</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">process(char)</span><br><span class="line">file_name.close()</span><br></pre></td></tr></table></figure><hr><h2 id="按行迭代"><a href="#按行迭代" class="headerlink" title="按行迭代"></a>按行迭代</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">file_name = open(file_path)</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">line = file_name.readline()</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> line:</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">process(line)</span><br><span class="line">file_name.close()</span><br></pre></td></tr></table></figure><h1 id="迭代全文"><a href="#迭代全文" class="headerlink" title="迭代全文"></a>迭代全文</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">file_name = open(file_path)</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> file_name:</span><br><span class="line">process(line)</span><br><span class="line">file_name.close()</span><br></pre></td></tr></table></figure><hr><p>参考：Python基础教程(第2版·修订版)</p><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Python打开文件可以用open函数&lt;br&gt;语法：open(filename, mode[, buffering]),返回一个文件对象&lt;br&gt;mode为文件模式，buffering为缓冲，都是可选参数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/imperio-wxm/learning-python/tree/master/learning-python/learning_file&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Demo Github源码&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://imperio-wxm.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://imperio-wxm.github.io/tags/Python/"/>
    
      <category term="file" scheme="http://imperio-wxm.github.io/tags/file/"/>
    
  </entry>
  
  <entry>
    <title>Python基础—日期与时间操作</title>
    <link href="http://imperio-wxm.github.io/2016/03/05/Python-date-time-ops/"/>
    <id>http://imperio-wxm.github.io/2016/03/05/Python-date-time-ops/</id>
    <published>2016-03-05T11:24:19.000Z</published>
    <updated>2018-06-30T13:01:49.656Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>Python标准库中提供了datatime模块来操作日期和时间</p></blockquote><p><a href="https://github.com/imperio-wxm/learning-python/tree/master/learning-python/learning_datetime" target="_blank" rel="noopener">Demo Github源码</a></p><a id="more"></a><h1 id="环境及版本"><a href="#环境及版本" class="headerlink" title="环境及版本"></a>环境及版本</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Windows 10 x64</span><br><span class="line">Python 2.7</span><br><span class="line">Pycharm 4.5.1</span><br></pre></td></tr></table></figure><hr><h1 id="datetime-date"><a href="#datetime-date" class="headerlink" title="datetime.date"></a>datetime.date</h1><ul><li><p>表示日期的类，常用的属性有year, month, day</p></li><li><p>year的范围是[1, 9999]，month的范围是[1, 12]，day的最大值根据给定的year, month参数来决定（区分闰年）</p></li></ul><hr><h2 id="常用的属性"><a href="#常用的属性" class="headerlink" title="常用的属性"></a>常用的属性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 利用构造函数创建日期</span></span><br><span class="line">now_time = date(<span class="number">2016</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">print</span> now_time</span><br></pre></td></tr></table></figure><ul><li>date.max、date.min: 最大、最小日期</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最大最小日期</span></span><br><span class="line"><span class="keyword">print</span> now_time.min, now_time.max</span><br></pre></td></tr></table></figure><ul><li>date.resolution: 表示日期的最小单位</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 表示日期的最小单位</span></span><br><span class="line"><span class="keyword">print</span> now_time.resolution</span><br></pre></td></tr></table></figure><ul><li>date.year,date.month,date.day: 取得年，月，日</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取得年、月、日</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"year=&#123;0&#125;,month=&#123;1&#125;,day=&#123;2&#125;"</span>.format(now_time.year, now_time.month, now_time.day)</span><br></pre></td></tr></table></figure><hr><h2 id="常用的类方法"><a href="#常用的类方法" class="headerlink" title="常用的类方法"></a>常用的类方法</h2><ul><li>date.today()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个表示当前本地日期的date对象</span></span><br><span class="line"><span class="keyword">print</span> date.today()</span><br></pre></td></tr></table></figure><ul><li>date.fromtimestamp(timestamp)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据给定的时间戮,返回一个date对象</span></span><br><span class="line">timesstamp = <span class="number">1451577600</span></span><br><span class="line"><span class="keyword">print</span> date.fromtimestamp(timesstamp)</span><br></pre></td></tr></table></figure><ul><li>date.replace(year, month, day)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成一个新的日期对象</span></span><br><span class="line">replace_date = now_time.replace(year=<span class="number">1990</span>)</span><br><span class="line"><span class="keyword">print</span> replace_date</span><br></pre></td></tr></table></figure><ul><li>date.timetuple()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回日期对应的time.struct_time对象</span></span><br><span class="line"><span class="keyword">print</span> now_time.timetuple()</span><br></pre></td></tr></table></figure><ul><li>date.weekday()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回weekday,如果是星期一,返回0,如果是星期2,返回1,以此类推.</span></span><br><span class="line"><span class="keyword">print</span> now_time.weekday()</span><br></pre></td></tr></table></figure><ul><li>date.isocalendar()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回格式如(year,month,day)的元组;</span></span><br><span class="line"><span class="keyword">print</span> now_time.isocalendar()</span><br></pre></td></tr></table></figure><ul><li>date.isoformat()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回格式如'%Y-%m-%d'的字符串</span></span><br><span class="line"><span class="keyword">print</span> now_time.isoformat()</span><br></pre></td></tr></table></figure><ul><li>date.strftime(fmt)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 自定义格式化字符串</span></span><br><span class="line">fmt = <span class="string">"%Y-%m-%d %H:%M:%S"</span></span><br><span class="line"><span class="keyword">print</span> now_time.strftime(fmt)</span><br></pre></td></tr></table></figure><ul><li>两个日期运算</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">date_1 = date(<span class="number">1992</span>, <span class="number">1</span>, <span class="number">20</span>)</span><br><span class="line">date_2 = date(<span class="number">2000</span>, <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"date_2 - date_1 = &#123;0&#125;"</span>.format(date_2 - date_1)</span><br></pre></td></tr></table></figure><ul><li>比较日期时返回True or False</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> date_1 &gt; date_2:</span><br><span class="line"><span class="keyword">print</span> <span class="string">"date_1 &gt; date_2"</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">print</span> <span class="string">"date_1 &lt; date_2"</span></span><br></pre></td></tr></table></figure><hr><h1 id="datetime-time"><a href="#datetime-time" class="headerlink" title="datetime.time"></a>datetime.time</h1><ul><li><p>time类表示时间，由hour、minute、second、microsecond（时、分、秒以及微秒）组成</p></li><li><p>hour的范围为[0, 24)、minute的范围为[0, 60)、second的范围为[0, 60)、microsecond的范围为[0, 1000000)</p></li></ul><hr><h2 id="常用的属性-1"><a href="#常用的属性-1" class="headerlink" title="常用的属性"></a>常用的属性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构造函数创建时间</span></span><br><span class="line">now_time = time(<span class="number">10</span>, <span class="number">12</span>, <span class="number">13</span>)</span><br><span class="line"><span class="keyword">print</span> now_time</span><br></pre></td></tr></table></figure><ul><li>time.min、time.max</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最小、最大时间</span></span><br><span class="line"><span class="keyword">print</span> now_time.min, now_time.max</span><br></pre></td></tr></table></figure><ul><li>time.resolution</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 时间的最小单位，微妙</span></span><br><span class="line"><span class="keyword">print</span> now_time.resolution</span><br></pre></td></tr></table></figure><ul><li>time.hour、time.minute、time.second、time.microsecond</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 时、分、秒、微秒</span></span><br><span class="line"><span class="keyword">print</span> now_time.hour, now_time.minute, now_time.second, now_time.microsecond</span><br></pre></td></tr></table></figure><hr><h2 id="常用方法"><a href="#常用方法" class="headerlink" title="常用方法"></a>常用方法</h2><ul><li>time.replace()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个新的时间对象,用参数指定的时、分、秒、微秒代替原有对象中的属性</span></span><br><span class="line">new_time = now_time.replace(hour=<span class="number">19</span>,second=<span class="number">50</span>)</span><br><span class="line"><span class="keyword">print</span> new_time</span><br></pre></td></tr></table></figure><ul><li>time.isoformat()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回型如"%H:%M:%S"格式的字符串表示</span></span><br><span class="line"><span class="keyword">print</span> now_time.isoformat()</span><br></pre></td></tr></table></figure><ul><li>time.strftime(fmt)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回自定义格式化字符串。在下面详细介绍</span></span><br><span class="line">fmt = <span class="string">"%H:%M:%S:%f"</span></span><br><span class="line"><span class="keyword">print</span> now_time.strftime(fmt)</span><br></pre></td></tr></table></figure><hr><h1 id="datetime-datetime"><a href="#datetime-datetime" class="headerlink" title="datetime.datetime"></a>datetime.datetime</h1><ul><li>datetime是date与time的结合体,包括date与time的所有信息</li></ul><hr><h2 id="常用属性"><a href="#常用属性" class="headerlink" title="常用属性"></a>常用属性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取当前时间</span></span><br><span class="line">now_datetime = datetime.now()</span><br><span class="line"><span class="keyword">print</span> now_datetime</span><br></pre></td></tr></table></figure><ul><li>datetime.min、datetime.max</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最小值与最大值</span></span><br><span class="line"><span class="keyword">print</span> now_datetime.min, now_datetime.max</span><br></pre></td></tr></table></figure><ul><li>datetime.resolution</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># datetime最小单位</span></span><br><span class="line"><span class="keyword">print</span> now_datetime.resolution</span><br></pre></td></tr></table></figure><ul><li>datetime.year、month、day、hour、minute、second、microsecond、tzinfo</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取datetime的年、月、日、时、分、秒、时区</span></span><br><span class="line"><span class="keyword">print</span> now_datetime.year, now_datetime.month, now_datetime.day</span><br><span class="line"><span class="keyword">print</span> now_datetime.hour, now_datetime.minute, now_datetime.second, now_datetime.microsecond</span><br><span class="line"><span class="keyword">print</span> now_datetime.tzinfo</span><br></pre></td></tr></table></figure><hr><h2 id="常用方法-1"><a href="#常用方法-1" class="headerlink" title="常用方法"></a>常用方法</h2><ul><li>datetime.today()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个表示当前本地时间的datetime对象</span></span><br><span class="line"><span class="keyword">print</span> now_datetime.today()</span><br></pre></td></tr></table></figure><ul><li>datetime.utcnow()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 返回一个当前utc时间的datetime对象</span></span><br><span class="line"><span class="keyword">print</span> now_datetime.utcnow()</span><br></pre></td></tr></table></figure><ul><li>datetime.fromtimestamp(timestamp[, tz])</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据时间戮创建一个datetime对象,参数tz指定时区信息</span></span><br><span class="line">timesstamp = <span class="number">1451577600</span></span><br><span class="line"><span class="keyword">print</span> datetime.fromtimestamp(timesstamp)</span><br></pre></td></tr></table></figure><ul><li>datetime.utcfromtimestamp(timestamp)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据时间戮创建一个datetime对象</span></span><br><span class="line"><span class="keyword">print</span> datetime.utcfromtimestamp(timesstamp)</span><br></pre></td></tr></table></figure><ul><li>datetime.combine(date, time)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据date和time,创建一个datetime对象</span></span><br><span class="line">new_date = date.today()</span><br><span class="line">new_time = time(<span class="number">12</span>, <span class="number">12</span>, <span class="number">12</span>)</span><br><span class="line"><span class="keyword">print</span> datetime.combine(new_date, new_time)</span><br></pre></td></tr></table></figure><ul><li>datetime.strptime(date_string, format)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将格式字符串转换为datetime对象</span></span><br><span class="line">fmt = <span class="string">"%Y-%m-%d %H:%M:%S:%f"</span></span><br><span class="line">fmt_datetime = <span class="string">"2016-1-2 12:8:52:2569"</span></span><br><span class="line"><span class="keyword">print</span> datetime.strptime(fmt_datetime, fmt)</span><br></pre></td></tr></table></figure><ul><li>datetime.strftime(format)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将datetime对象格式化成字符串</span></span><br><span class="line">datetime_str = datetime.today().strftime(<span class="string">"%Y-%m-%d %H:%M:%S:%f"</span>)</span><br><span class="line"><span class="keyword">print</span> datetime_str</span><br></pre></td></tr></table></figure><ul><li>datetime.weekday()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取星期</span></span><br><span class="line"><span class="keyword">print</span> datetime.today().weekday()</span><br></pre></td></tr></table></figure><ul><li>datetime.utctimetuple()</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 转换成UTC的元祖</span></span><br><span class="line"><span class="keyword">print</span> datetime.today().utctimetuple()</span><br></pre></td></tr></table></figure><hr><h1 id="格式化日期符号表"><a href="#格式化日期符号表" class="headerlink" title="格式化日期符号表"></a>格式化日期符号表</h1><table><thead><tr><th>符号</th><th>意义</th></tr></thead><tbody><tr><td>%y</td><td>两位数的年份表示（00-99）</td></tr><tr><td>%Y</td><td>四位数的年份表示（000-9999）</td></tr><tr><td>%m</td><td>月份（01-12）</td></tr><tr><td>%d</td><td>月内中的一天（0-31）</td></tr><tr><td>%H</td><td>24小时制小时数（0-23）</td></tr><tr><td>%I</td><td>12小时制小时数（01-12）</td></tr><tr><td>%M</td><td>分钟数（00=59）</td></tr><tr><td>%S</td><td>秒（00-59）</td></tr><tr><td>%a</td><td>本地简化星期名称</td></tr><tr><td>%A</td><td>本地完整星期名称</td></tr><tr><td>%b</td><td>本地简化的月份名称</td></tr><tr><td>%B</td><td>本地完整的月份名称</td></tr><tr><td>%c</td><td>本地相应的日期表示和时间表示</td></tr><tr><td>%j</td><td>年内的一天（001-366）</td></tr><tr><td>%p</td><td>本地A.M.或P.M.的等价符</td></tr><tr><td>%U</td><td>一年中的星期数（00-53）星期天为星期的开始</td></tr><tr><td>%w</td><td>星期（0-6），星期天为星期的开始</td></tr><tr><td>%W</td><td>一年中的星期数（00-53）星期一为星期的开始</td></tr><tr><td>%x</td><td>本地相应的日期表示</td></tr><tr><td>%X</td><td>本地相应的时间表示</td></tr><tr><td>%Z</td><td>当前时区的名称</td></tr><tr><td>%%</td><td>%号本身</td></tr></tbody></table><hr><p>参考：Python基础教程(第2版·修订版)</p><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;Python标准库中提供了datatime模块来操作日期和时间&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/imperio-wxm/learning-python/tree/master/learning-python/learning_datetime&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Demo Github源码&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="http://imperio-wxm.github.io/categories/Python/"/>
    
    
      <category term="Python" scheme="http://imperio-wxm.github.io/tags/Python/"/>
    
      <category term="datatime" scheme="http://imperio-wxm.github.io/tags/datatime/"/>
    
  </entry>
  
  <entry>
    <title>Redis监控工具—Redis-stat、RedisLive</title>
    <link href="http://imperio-wxm.github.io/2016/02/25/Redis-Monitor-Tools/"/>
    <id>http://imperio-wxm.github.io/2016/02/25/Redis-Monitor-Tools/</id>
    <published>2016-02-25T02:15:32.000Z</published>
    <updated>2018-06-30T13:01:49.661Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Redis-stat（Ruby）和Redis Live（python）是两款Redis监控工具，下面将介绍如何安装部署这两个工具，监控Redis运行情况</p></blockquote><hr><a id="more"></a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">测试环境：</span><br><span class="line">  Ubuntu 14.04 LTS x64</span><br><span class="line">  Redis redis-3.0.7.tar.gz</span><br><span class="line">  Ruby ruby 1.9.3</span><br><span class="line">  Python 2.7.6</span><br></pre></td></tr></table></figure><hr><h1 id="Redis-安装"><a href="#Redis-安装" class="headerlink" title="Redis 安装"></a>Redis 安装</h1><p>Redis安装请参照：<a href="http://wxmimperio.tk/2016/02/20/Redis-Install-Config/" target="_blank" rel="noopener">Redis安装与配置</a></p><hr><h1 id="Redis-stat-安装部署"><a href="#Redis-stat-安装部署" class="headerlink" title="Redis-stat 安装部署"></a>Redis-stat 安装部署</h1><p>redis-stat is a simple Redis monitoring tool written in Ruby.</p><p>It is based on INFO command of Redis, and thus generally won’t affect the performance of the Redis instance unlike the other monitoring tools based on MONITOR command.</p><p>redis-stat allows you to monitor Redis instances</p><ul><li>either with vmstat-like output from the terminal</li><li>or with the dashboard page served by its embedded web server.</li></ul><p>通常来说，不会像基于MONITOR命令的监控工具一样，对Redis本身有性能上的影响</p><hr><p><a href="https://github.com/junegunn/redis-stat" target="_blank" rel="noopener">Github地址</a></p><hr><h2 id="卸载原有Ruby"><a href="#卸载原有Ruby" class="headerlink" title="卸载原有Ruby"></a>卸载原有Ruby</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get autoremove --purge ruby*</span><br></pre></td></tr></table></figure><hr><h2 id="安装Ruby"><a href="#安装Ruby" class="headerlink" title="安装Ruby"></a>安装Ruby</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ruby-full</span><br></pre></td></tr></table></figure><hr><h2 id="安装Redis-stat"><a href="#安装Redis-stat" class="headerlink" title="安装Redis-stat"></a>安装Redis-stat</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install redis-stat</span><br></pre></td></tr></table></figure><hr><h2 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h2><ul><li>redis-stat命令参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">usage: redis-stat [HOST[:PORT] ...] [INTERVAL [COUNT]]</span><br><span class="line"></span><br><span class="line">    -a, --auth=PASSWORD             设置密码</span><br><span class="line">    -v, --verbose                   显示更多信息</span><br><span class="line">        --style=STYLE               输出编码类型: unicode|ascii</span><br><span class="line">        --no-color                  取消ANSI颜色编码</span><br><span class="line">        --csv=OUTPUT_CSV_FILE_PATH  以CSV格式存储结果</span><br><span class="line">        --es=ELASTICSEARCH_URL      把结果发送到 ElasticSearch: [http://]HOST[:PORT][/INDEX]</span><br><span class="line"></span><br><span class="line">        --server[=PORT]             运行redis-stat的web server (默认端口号: <span class="number">63790</span>)</span><br><span class="line">        --daemon                    使得redis-stat成为进程。必须使用 --server 选项</span><br><span class="line">        </span><br><span class="line">        --version                   显示版本号</span><br><span class="line">        --help                      显示帮助信息</span><br></pre></td></tr></table></figure><ul><li>redis-stat运行命令行监控</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">redis-stat</span><br><span class="line">redis-stat <span class="number">1</span></span><br><span class="line">redis-stat <span class="number">1</span> <span class="number">10</span></span><br><span class="line">redis-stat --verbose</span><br><span class="line">redis-stat localhost:<span class="number">6380</span> <span class="number">1</span> <span class="number">10</span></span><br><span class="line">redis-stat localhost localhost:<span class="number">6380</span> localhost:<span class="number">6381</span> <span class="number">5</span></span><br><span class="line">redis-stat localhost localhost:<span class="number">6380</span> <span class="number">1</span> <span class="number">10</span> --csv=/tmp/outpu.csv --verbose</span><br></pre></td></tr></table></figure><ul><li>Server端运行界面</li></ul><p><img src="https://github.com/junegunn/redis-stat/raw/master/screenshots/redis-stat-0.3.0.png" alt=""></p><ul><li>Web界面中的redis-stat</li></ul><p>当设置–server选项之后，redis-stat会在后台启动一个嵌入式的web server(默认端口号：63790)，可以让你在浏览器中监控Redis</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">redis-stat --server</span><br><span class="line">redis-stat --verbose --server=<span class="number">8080</span> <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># redis-stat server can be daemonized</span></span><br><span class="line">redis-stat --server --daemon</span><br><span class="line"></span><br><span class="line"><span class="comment"># Kill the daemon</span></span><br><span class="line">killall <span class="number">-9</span> redis-stat-daemon</span><br></pre></td></tr></table></figure><ul><li>Web端运行界面</li></ul><p>然后在你的浏览器中输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://你的Redis IP:<span class="number">63790</span></span><br></pre></td></tr></table></figure><p><img src="https://github.com/junegunn/redis-stat/raw/master/screenshots/redis-stat-web.png" alt=""></p><hr><h1 id="RedisLive-安装部署"><a href="#RedisLive-安装部署" class="headerlink" title="RedisLive 安装部署"></a>RedisLive 安装部署</h1><p>Redis Live is a dashboard application with a number of useful widgets. At it’s heart is a monitoring script that periodically issues INFO and MONITOR command to the redis instances and stores the data for analytics.</p><p>长时间运行对Redis性能有所影响</p><hr><p><a href="https://github.com/nkrode/RedisLive" target="_blank" rel="noopener">Github地址</a><br><a href="http://www.nkrode.com/article/real-time-dashboard-for-redis" target="_blank" rel="noopener">Real time dashboard for redis</a></p><hr><h2 id="安装运行依赖"><a href="#安装运行依赖" class="headerlink" title="安装运行依赖"></a>安装运行依赖</h2><ul><li>tornado </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tornado</span><br></pre></td></tr></table></figure><ul><li>redis.py </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install redis</span><br></pre></td></tr></table></figure><ul><li>python-dateutil </li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install python-dateutil</span><br></pre></td></tr></table></figure><hr><h2 id="下载RedisLive"><a href="#下载RedisLive" class="headerlink" title="下载RedisLive"></a>下载RedisLive</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/kumarnitin/RedisLive.git</span><br></pre></td></tr></table></figure><hr><h2 id="conf配置"><a href="#conf配置" class="headerlink" title="conf配置"></a>conf配置</h2><p>进入src目录</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp redis-live.conf.example ./redis-live.conf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim redis-live.conf</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;  </span><br><span class="line">        <span class="string">"RedisServers"</span>:  </span><br><span class="line">        [   </span><br><span class="line">                &#123;  </span><br><span class="line">                  <span class="string">"server"</span> : <span class="string">"你的Redis IP地址"</span>,  </span><br><span class="line">                  <span class="string">"port"</span>  : <span class="number">6379</span>  </span><br><span class="line">                &#125;</span><br><span class="line">                ........</span><br><span class="line">                可以多个</span><br><span class="line">        ],  </span><br><span class="line">          </span><br><span class="line"> </span><br><span class="line">        <span class="string">"DataStoreType"</span> : <span class="string">"redis"</span>,  </span><br><span class="line"> </span><br><span class="line">        <span class="string">"RedisStatsServer"</span>:  </span><br><span class="line">        &#123;  </span><br><span class="line">                <span class="string">"server"</span> : <span class="string">"你的Redis 监控IP地址"</span>,  </span><br><span class="line">                <span class="string">"port"</span> : <span class="number">6379</span>  </span><br><span class="line">        &#125;,</span><br><span class="line">        </span><br><span class="line">        <span class="string">"SqliteStatsStore"</span> :</span><br><span class="line">        &#123;</span><br><span class="line">                <span class="string">"path"</span>:  <span class="string">"to your sql lite file"</span></span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>其中RedisServers为你要监控的redis实例，可以添加多个，RedisStatsServer是存储RedisLive监控数据的实例，如果redis有密码，可以在实例配置中加入password选项；如果没有存储RedisLive数据的实例，需要将DataStoreType改成”DataStoreType” : “sqlite”这种设置</li></ul><hr><h2 id="启动RedisLive"><a href="#启动RedisLive" class="headerlink" title="启动RedisLive"></a>启动RedisLive</h2><ul><li>启动监控脚本，监控120秒，duration参数是以秒为单位</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ./redis-monitor.py --duration=<span class="number">120</span></span><br></pre></td></tr></table></figure><ul><li>启动webserver。<br>RedisLive使用tornado作为web服务器，所以不需要单独安装服务器<br>Tornado web server 是使用Python编写出來的一个极轻量级、高可伸缩性和非阻塞IO的Web服务器软件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ./redis-live.py</span><br></pre></td></tr></table></figure><hr><h2 id="Web运行界面"><a href="#Web运行界面" class="headerlink" title="Web运行界面"></a>Web运行界面</h2><p>然后在你的浏览器中输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://你的Redis IP:<span class="number">8888</span>/index.html</span><br></pre></td></tr></table></figure><p><img src="https://github.com/kumarnitin/RedisLive/raw/master/design/redis-live.png" alt=""></p><hr><blockquote><blockquote><p>转载请注明出处</p></blockquote></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;Redis-stat（Ruby）和Redis Live（python）是两款Redis监控工具，下面将介绍如何安装部署这两个工具，监控Redis运行情况&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
    
    </summary>
    
      <category term="NoSQL" scheme="http://imperio-wxm.github.io/categories/NoSQL/"/>
    
      <category term="Redis" scheme="http://imperio-wxm.github.io/categories/NoSQL/Redis/"/>
    
    
      <category term="redis" scheme="http://imperio-wxm.github.io/tags/redis/"/>
    
      <category term="数据库" scheme="http://imperio-wxm.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="NoSQL" scheme="http://imperio-wxm.github.io/tags/NoSQL/"/>
    
      <category term="图形监控" scheme="http://imperio-wxm.github.io/tags/%E5%9B%BE%E5%BD%A2%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
</feed>
